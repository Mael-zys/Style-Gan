{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FAN-classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mael-zys/Style-Gan/blob/main/FAN_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qlqmb6FfO8nz"
      },
      "source": [
        "# if 'google.colab' in str(get_ipython()):\n",
        "#   from IPython.display import clear_output\n",
        "#   from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "#   gdd.download_file_from_google_drive(file_id='1k43v1P3csrqzkzE6xFavgMg2Yo8F0OpG',\n",
        "#   dest_path='./code.zip', unzip=True)\n",
        "\n",
        "# else:\n",
        "#   print('You are not using Colab. Please define working_dir with the absolute path to the folder where you downloaded the code')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVIbnARtVivP",
        "outputId": "5b26382c-50da-4212-c340-0db45c866d80"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKbbEZvrUnJo",
        "outputId": "805a2fcc-506e-40bc-efcc-d9e9070e9673"
      },
      "source": [
        "FOLDERNAME = 'FaceAttribute/FaceAttribute/'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the folder name.\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/FaceAttribute/FaceAttribute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYJKBuNkXurU",
        "outputId": "84e2d2ce-81e4-4940-e555-86c498d13ba2"
      },
      "source": [
        "%%bash\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--2021-06-14 15:18:00--  https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh [following]\n",
            "--2021-06-14 15:18:00--  https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8203, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58468498 (56M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-4.5.4-Linux-x86_64.sh.3’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  0% 8.03M 7s\n",
            "    50K .......... .......... .......... .......... ..........  0% 6.25M 8s\n",
            "   100K .......... .......... .......... .......... ..........  0% 12.8M 7s\n",
            "   150K .......... .......... .......... .......... ..........  0% 18.4M 6s\n",
            "   200K .......... .......... .......... .......... ..........  0% 16.9M 5s\n",
            "   250K .......... .......... .......... .......... ..........  0% 18.6M 5s\n",
            "   300K .......... .......... .......... .......... ..........  0% 28.1M 4s\n",
            "   350K .......... .......... .......... .......... ..........  0% 15.1M 4s\n",
            "   400K .......... .......... .......... .......... ..........  0% 32.3M 4s\n",
            "   450K .......... .......... .......... .......... ..........  0% 13.5M 4s\n",
            "   500K .......... .......... .......... .......... ..........  0% 27.3M 4s\n",
            "   550K .......... .......... .......... .......... ..........  1% 53.4M 4s\n",
            "   600K .......... .......... .......... .......... ..........  1% 60.1M 3s\n",
            "   650K .......... .......... .......... .......... ..........  1% 65.9M 3s\n",
            "   700K .......... .......... .......... .......... ..........  1% 67.9M 3s\n",
            "   750K .......... .......... .......... .......... ..........  1% 47.5M 3s\n",
            "   800K .......... .......... .......... .......... ..........  1% 64.5M 3s\n",
            "   850K .......... .......... .......... .......... ..........  1% 46.6M 3s\n",
            "   900K .......... .......... .......... .......... ..........  1% 51.7M 3s\n",
            "   950K .......... .......... .......... .......... ..........  1% 36.7M 3s\n",
            "  1000K .......... .......... .......... .......... ..........  1% 22.0M 3s\n",
            "  1050K .......... .......... .......... .......... ..........  1% 37.8M 3s\n",
            "  1100K .......... .......... .......... .......... ..........  2% 34.8M 2s\n",
            "  1150K .......... .......... .......... .......... ..........  2% 71.0M 2s\n",
            "  1200K .......... .......... .......... .......... ..........  2% 88.7M 2s\n",
            "  1250K .......... .......... .......... .......... ..........  2% 43.5M 2s\n",
            "  1300K .......... .......... .......... .......... ..........  2% 53.9M 2s\n",
            "  1350K .......... .......... .......... .......... ..........  2% 12.3M 2s\n",
            "  1400K .......... .......... .......... .......... ..........  2% 12.5M 2s\n",
            "  1450K .......... .......... .......... .......... ..........  2% 50.5M 2s\n",
            "  1500K .......... .......... .......... .......... ..........  2% 84.1M 2s\n",
            "  1550K .......... .......... .......... .......... ..........  2% 26.2M 2s\n",
            "  1600K .......... .......... .......... .......... ..........  2% 53.6M 2s\n",
            "  1650K .......... .......... .......... .......... ..........  2% 80.9M 2s\n",
            "  1700K .......... .......... .......... .......... ..........  3% 83.8M 2s\n",
            "  1750K .......... .......... .......... .......... ..........  3% 75.7M 2s\n",
            "  1800K .......... .......... .......... .......... ..........  3% 92.3M 2s\n",
            "  1850K .......... .......... .......... .......... ..........  3% 90.3M 2s\n",
            "  1900K .......... .......... .......... .......... ..........  3% 51.1M 2s\n",
            "  1950K .......... .......... .......... .......... ..........  3% 63.1M 2s\n",
            "  2000K .......... .......... .......... .......... ..........  3% 70.9M 2s\n",
            "  2050K .......... .......... .......... .......... ..........  3% 30.6M 2s\n",
            "  2100K .......... .......... .......... .......... ..........  3% 51.5M 2s\n",
            "  2150K .......... .......... .......... .......... ..........  3% 70.2M 2s\n",
            "  2200K .......... .......... .......... .......... ..........  3% 84.0M 2s\n",
            "  2250K .......... .......... .......... .......... ..........  4% 82.4M 2s\n",
            "  2300K .......... .......... .......... .......... ..........  4% 63.9M 2s\n",
            "  2350K .......... .......... .......... .......... ..........  4% 43.7M 2s\n",
            "  2400K .......... .......... .......... .......... ..........  4% 77.8M 2s\n",
            "  2450K .......... .......... .......... .......... ..........  4% 47.5M 2s\n",
            "  2500K .......... .......... .......... .......... ..........  4% 79.5M 2s\n",
            "  2550K .......... .......... .......... .......... ..........  4% 39.0M 2s\n",
            "  2600K .......... .......... .......... .......... ..........  4% 54.2M 2s\n",
            "  2650K .......... .......... .......... .......... ..........  4% 86.1M 2s\n",
            "  2700K .......... .......... .......... .......... ..........  4% 91.2M 2s\n",
            "  2750K .......... .......... .......... .......... ..........  4% 75.6M 2s\n",
            "  2800K .......... .......... .......... .......... ..........  4% 83.4M 2s\n",
            "  2850K .......... .......... .......... .......... ..........  5% 49.8M 2s\n",
            "  2900K .......... .......... .......... .......... ..........  5% 78.6M 2s\n",
            "  2950K .......... .......... .......... .......... ..........  5% 44.3M 2s\n",
            "  3000K .......... .......... .......... .......... ..........  5% 78.1M 2s\n",
            "  3050K .......... .......... .......... .......... ..........  5% 27.6M 2s\n",
            "  3100K .......... .......... .......... .......... ..........  5% 20.5M 2s\n",
            "  3150K .......... .......... .......... .......... ..........  5% 19.3M 2s\n",
            "  3200K .......... .......... .......... .......... ..........  5% 59.6M 2s\n",
            "  3250K .......... .......... .......... .......... ..........  5% 88.2M 2s\n",
            "  3300K .......... .......... .......... .......... ..........  5% 92.8M 2s\n",
            "  3350K .......... .......... .......... .......... ..........  5% 63.2M 2s\n",
            "  3400K .......... .......... .......... .......... ..........  6% 46.2M 2s\n",
            "  3450K .......... .......... .......... .......... ..........  6% 54.2M 2s\n",
            "  3500K .......... .......... .......... .......... ..........  6% 63.8M 2s\n",
            "  3550K .......... .......... .......... .......... ..........  6% 35.5M 2s\n",
            "  3600K .......... .......... .......... .......... ..........  6% 62.4M 1s\n",
            "  3650K .......... .......... .......... .......... ..........  6% 79.3M 1s\n",
            "  3700K .......... .......... .......... .......... ..........  6% 70.9M 1s\n",
            "  3750K .......... .......... .......... .......... ..........  6% 80.8M 1s\n",
            "  3800K .......... .......... .......... .......... ..........  6% 83.8M 1s\n",
            "  3850K .......... .......... .......... .......... ..........  6% 76.9M 1s\n",
            "  3900K .......... .......... .......... .......... ..........  6% 45.5M 1s\n",
            "  3950K .......... .......... .......... .......... ..........  7% 59.0M 1s\n",
            "  4000K .......... .......... .......... .......... ..........  7% 89.5M 1s\n",
            "  4050K .......... .......... .......... .......... ..........  7% 93.5M 1s\n",
            "  4100K .......... .......... .......... .......... ..........  7% 12.5M 1s\n",
            "  4150K .......... .......... .......... .......... ..........  7% 68.9M 1s\n",
            "  4200K .......... .......... .......... .......... ..........  7% 43.9M 1s\n",
            "  4250K .......... .......... .......... .......... ..........  7% 89.7M 1s\n",
            "  4300K .......... .......... .......... .......... ..........  7% 59.8M 1s\n",
            "  4350K .......... .......... .......... .......... ..........  7% 68.9M 1s\n",
            "  4400K .......... .......... .......... .......... ..........  7% 83.9M 1s\n",
            "  4450K .......... .......... .......... .......... ..........  7% 40.6M 1s\n",
            "  4500K .......... .......... .......... .......... ..........  7% 94.5M 1s\n",
            "  4550K .......... .......... .......... .......... ..........  8% 82.7M 1s\n",
            "  4600K .......... .......... .......... .......... ..........  8% 40.0M 1s\n",
            "  4650K .......... .......... .......... .......... ..........  8% 94.6M 1s\n",
            "  4700K .......... .......... .......... .......... ..........  8% 69.8M 1s\n",
            "  4750K .......... .......... .......... .......... ..........  8% 72.6M 1s\n",
            "  4800K .......... .......... .......... .......... ..........  8% 59.8M 1s\n",
            "  4850K .......... .......... .......... .......... ..........  8% 89.3M 1s\n",
            "  4900K .......... .......... .......... .......... ..........  8% 91.5M 1s\n",
            "  4950K .......... .......... .......... .......... ..........  8% 80.3M 1s\n",
            "  5000K .......... .......... .......... .......... ..........  8% 56.6M 1s\n",
            "  5050K .......... .......... .......... .......... ..........  8% 90.2M 1s\n",
            "  5100K .......... .......... .......... .......... ..........  9% 37.8M 1s\n",
            "  5150K .......... .......... .......... .......... ..........  9% 50.5M 1s\n",
            "  5200K .......... .......... .......... .......... ..........  9% 57.8M 1s\n",
            "  5250K .......... .......... .......... .......... ..........  9% 78.3M 1s\n",
            "  5300K .......... .......... .......... .......... ..........  9% 95.3M 1s\n",
            "  5350K .......... .......... .......... .......... ..........  9% 49.7M 1s\n",
            "  5400K .......... .......... .......... .......... ..........  9% 82.0M 1s\n",
            "  5450K .......... .......... .......... .......... ..........  9% 92.6M 1s\n",
            "  5500K .......... .......... .......... .......... ..........  9% 49.3M 1s\n",
            "  5550K .......... .......... .......... .......... ..........  9% 55.3M 1s\n",
            "  5600K .......... .......... .......... .......... ..........  9% 43.5M 1s\n",
            "  5650K .......... .......... .......... .......... ..........  9% 45.7M 1s\n",
            "  5700K .......... .......... .......... .......... .......... 10% 61.8M 1s\n",
            "  5750K .......... .......... .......... .......... .......... 10% 78.5M 1s\n",
            "  5800K .......... .......... .......... .......... .......... 10% 64.5M 1s\n",
            "  5850K .......... .......... .......... .......... .......... 10% 61.8M 1s\n",
            "  5900K .......... .......... .......... .......... .......... 10% 91.9M 1s\n",
            "  5950K .......... .......... .......... .......... .......... 10% 77.1M 1s\n",
            "  6000K .......... .......... .......... .......... .......... 10% 58.8M 1s\n",
            "  6050K .......... .......... .......... .......... .......... 10% 89.3M 1s\n",
            "  6100K .......... .......... .......... .......... .......... 10% 84.8M 1s\n",
            "  6150K .......... .......... .......... .......... .......... 10% 30.2M 1s\n",
            "  6200K .......... .......... .......... .......... .......... 10% 83.9M 1s\n",
            "  6250K .......... .......... .......... .......... .......... 11% 61.7M 1s\n",
            "  6300K .......... .......... .......... .......... .......... 11% 64.8M 1s\n",
            "  6350K .......... .......... .......... .......... .......... 11% 45.8M 1s\n",
            "  6400K .......... .......... .......... .......... .......... 11% 73.9M 1s\n",
            "  6450K .......... .......... .......... .......... .......... 11% 50.8M 1s\n",
            "  6500K .......... .......... .......... .......... .......... 11% 87.1M 1s\n",
            "  6550K .......... .......... .......... .......... .......... 11% 77.2M 1s\n",
            "  6600K .......... .......... .......... .......... .......... 11% 94.3M 1s\n",
            "  6650K .......... .......... .......... .......... .......... 11% 32.1M 1s\n",
            "  6700K .......... .......... .......... .......... .......... 11% 96.4M 1s\n",
            "  6750K .......... .......... .......... .......... .......... 11% 48.0M 1s\n",
            "  6800K .......... .......... .......... .......... .......... 11% 61.1M 1s\n",
            "  6850K .......... .......... .......... .......... .......... 12% 74.8M 1s\n",
            "  6900K .......... .......... .......... .......... .......... 12% 63.9M 1s\n",
            "  6950K .......... .......... .......... .......... .......... 12% 78.4M 1s\n",
            "  7000K .......... .......... .......... .......... .......... 12% 70.7M 1s\n",
            "  7050K .......... .......... .......... .......... .......... 12% 15.9M 1s\n",
            "  7100K .......... .......... .......... .......... .......... 12% 51.4M 1s\n",
            "  7150K .......... .......... .......... .......... .......... 12% 8.25M 1s\n",
            "  7200K .......... .......... .......... .......... .......... 12% 79.5M 1s\n",
            "  7250K .......... .......... .......... .......... .......... 12% 74.9M 1s\n",
            "  7300K .......... .......... .......... .......... .......... 12% 74.6M 1s\n",
            "  7350K .......... .......... .......... .......... .......... 12% 81.4M 1s\n",
            "  7400K .......... .......... .......... .......... .......... 13% 64.7M 1s\n",
            "  7450K .......... .......... .......... .......... .......... 13% 76.0M 1s\n",
            "  7500K .......... .......... .......... .......... .......... 13% 41.8M 1s\n",
            "  7550K .......... .......... .......... .......... .......... 13% 72.8M 1s\n",
            "  7600K .......... .......... .......... .......... .......... 13% 46.6M 1s\n",
            "  7650K .......... .......... .......... .......... .......... 13% 33.8M 1s\n",
            "  7700K .......... .......... .......... .......... .......... 13% 57.6M 1s\n",
            "  7750K .......... .......... .......... .......... .......... 13% 70.4M 1s\n",
            "  7800K .......... .......... .......... .......... .......... 13% 79.5M 1s\n",
            "  7850K .......... .......... .......... .......... .......... 13% 52.9M 1s\n",
            "  7900K .......... .......... .......... .......... .......... 13% 53.0M 1s\n",
            "  7950K .......... .......... .......... .......... .......... 14% 16.2M 1s\n",
            "  8000K .......... .......... .......... .......... .......... 14% 61.4M 1s\n",
            "  8050K .......... .......... .......... .......... .......... 14% 89.8M 1s\n",
            "  8100K .......... .......... .......... .......... .......... 14% 67.1M 1s\n",
            "  8150K .......... .......... .......... .......... .......... 14% 77.1M 1s\n",
            "  8200K .......... .......... .......... .......... .......... 14% 32.7M 1s\n",
            "  8250K .......... .......... .......... .......... .......... 14% 71.3M 1s\n",
            "  8300K .......... .......... .......... .......... .......... 14% 81.8M 1s\n",
            "  8350K .......... .......... .......... .......... .......... 14% 83.7M 1s\n",
            "  8400K .......... .......... .......... .......... .......... 14% 77.1M 1s\n",
            "  8450K .......... .......... .......... .......... .......... 14% 86.5M 1s\n",
            "  8500K .......... .......... .......... .......... .......... 14% 64.4M 1s\n",
            "  8550K .......... .......... .......... .......... .......... 15% 55.5M 1s\n",
            "  8600K .......... .......... .......... .......... .......... 15% 60.4M 1s\n",
            "  8650K .......... .......... .......... .......... .......... 15% 82.7M 1s\n",
            "  8700K .......... .......... .......... .......... .......... 15% 30.2M 1s\n",
            "  8750K .......... .......... .......... .......... .......... 15% 44.3M 1s\n",
            "  8800K .......... .......... .......... .......... .......... 15% 74.2M 1s\n",
            "  8850K .......... .......... .......... .......... .......... 15% 63.0M 1s\n",
            "  8900K .......... .......... .......... .......... .......... 15% 89.3M 1s\n",
            "  8950K .......... .......... .......... .......... .......... 15% 52.4M 1s\n",
            "  9000K .......... .......... .......... .......... .......... 15% 82.2M 1s\n",
            "  9050K .......... .......... .......... .......... .......... 15% 93.4M 1s\n",
            "  9100K .......... .......... .......... .......... .......... 16% 60.4M 1s\n",
            "  9150K .......... .......... .......... .......... .......... 16% 66.7M 1s\n",
            "  9200K .......... .......... .......... .......... .......... 16% 37.0M 1s\n",
            "  9250K .......... .......... .......... .......... .......... 16% 68.2M 1s\n",
            "  9300K .......... .......... .......... .......... .......... 16% 86.3M 1s\n",
            "  9350K .......... .......... .......... .......... .......... 16% 43.9M 1s\n",
            "  9400K .......... .......... .......... .......... .......... 16% 50.0M 1s\n",
            "  9450K .......... .......... .......... .......... .......... 16% 58.3M 1s\n",
            "  9500K .......... .......... .......... .......... .......... 16% 74.6M 1s\n",
            "  9550K .......... .......... .......... .......... .......... 16% 47.5M 1s\n",
            "  9600K .......... .......... .......... .......... .......... 16% 75.5M 1s\n",
            "  9650K .......... .......... .......... .......... .......... 16% 93.8M 1s\n",
            "  9700K .......... .......... .......... .......... .......... 17% 33.7M 1s\n",
            "  9750K .......... .......... .......... .......... .......... 17% 75.1M 1s\n",
            "  9800K .......... .......... .......... .......... .......... 17% 88.9M 1s\n",
            "  9850K .......... .......... .......... .......... .......... 17% 67.5M 1s\n",
            "  9900K .......... .......... .......... .......... .......... 17% 56.9M 1s\n",
            "  9950K .......... .......... .......... .......... .......... 17% 52.4M 1s\n",
            " 10000K .......... .......... .......... .......... .......... 17% 86.0M 1s\n",
            " 10050K .......... .......... .......... .......... .......... 17% 69.2M 1s\n",
            " 10100K .......... .......... .......... .......... .......... 17% 65.1M 1s\n",
            " 10150K .......... .......... .......... .......... .......... 17% 74.1M 1s\n",
            " 10200K .......... .......... .......... .......... .......... 17% 55.5M 1s\n",
            " 10250K .......... .......... .......... .......... .......... 18% 42.9M 1s\n",
            " 10300K .......... .......... .......... .......... .......... 18% 95.6M 1s\n",
            " 10350K .......... .......... .......... .......... .......... 18% 57.1M 1s\n",
            " 10400K .......... .......... .......... .......... .......... 18% 60.2M 1s\n",
            " 10450K .......... .......... .......... .......... .......... 18% 94.1M 1s\n",
            " 10500K .......... .......... .......... .......... .......... 18% 65.5M 1s\n",
            " 10550K .......... .......... .......... .......... .......... 18% 82.1M 1s\n",
            " 10600K .......... .......... .......... .......... .......... 18% 51.9M 1s\n",
            " 10650K .......... .......... .......... .......... .......... 18% 72.5M 1s\n",
            " 10700K .......... .......... .......... .......... .......... 18% 72.8M 1s\n",
            " 10750K .......... .......... .......... .......... .......... 18% 36.2M 1s\n",
            " 10800K .......... .......... .......... .......... .......... 19%  102M 1s\n",
            " 10850K .......... .......... .......... .......... .......... 19%  102M 1s\n",
            " 10900K .......... .......... .......... .......... .......... 19% 63.3M 1s\n",
            " 10950K .......... .......... .......... .......... .......... 19% 66.3M 1s\n",
            " 11000K .......... .......... .......... .......... .......... 19% 70.8M 1s\n",
            " 11050K .......... .......... .......... .......... .......... 19% 87.5M 1s\n",
            " 11100K .......... .......... .......... .......... .......... 19% 70.6M 1s\n",
            " 11150K .......... .......... .......... .......... .......... 19% 50.6M 1s\n",
            " 11200K .......... .......... .......... .......... .......... 19% 70.8M 1s\n",
            " 11250K .......... .......... .......... .......... .......... 19% 24.9M 1s\n",
            " 11300K .......... .......... .......... .......... .......... 19% 78.8M 1s\n",
            " 11350K .......... .......... .......... .......... .......... 19% 49.2M 1s\n",
            " 11400K .......... .......... .......... .......... .......... 20% 52.8M 1s\n",
            " 11450K .......... .......... .......... .......... .......... 20% 35.4M 1s\n",
            " 11500K .......... .......... .......... .......... .......... 20% 46.0M 1s\n",
            " 11550K .......... .......... .......... .......... .......... 20% 71.8M 1s\n",
            " 11600K .......... .......... .......... .......... .......... 20% 45.7M 1s\n",
            " 11650K .......... .......... .......... .......... .......... 20% 82.6M 1s\n",
            " 11700K .......... .......... .......... .......... .......... 20% 65.4M 1s\n",
            " 11750K .......... .......... .......... .......... .......... 20% 30.7M 1s\n",
            " 11800K .......... .......... .......... .......... .......... 20% 82.1M 1s\n",
            " 11850K .......... .......... .......... .......... .......... 20% 67.6M 1s\n",
            " 11900K .......... .......... .......... .......... .......... 20% 84.7M 1s\n",
            " 11950K .......... .......... .......... .......... .......... 21% 59.3M 1s\n",
            " 12000K .......... .......... .......... .......... .......... 21% 68.1M 1s\n",
            " 12050K .......... .......... .......... .......... .......... 21% 91.2M 1s\n",
            " 12100K .......... .......... .......... .......... .......... 21% 68.5M 1s\n",
            " 12150K .......... .......... .......... .......... .......... 21% 65.4M 1s\n",
            " 12200K .......... .......... .......... .......... .......... 21% 85.2M 1s\n",
            " 12250K .......... .......... .......... .......... .......... 21% 93.0M 1s\n",
            " 12300K .......... .......... .......... .......... .......... 21% 38.4M 1s\n",
            " 12350K .......... .......... .......... .......... .......... 21% 38.9M 1s\n",
            " 12400K .......... .......... .......... .......... .......... 21% 73.9M 1s\n",
            " 12450K .......... .......... .......... .......... .......... 21% 67.0M 1s\n",
            " 12500K .......... .......... .......... .......... .......... 21% 81.8M 1s\n",
            " 12550K .......... .......... .......... .......... .......... 22% 59.7M 1s\n",
            " 12600K .......... .......... .......... .......... .......... 22% 59.5M 1s\n",
            " 12650K .......... .......... .......... .......... .......... 22% 59.2M 1s\n",
            " 12700K .......... .......... .......... .......... .......... 22% 67.0M 1s\n",
            " 12750K .......... .......... .......... .......... .......... 22% 76.4M 1s\n",
            " 12800K .......... .......... .......... .......... .......... 22% 36.2M 1s\n",
            " 12850K .......... .......... .......... .......... .......... 22% 75.5M 1s\n",
            " 12900K .......... .......... .......... .......... .......... 22% 93.6M 1s\n",
            " 12950K .......... .......... .......... .......... .......... 22% 61.6M 1s\n",
            " 13000K .......... .......... .......... .......... .......... 22% 63.2M 1s\n",
            " 13050K .......... .......... .......... .......... .......... 22% 64.5M 1s\n",
            " 13100K .......... .......... .......... .......... .......... 23% 91.8M 1s\n",
            " 13150K .......... .......... .......... .......... .......... 23% 73.7M 1s\n",
            " 13200K .......... .......... .......... .......... .......... 23% 49.5M 1s\n",
            " 13250K .......... .......... .......... .......... .......... 23% 85.0M 1s\n",
            " 13300K .......... .......... .......... .......... .......... 23% 29.8M 1s\n",
            " 13350K .......... .......... .......... .......... .......... 23% 59.8M 1s\n",
            " 13400K .......... .......... .......... .......... .......... 23% 97.5M 1s\n",
            " 13450K .......... .......... .......... .......... .......... 23% 69.4M 1s\n",
            " 13500K .......... .......... .......... .......... .......... 23% 64.3M 1s\n",
            " 13550K .......... .......... .......... .......... .......... 23% 59.6M 1s\n",
            " 13600K .......... .......... .......... .......... .......... 23% 79.1M 1s\n",
            " 13650K .......... .......... .......... .......... .......... 23% 75.5M 1s\n",
            " 13700K .......... .......... .......... .......... .......... 24% 46.4M 1s\n",
            " 13750K .......... .......... .......... .......... .......... 24% 77.4M 1s\n",
            " 13800K .......... .......... .......... .......... .......... 24% 32.6M 1s\n",
            " 13850K .......... .......... .......... .......... .......... 24% 62.8M 1s\n",
            " 13900K .......... .......... .......... .......... .......... 24% 92.5M 1s\n",
            " 13950K .......... .......... .......... .......... .......... 24% 61.2M 1s\n",
            " 14000K .......... .......... .......... .......... .......... 24% 61.2M 1s\n",
            " 14050K .......... .......... .......... .......... .......... 24% 56.8M 1s\n",
            " 14100K .......... .......... .......... .......... .......... 24% 86.0M 1s\n",
            " 14150K .......... .......... .......... .......... .......... 24% 19.6M 1s\n",
            " 14200K .......... .......... .......... .......... .......... 24% 46.5M 1s\n",
            " 14250K .......... .......... .......... .......... .......... 25% 88.0M 1s\n",
            " 14300K .......... .......... .......... .......... .......... 25% 89.9M 1s\n",
            " 14350K .......... .......... .......... .......... .......... 25% 26.9M 1s\n",
            " 14400K .......... .......... .......... .......... .......... 25% 76.6M 1s\n",
            " 14450K .......... .......... .......... .......... .......... 25% 81.4M 1s\n",
            " 14500K .......... .......... .......... .......... .......... 25% 63.4M 1s\n",
            " 14550K .......... .......... .......... .......... .......... 25% 67.9M 1s\n",
            " 14600K .......... .......... .......... .......... .......... 25% 72.5M 1s\n",
            " 14650K .......... .......... .......... .......... .......... 25% 70.9M 1s\n",
            " 14700K .......... .......... .......... .......... .......... 25% 16.5M 1s\n",
            " 14750K .......... .......... .......... .......... .......... 25% 59.2M 1s\n",
            " 14800K .......... .......... .......... .......... .......... 26% 80.8M 1s\n",
            " 14850K .......... .......... .......... .......... .......... 26% 36.6M 1s\n",
            " 14900K .......... .......... .......... .......... .......... 26% 66.1M 1s\n",
            " 14950K .......... .......... .......... .......... .......... 26% 48.3M 1s\n",
            " 15000K .......... .......... .......... .......... .......... 26% 79.8M 1s\n",
            " 15050K .......... .......... .......... .......... .......... 26% 88.2M 1s\n",
            " 15100K .......... .......... .......... .......... .......... 26% 60.3M 1s\n",
            " 15150K .......... .......... .......... .......... .......... 26% 69.1M 1s\n",
            " 15200K .......... .......... .......... .......... .......... 26% 70.1M 1s\n",
            " 15250K .......... .......... .......... .......... .......... 26% 60.4M 1s\n",
            " 15300K .......... .......... .......... .......... .......... 26% 81.1M 1s\n",
            " 15350K .......... .......... .......... .......... .......... 26% 30.0M 1s\n",
            " 15400K .......... .......... .......... .......... .......... 27% 87.6M 1s\n",
            " 15450K .......... .......... .......... .......... .......... 27% 56.1M 1s\n",
            " 15500K .......... .......... .......... .......... .......... 27% 88.4M 1s\n",
            " 15550K .......... .......... .......... .......... .......... 27% 47.9M 1s\n",
            " 15600K .......... .......... .......... .......... .......... 27% 31.1M 1s\n",
            " 15650K .......... .......... .......... .......... .......... 27% 88.1M 1s\n",
            " 15700K .......... .......... .......... .......... .......... 27% 53.4M 1s\n",
            " 15750K .......... .......... .......... .......... .......... 27% 63.0M 1s\n",
            " 15800K .......... .......... .......... .......... .......... 27% 62.7M 1s\n",
            " 15850K .......... .......... .......... .......... .......... 27% 29.2M 1s\n",
            " 15900K .......... .......... .......... .......... .......... 27% 70.7M 1s\n",
            " 15950K .......... .......... .......... .......... .......... 28% 53.8M 1s\n",
            " 16000K .......... .......... .......... .......... .......... 28% 83.9M 1s\n",
            " 16050K .......... .......... .......... .......... .......... 28% 89.2M 1s\n",
            " 16100K .......... .......... .......... .......... .......... 28% 67.5M 1s\n",
            " 16150K .......... .......... .......... .......... .......... 28% 59.6M 1s\n",
            " 16200K .......... .......... .......... .......... .......... 28% 69.3M 1s\n",
            " 16250K .......... .......... .......... .......... .......... 28% 73.1M 1s\n",
            " 16300K .......... .......... .......... .......... .......... 28% 86.1M 1s\n",
            " 16350K .......... .......... .......... .......... .......... 28% 37.3M 1s\n",
            " 16400K .......... .......... .......... .......... .......... 28% 76.3M 1s\n",
            " 16450K .......... .......... .......... .......... .......... 28% 68.2M 1s\n",
            " 16500K .......... .......... .......... .......... .......... 28% 93.9M 1s\n",
            " 16550K .......... .......... .......... .......... .......... 29% 86.3M 1s\n",
            " 16600K .......... .......... .......... .......... .......... 29% 97.7M 1s\n",
            " 16650K .......... .......... .......... .......... .......... 29% 58.1M 1s\n",
            " 16700K .......... .......... .......... .......... .......... 29% 95.2M 1s\n",
            " 16750K .......... .......... .......... .......... .......... 29% 53.2M 1s\n",
            " 16800K .......... .......... .......... .......... .......... 29% 63.1M 1s\n",
            " 16850K .......... .......... .......... .......... .......... 29% 91.6M 1s\n",
            " 16900K .......... .......... .......... .......... .......... 29% 32.6M 1s\n",
            " 16950K .......... .......... .......... .......... .......... 29% 79.6M 1s\n",
            " 17000K .......... .......... .......... .......... .......... 29% 62.2M 1s\n",
            " 17050K .......... .......... .......... .......... .......... 29% 69.1M 1s\n",
            " 17100K .......... .......... .......... .......... .......... 30% 76.6M 1s\n",
            " 17150K .......... .......... .......... .......... .......... 30% 41.3M 1s\n",
            " 17200K .......... .......... .......... .......... .......... 30% 69.4M 1s\n",
            " 17250K .......... .......... .......... .......... .......... 30% 82.9M 1s\n",
            " 17300K .......... .......... .......... .......... .......... 30% 93.7M 1s\n",
            " 17350K .......... .......... .......... .......... .......... 30% 86.6M 1s\n",
            " 17400K .......... .......... .......... .......... .......... 30% 43.8M 1s\n",
            " 17450K .......... .......... .......... .......... .......... 30% 95.3M 1s\n",
            " 17500K .......... .......... .......... .......... .......... 30% 94.7M 1s\n",
            " 17550K .......... .......... .......... .......... .......... 30% 57.8M 1s\n",
            " 17600K .......... .......... .......... .......... .......... 30% 87.2M 1s\n",
            " 17650K .......... .......... .......... .......... .......... 30% 77.6M 1s\n",
            " 17700K .......... .......... .......... .......... .......... 31% 97.3M 1s\n",
            " 17750K .......... .......... .......... .......... .......... 31% 70.2M 1s\n",
            " 17800K .......... .......... .......... .......... .......... 31% 38.8M 1s\n",
            " 17850K .......... .......... .......... .......... .......... 31% 76.7M 1s\n",
            " 17900K .......... .......... .......... .......... .......... 31% 37.3M 1s\n",
            " 17950K .......... .......... .......... .......... .......... 31% 37.6M 1s\n",
            " 18000K .......... .......... .......... .......... .......... 31% 59.4M 1s\n",
            " 18050K .......... .......... .......... .......... .......... 31% 47.3M 1s\n",
            " 18100K .......... .......... .......... .......... .......... 31% 72.4M 1s\n",
            " 18150K .......... .......... .......... .......... .......... 31% 64.8M 1s\n",
            " 18200K .......... .......... .......... .......... .......... 31% 74.0M 1s\n",
            " 18250K .......... .......... .......... .......... .......... 32% 72.7M 1s\n",
            " 18300K .......... .......... .......... .......... .......... 32% 37.4M 1s\n",
            " 18350K .......... .......... .......... .......... .......... 32% 40.2M 1s\n",
            " 18400K .......... .......... .......... .......... .......... 32% 30.0M 1s\n",
            " 18450K .......... .......... .......... .......... .......... 32% 38.8M 1s\n",
            " 18500K .......... .......... .......... .......... .......... 32% 52.8M 1s\n",
            " 18550K .......... .......... .......... .......... .......... 32% 39.8M 1s\n",
            " 18600K .......... .......... .......... .......... .......... 32% 66.9M 1s\n",
            " 18650K .......... .......... .......... .......... .......... 32% 39.9M 1s\n",
            " 18700K .......... .......... .......... .......... .......... 32% 51.9M 1s\n",
            " 18750K .......... .......... .......... .......... .......... 32% 43.4M 1s\n",
            " 18800K .......... .......... .......... .......... .......... 33% 69.1M 1s\n",
            " 18850K .......... .......... .......... .......... .......... 33% 37.8M 1s\n",
            " 18900K .......... .......... .......... .......... .......... 33% 57.7M 1s\n",
            " 18950K .......... .......... .......... .......... .......... 33% 31.1M 1s\n",
            " 19000K .......... .......... .......... .......... .......... 33% 72.2M 1s\n",
            " 19050K .......... .......... .......... .......... .......... 33% 39.5M 1s\n",
            " 19100K .......... .......... .......... .......... .......... 33% 34.5M 1s\n",
            " 19150K .......... .......... .......... .......... .......... 33% 35.8M 1s\n",
            " 19200K .......... .......... .......... .......... .......... 33% 43.6M 1s\n",
            " 19250K .......... .......... .......... .......... .......... 33% 75.0M 1s\n",
            " 19300K .......... .......... .......... .......... .......... 33% 51.9M 1s\n",
            " 19350K .......... .......... .......... .......... .......... 33% 61.5M 1s\n",
            " 19400K .......... .......... .......... .......... .......... 34% 53.3M 1s\n",
            " 19450K .......... .......... .......... .......... .......... 34% 31.0M 1s\n",
            " 19500K .......... .......... .......... .......... .......... 34% 71.5M 1s\n",
            " 19550K .......... .......... .......... .......... .......... 34% 49.5M 1s\n",
            " 19600K .......... .......... .......... .......... .......... 34% 72.8M 1s\n",
            " 19650K .......... .......... .......... .......... .......... 34% 71.9M 1s\n",
            " 19700K .......... .......... .......... .......... .......... 34% 72.7M 1s\n",
            " 19750K .......... .......... .......... .......... .......... 34% 64.9M 1s\n",
            " 19800K .......... .......... .......... .......... .......... 34% 72.0M 1s\n",
            " 19850K .......... .......... .......... .......... .......... 34% 74.7M 1s\n",
            " 19900K .......... .......... .......... .......... .......... 34% 75.1M 1s\n",
            " 19950K .......... .......... .......... .......... .......... 35% 31.2M 1s\n",
            " 20000K .......... .......... .......... .......... .......... 35% 71.3M 1s\n",
            " 20050K .......... .......... .......... .......... .......... 35% 65.4M 1s\n",
            " 20100K .......... .......... .......... .......... .......... 35% 68.8M 1s\n",
            " 20150K .......... .......... .......... .......... .......... 35% 59.9M 1s\n",
            " 20200K .......... .......... .......... .......... .......... 35% 75.8M 1s\n",
            " 20250K .......... .......... .......... .......... .......... 35% 72.3M 1s\n",
            " 20300K .......... .......... .......... .......... .......... 35% 74.2M 1s\n",
            " 20350K .......... .......... .......... .......... .......... 35% 60.8M 1s\n",
            " 20400K .......... .......... .......... .......... .......... 35% 69.9M 1s\n",
            " 20450K .......... .......... .......... .......... .......... 35% 34.2M 1s\n",
            " 20500K .......... .......... .......... .......... .......... 35% 62.8M 1s\n",
            " 20550K .......... .......... .......... .......... .......... 36% 61.1M 1s\n",
            " 20600K .......... .......... .......... .......... .......... 36% 69.4M 1s\n",
            " 20650K .......... .......... .......... .......... .......... 36% 69.5M 1s\n",
            " 20700K .......... .......... .......... .......... .......... 36% 68.9M 1s\n",
            " 20750K .......... .......... .......... .......... .......... 36% 58.3M 1s\n",
            " 20800K .......... .......... .......... .......... .......... 36% 44.7M 1s\n",
            " 20850K .......... .......... .......... .......... .......... 36% 40.5M 1s\n",
            " 20900K .......... .......... .......... .......... .......... 36% 56.4M 1s\n",
            " 20950K .......... .......... .......... .......... .......... 36% 59.0M 1s\n",
            " 21000K .......... .......... .......... .......... .......... 36% 33.9M 1s\n",
            " 21050K .......... .......... .......... .......... .......... 36% 69.2M 1s\n",
            " 21100K .......... .......... .......... .......... .......... 37% 49.8M 1s\n",
            " 21150K .......... .......... .......... .......... .......... 37% 37.6M 1s\n",
            " 21200K .......... .......... .......... .......... .......... 37% 34.9M 1s\n",
            " 21250K .......... .......... .......... .......... .......... 37% 46.0M 1s\n",
            " 21300K .......... .......... .......... .......... .......... 37% 67.4M 1s\n",
            " 21350K .......... .......... .......... .......... .......... 37% 61.3M 1s\n",
            " 21400K .......... .......... .......... .......... .......... 37% 45.2M 1s\n",
            " 21450K .......... .......... .......... .......... .......... 37% 37.1M 1s\n",
            " 21500K .......... .......... .......... .......... .......... 37% 22.4M 1s\n",
            " 21550K .......... .......... .......... .......... .......... 37% 37.0M 1s\n",
            " 21600K .......... .......... .......... .......... .......... 37% 44.6M 1s\n",
            " 21650K .......... .......... .......... .......... .......... 38% 45.4M 1s\n",
            " 21700K .......... .......... .......... .......... .......... 38% 43.2M 1s\n",
            " 21750K .......... .......... .......... .......... .......... 38% 41.2M 1s\n",
            " 21800K .......... .......... .......... .......... .......... 38% 45.0M 1s\n",
            " 21850K .......... .......... .......... .......... .......... 38% 42.7M 1s\n",
            " 21900K .......... .......... .......... .......... .......... 38% 24.3M 1s\n",
            " 21950K .......... .......... .......... .......... .......... 38% 14.3M 1s\n",
            " 22000K .......... .......... .......... .......... .......... 38% 23.5M 1s\n",
            " 22050K .......... .......... .......... .......... .......... 38% 44.6M 1s\n",
            " 22100K .......... .......... .......... .......... .......... 38% 77.1M 1s\n",
            " 22150K .......... .......... .......... .......... .......... 38% 62.3M 1s\n",
            " 22200K .......... .......... .......... .......... .......... 38% 74.6M 1s\n",
            " 22250K .......... .......... .......... .......... .......... 39% 82.2M 1s\n",
            " 22300K .......... .......... .......... .......... .......... 39% 79.7M 1s\n",
            " 22350K .......... .......... .......... .......... .......... 39% 63.9M 1s\n",
            " 22400K .......... .......... .......... .......... .......... 39% 72.5M 1s\n",
            " 22450K .......... .......... .......... .......... .......... 39% 72.0M 1s\n",
            " 22500K .......... .......... .......... .......... .......... 39% 35.6M 1s\n",
            " 22550K .......... .......... .......... .......... .......... 39% 38.5M 1s\n",
            " 22600K .......... .......... .......... .......... .......... 39% 50.0M 1s\n",
            " 22650K .......... .......... .......... .......... .......... 39% 75.6M 1s\n",
            " 22700K .......... .......... .......... .......... .......... 39% 71.3M 1s\n",
            " 22750K .......... .......... .......... .......... .......... 39% 64.7M 1s\n",
            " 22800K .......... .......... .......... .......... .......... 40% 79.9M 1s\n",
            " 22850K .......... .......... .......... .......... .......... 40% 44.1M 1s\n",
            " 22900K .......... .......... .......... .......... .......... 40% 60.2M 1s\n",
            " 22950K .......... .......... .......... .......... .......... 40% 66.6M 1s\n",
            " 23000K .......... .......... .......... .......... .......... 40% 46.8M 1s\n",
            " 23050K .......... .......... .......... .......... .......... 40% 26.6M 1s\n",
            " 23100K .......... .......... .......... .......... .......... 40% 78.9M 1s\n",
            " 23150K .......... .......... .......... .......... .......... 40% 69.8M 1s\n",
            " 23200K .......... .......... .......... .......... .......... 40% 92.3M 1s\n",
            " 23250K .......... .......... .......... .......... .......... 40% 87.8M 1s\n",
            " 23300K .......... .......... .......... .......... .......... 40% 88.0M 1s\n",
            " 23350K .......... .......... .......... .......... .......... 40% 55.6M 1s\n",
            " 23400K .......... .......... .......... .......... .......... 41% 38.3M 1s\n",
            " 23450K .......... .......... .......... .......... .......... 41% 47.0M 1s\n",
            " 23500K .......... .......... .......... .......... .......... 41% 61.7M 1s\n",
            " 23550K .......... .......... .......... .......... .......... 41% 28.3M 1s\n",
            " 23600K .......... .......... .......... .......... .......... 41% 83.2M 1s\n",
            " 23650K .......... .......... .......... .......... .......... 41% 89.7M 1s\n",
            " 23700K .......... .......... .......... .......... .......... 41% 88.6M 1s\n",
            " 23750K .......... .......... .......... .......... .......... 41% 83.3M 1s\n",
            " 23800K .......... .......... .......... .......... .......... 41% 53.0M 1s\n",
            " 23850K .......... .......... .......... .......... .......... 41% 62.0M 1s\n",
            " 23900K .......... .......... .......... .......... .......... 41% 51.2M 1s\n",
            " 23950K .......... .......... .......... .......... .......... 42% 48.9M 1s\n",
            " 24000K .......... .......... .......... .......... .......... 42% 92.7M 1s\n",
            " 24050K .......... .......... .......... .......... .......... 42% 36.9M 1s\n",
            " 24100K .......... .......... .......... .......... .......... 42% 82.1M 1s\n",
            " 24150K .......... .......... .......... .......... .......... 42% 75.3M 1s\n",
            " 24200K .......... .......... .......... .......... .......... 42% 87.0M 1s\n",
            " 24250K .......... .......... .......... .......... .......... 42% 87.6M 1s\n",
            " 24300K .......... .......... .......... .......... .......... 42% 52.8M 1s\n",
            " 24350K .......... .......... .......... .......... .......... 42% 46.8M 1s\n",
            " 24400K .......... .......... .......... .......... .......... 42% 50.9M 1s\n",
            " 24450K .......... .......... .......... .......... .......... 42% 65.7M 1s\n",
            " 24500K .......... .......... .......... .......... .......... 42% 74.5M 1s\n",
            " 24550K .......... .......... .......... .......... .......... 43% 21.8M 1s\n",
            " 24600K .......... .......... .......... .......... .......... 43% 24.6M 1s\n",
            " 24650K .......... .......... .......... .......... .......... 43% 45.3M 1s\n",
            " 24700K .......... .......... .......... .......... .......... 43% 86.7M 1s\n",
            " 24750K .......... .......... .......... .......... .......... 43% 54.0M 1s\n",
            " 24800K .......... .......... .......... .......... .......... 43% 76.2M 1s\n",
            " 24850K .......... .......... .......... .......... .......... 43% 90.8M 1s\n",
            " 24900K .......... .......... .......... .......... .......... 43% 92.8M 1s\n",
            " 24950K .......... .......... .......... .......... .......... 43% 57.8M 1s\n",
            " 25000K .......... .......... .......... .......... .......... 43% 60.4M 1s\n",
            " 25050K .......... .......... .......... .......... .......... 43% 91.5M 1s\n",
            " 25100K .......... .......... .......... .......... .......... 44% 36.8M 1s\n",
            " 25150K .......... .......... .......... .......... .......... 44% 65.9M 1s\n",
            " 25200K .......... .......... .......... .......... .......... 44% 64.6M 1s\n",
            " 25250K .......... .......... .......... .......... .......... 44% 62.2M 1s\n",
            " 25300K .......... .......... .......... .......... .......... 44% 60.8M 1s\n",
            " 25350K .......... .......... .......... .......... .......... 44% 69.9M 1s\n",
            " 25400K .......... .......... .......... .......... .......... 44% 75.2M 1s\n",
            " 25450K .......... .......... .......... .......... .......... 44% 58.5M 1s\n",
            " 25500K .......... .......... .......... .......... .......... 44% 70.2M 1s\n",
            " 25550K .......... .......... .......... .......... .......... 44% 76.9M 1s\n",
            " 25600K .......... .......... .......... .......... .......... 44% 40.2M 1s\n",
            " 25650K .......... .......... .......... .......... .......... 45% 93.2M 1s\n",
            " 25700K .......... .......... .......... .......... .......... 45% 79.4M 1s\n",
            " 25750K .......... .......... .......... .......... .......... 45% 60.4M 1s\n",
            " 25800K .......... .......... .......... .......... .......... 45% 77.0M 1s\n",
            " 25850K .......... .......... .......... .......... .......... 45% 82.6M 1s\n",
            " 25900K .......... .......... .......... .......... .......... 45% 61.2M 1s\n",
            " 25950K .......... .......... .......... .......... .......... 45% 32.7M 1s\n",
            " 26000K .......... .......... .......... .......... .......... 45% 44.9M 1s\n",
            " 26050K .......... .......... .......... .......... .......... 45% 69.9M 1s\n",
            " 26100K .......... .......... .......... .......... .......... 45% 40.9M 1s\n",
            " 26150K .......... .......... .......... .......... .......... 45% 67.8M 1s\n",
            " 26200K .......... .......... .......... .......... .......... 45% 85.0M 1s\n",
            " 26250K .......... .......... .......... .......... .......... 46% 83.7M 1s\n",
            " 26300K .......... .......... .......... .......... .......... 46% 88.2M 1s\n",
            " 26350K .......... .......... .......... .......... .......... 46% 52.7M 1s\n",
            " 26400K .......... .......... .......... .......... .......... 46% 44.9M 1s\n",
            " 26450K .......... .......... .......... .......... .......... 46% 56.4M 1s\n",
            " 26500K .......... .......... .......... .......... .......... 46% 87.0M 1s\n",
            " 26550K .......... .......... .......... .......... .......... 46% 74.1M 1s\n",
            " 26600K .......... .......... .......... .......... .......... 46% 39.9M 1s\n",
            " 26650K .......... .......... .......... .......... .......... 46% 92.7M 1s\n",
            " 26700K .......... .......... .......... .......... .......... 46% 85.4M 1s\n",
            " 26750K .......... .......... .......... .......... .......... 46% 60.4M 1s\n",
            " 26800K .......... .......... .......... .......... .......... 47% 44.4M 1s\n",
            " 26850K .......... .......... .......... .......... .......... 47% 50.5M 1s\n",
            " 26900K .......... .......... .......... .......... .......... 47% 40.2M 1s\n",
            " 26950K .......... .......... .......... .......... .......... 47% 38.2M 1s\n",
            " 27000K .......... .......... .......... .......... .......... 47% 86.0M 1s\n",
            " 27050K .......... .......... .......... .......... .......... 47% 93.1M 1s\n",
            " 27100K .......... .......... .......... .......... .......... 47% 8.48M 1s\n",
            " 27150K .......... .......... .......... .......... .......... 47% 9.90M 1s\n",
            " 27200K .......... .......... .......... .......... .......... 47% 37.9M 1s\n",
            " 27250K .......... .......... .......... .......... .......... 47% 36.9M 1s\n",
            " 27300K .......... .......... .......... .......... .......... 47% 37.5M 1s\n",
            " 27350K .......... .......... .......... .......... .......... 47% 54.4M 1s\n",
            " 27400K .......... .......... .......... .......... .......... 48% 88.2M 1s\n",
            " 27450K .......... .......... .......... .......... .......... 48% 79.2M 1s\n",
            " 27500K .......... .......... .......... .......... .......... 48% 72.0M 1s\n",
            " 27550K .......... .......... .......... .......... .......... 48% 60.0M 1s\n",
            " 27600K .......... .......... .......... .......... .......... 48% 76.4M 1s\n",
            " 27650K .......... .......... .......... .......... .......... 48% 36.6M 1s\n",
            " 27700K .......... .......... .......... .......... .......... 48% 84.7M 1s\n",
            " 27750K .......... .......... .......... .......... .......... 48% 75.9M 1s\n",
            " 27800K .......... .......... .......... .......... .......... 48%  102M 1s\n",
            " 27850K .......... .......... .......... .......... .......... 48% 92.2M 1s\n",
            " 27900K .......... .......... .......... .......... .......... 48% 95.4M 1s\n",
            " 27950K .......... .......... .......... .......... .......... 49% 73.7M 1s\n",
            " 28000K .......... .......... .......... .......... .......... 49% 75.6M 1s\n",
            " 28050K .......... .......... .......... .......... .......... 49% 88.6M 1s\n",
            " 28100K .......... .......... .......... .......... .......... 49% 94.5M 1s\n",
            " 28150K .......... .......... .......... .......... .......... 49% 36.1M 1s\n",
            " 28200K .......... .......... .......... .......... .......... 49% 91.4M 1s\n",
            " 28250K .......... .......... .......... .......... .......... 49% 90.7M 1s\n",
            " 28300K .......... .......... .......... .......... .......... 49% 90.4M 1s\n",
            " 28350K .......... .......... .......... .......... .......... 49% 78.1M 1s\n",
            " 28400K .......... .......... .......... .......... .......... 49% 97.3M 1s\n",
            " 28450K .......... .......... .......... .......... .......... 49% 89.1M 1s\n",
            " 28500K .......... .......... .......... .......... .......... 50% 85.8M 1s\n",
            " 28550K .......... .......... .......... .......... .......... 50% 74.8M 1s\n",
            " 28600K .......... .......... .......... .......... .......... 50% 97.5M 1s\n",
            " 28650K .......... .......... .......... .......... .......... 50% 44.7M 1s\n",
            " 28700K .......... .......... .......... .......... .......... 50% 90.0M 1s\n",
            " 28750K .......... .......... .......... .......... .......... 50% 79.0M 1s\n",
            " 28800K .......... .......... .......... .......... .......... 50% 95.6M 1s\n",
            " 28850K .......... .......... .......... .......... .......... 50% 91.1M 1s\n",
            " 28900K .......... .......... .......... .......... .......... 50% 85.3M 1s\n",
            " 28950K .......... .......... .......... .......... .......... 50% 76.5M 1s\n",
            " 29000K .......... .......... .......... .......... .......... 50% 88.2M 1s\n",
            " 29050K .......... .......... .......... .......... .......... 50% 78.6M 1s\n",
            " 29100K .......... .......... .......... .......... .......... 51% 74.0M 1s\n",
            " 29150K .......... .......... .......... .......... .......... 51% 34.8M 1s\n",
            " 29200K .......... .......... .......... .......... .......... 51% 81.5M 1s\n",
            " 29250K .......... .......... .......... .......... .......... 51% 82.1M 1s\n",
            " 29300K .......... .......... .......... .......... .......... 51% 85.1M 1s\n",
            " 29350K .......... .......... .......... .......... .......... 51% 25.2M 1s\n",
            " 29400K .......... .......... .......... .......... .......... 51% 79.9M 1s\n",
            " 29450K .......... .......... .......... .......... .......... 51% 79.3M 1s\n",
            " 29500K .......... .......... .......... .......... .......... 51% 81.6M 1s\n",
            " 29550K .......... .......... .......... .......... .......... 51% 78.1M 1s\n",
            " 29600K .......... .......... .......... .......... .......... 51% 65.7M 1s\n",
            " 29650K .......... .......... .......... .......... .......... 52% 95.7M 1s\n",
            " 29700K .......... .......... .......... .......... .......... 52% 38.8M 1s\n",
            " 29750K .......... .......... .......... .......... .......... 52% 80.5M 1s\n",
            " 29800K .......... .......... .......... .......... .......... 52% 90.1M 1s\n",
            " 29850K .......... .......... .......... .......... .......... 52% 91.8M 1s\n",
            " 29900K .......... .......... .......... .......... .......... 52% 88.2M 1s\n",
            " 29950K .......... .......... .......... .......... .......... 52% 74.3M 1s\n",
            " 30000K .......... .......... .......... .......... .......... 52% 86.3M 1s\n",
            " 30050K .......... .......... .......... .......... .......... 52% 98.7M 1s\n",
            " 30100K .......... .......... .......... .......... .......... 52% 91.8M 1s\n",
            " 30150K .......... .......... .......... .......... .......... 52% 77.4M 1s\n",
            " 30200K .......... .......... .......... .......... .......... 52% 42.9M 1s\n",
            " 30250K .......... .......... .......... .......... .......... 53% 97.1M 1s\n",
            " 30300K .......... .......... .......... .......... .......... 53% 93.6M 1s\n",
            " 30350K .......... .......... .......... .......... .......... 53% 82.6M 1s\n",
            " 30400K .......... .......... .......... .......... .......... 53% 85.8M 1s\n",
            " 30450K .......... .......... .......... .......... .......... 53% 83.7M 0s\n",
            " 30500K .......... .......... .......... .......... .......... 53% 68.9M 0s\n",
            " 30550K .......... .......... .......... .......... .......... 53% 1.83M 1s\n",
            " 30600K .......... .......... .......... .......... .......... 53% 49.9M 1s\n",
            " 30650K .......... .......... .......... .......... .......... 53% 50.7M 1s\n",
            " 30700K .......... .......... .......... .......... .......... 53% 25.6M 1s\n",
            " 30750K .......... .......... .......... .......... .......... 53% 68.6M 1s\n",
            " 30800K .......... .......... .......... .......... .......... 54% 41.0M 1s\n",
            " 30850K .......... .......... .......... .......... .......... 54% 62.6M 1s\n",
            " 30900K .......... .......... .......... .......... .......... 54% 52.9M 1s\n",
            " 30950K .......... .......... .......... .......... .......... 54% 46.7M 1s\n",
            " 31000K .......... .......... .......... .......... .......... 54% 46.3M 1s\n",
            " 31050K .......... .......... .......... .......... .......... 54% 43.8M 1s\n",
            " 31100K .......... .......... .......... .......... .......... 54% 42.6M 1s\n",
            " 31150K .......... .......... .......... .......... .......... 54% 34.6M 1s\n",
            " 31200K .......... .......... .......... .......... .......... 54% 26.8M 1s\n",
            " 31250K .......... .......... .......... .......... .......... 54% 33.1M 1s\n",
            " 31300K .......... .......... .......... .......... .......... 54% 41.1M 1s\n",
            " 31350K .......... .......... .......... .......... .......... 54% 47.2M 1s\n",
            " 31400K .......... .......... .......... .......... .......... 55% 38.8M 1s\n",
            " 31450K .......... .......... .......... .......... .......... 55% 45.0M 1s\n",
            " 31500K .......... .......... .......... .......... .......... 55% 39.0M 1s\n",
            " 31550K .......... .......... .......... .......... .......... 55% 37.3M 1s\n",
            " 31600K .......... .......... .......... .......... .......... 55% 80.7M 1s\n",
            " 31650K .......... .......... .......... .......... .......... 55% 82.3M 1s\n",
            " 31700K .......... .......... .......... .......... .......... 55% 80.3M 0s\n",
            " 31750K .......... .......... .......... .......... .......... 55% 34.4M 0s\n",
            " 31800K .......... .......... .......... .......... .......... 55% 88.1M 0s\n",
            " 31850K .......... .......... .......... .......... .......... 55% 58.3M 0s\n",
            " 31900K .......... .......... .......... .......... .......... 55% 42.2M 0s\n",
            " 31950K .......... .......... .......... .......... .......... 56% 33.9M 0s\n",
            " 32000K .......... .......... .......... .......... .......... 56% 14.3M 0s\n",
            " 32050K .......... .......... .......... .......... .......... 56% 37.8M 0s\n",
            " 32100K .......... .......... .......... .......... .......... 56% 82.9M 0s\n",
            " 32150K .......... .......... .......... .......... .......... 56% 77.7M 0s\n",
            " 32200K .......... .......... .......... .......... .......... 56% 84.6M 0s\n",
            " 32250K .......... .......... .......... .......... .......... 56% 40.1M 0s\n",
            " 32300K .......... .......... .......... .......... .......... 56% 78.8M 0s\n",
            " 32350K .......... .......... .......... .......... .......... 56% 51.5M 0s\n",
            " 32400K .......... .......... .......... .......... .......... 56% 46.3M 0s\n",
            " 32450K .......... .......... .......... .......... .......... 56% 80.0M 0s\n",
            " 32500K .......... .......... .......... .......... .......... 57% 77.3M 0s\n",
            " 32550K .......... .......... .......... .......... .......... 57% 71.9M 0s\n",
            " 32600K .......... .......... .......... .......... .......... 57% 91.9M 0s\n",
            " 32650K .......... .......... .......... .......... .......... 57% 90.6M 0s\n",
            " 32700K .......... .......... .......... .......... .......... 57% 37.3M 0s\n",
            " 32750K .......... .......... .......... .......... .......... 57% 36.8M 0s\n",
            " 32800K .......... .......... .......... .......... .......... 57% 83.9M 0s\n",
            " 32850K .......... .......... .......... .......... .......... 57% 86.7M 0s\n",
            " 32900K .......... .......... .......... .......... .......... 57% 93.2M 0s\n",
            " 32950K .......... .......... .......... .......... .......... 57% 6.27M 0s\n",
            " 33000K .......... .......... .......... .......... .......... 57% 39.2M 0s\n",
            " 33050K .......... .......... .......... .......... .......... 57% 29.1M 0s\n",
            " 33100K .......... .......... .......... .......... .......... 58% 28.5M 0s\n",
            " 33150K .......... .......... .......... .......... .......... 58% 25.8M 0s\n",
            " 33200K .......... .......... .......... .......... .......... 58% 60.1M 0s\n",
            " 33250K .......... .......... .......... .......... .......... 58% 41.0M 0s\n",
            " 33300K .......... .......... .......... .......... .......... 58% 76.3M 0s\n",
            " 33350K .......... .......... .......... .......... .......... 58% 78.6M 0s\n",
            " 33400K .......... .......... .......... .......... .......... 58% 63.1M 0s\n",
            " 33450K .......... .......... .......... .......... .......... 58% 74.7M 0s\n",
            " 33500K .......... .......... .......... .......... .......... 58% 62.7M 0s\n",
            " 33550K .......... .......... .......... .......... .......... 58% 74.6M 0s\n",
            " 33600K .......... .......... .......... .......... .......... 58% 98.5M 0s\n",
            " 33650K .......... .......... .......... .......... .......... 59% 70.1M 0s\n",
            " 33700K .......... .......... .......... .......... .......... 59% 90.5M 0s\n",
            " 33750K .......... .......... .......... .......... .......... 59% 63.6M 0s\n",
            " 33800K .......... .......... .......... .......... .......... 59% 39.0M 0s\n",
            " 33850K .......... .......... .......... .......... .......... 59% 66.5M 0s\n",
            " 33900K .......... .......... .......... .......... .......... 59% 72.7M 0s\n",
            " 33950K .......... .......... .......... .......... .......... 59% 39.8M 0s\n",
            " 34000K .......... .......... .......... .......... .......... 59% 59.4M 0s\n",
            " 34050K .......... .......... .......... .......... .......... 59% 86.6M 0s\n",
            " 34100K .......... .......... .......... .......... .......... 59% 89.3M 0s\n",
            " 34150K .......... .......... .......... .......... .......... 59% 44.3M 0s\n",
            " 34200K .......... .......... .......... .......... .......... 59% 61.2M 0s\n",
            " 34250K .......... .......... .......... .......... .......... 60% 82.1M 0s\n",
            " 34300K .......... .......... .......... .......... .......... 60% 40.1M 0s\n",
            " 34350K .......... .......... .......... .......... .......... 60% 69.9M 0s\n",
            " 34400K .......... .......... .......... .......... .......... 60% 85.6M 0s\n",
            " 34450K .......... .......... .......... .......... .......... 60% 46.2M 0s\n",
            " 34500K .......... .......... .......... .......... .......... 60% 81.5M 0s\n",
            " 34550K .......... .......... .......... .......... .......... 60% 75.5M 0s\n",
            " 34600K .......... .......... .......... .......... .......... 60% 78.1M 0s\n",
            " 34650K .......... .......... .......... .......... .......... 60% 43.1M 0s\n",
            " 34700K .......... .......... .......... .......... .......... 60% 55.6M 0s\n",
            " 34750K .......... .......... .......... .......... .......... 60% 68.2M 0s\n",
            " 34800K .......... .......... .......... .......... .......... 61% 38.4M 0s\n",
            " 34850K .......... .......... .......... .......... .......... 61% 83.9M 0s\n",
            " 34900K .......... .......... .......... .......... .......... 61% 47.6M 0s\n",
            " 34950K .......... .......... .......... .......... .......... 61% 76.4M 0s\n",
            " 35000K .......... .......... .......... .......... .......... 61% 56.1M 0s\n",
            " 35050K .......... .......... .......... .......... .......... 61% 70.8M 0s\n",
            " 35100K .......... .......... .......... .......... .......... 61% 41.2M 0s\n",
            " 35150K .......... .......... .......... .......... .......... 61% 53.2M 0s\n",
            " 35200K .......... .......... .......... .......... .......... 61% 87.2M 0s\n",
            " 35250K .......... .......... .......... .......... .......... 61% 85.3M 0s\n",
            " 35300K .......... .......... .......... .......... .......... 61% 34.0M 0s\n",
            " 35350K .......... .......... .......... .......... .......... 61% 15.6M 0s\n",
            " 35400K .......... .......... .......... .......... .......... 62% 76.2M 0s\n",
            " 35450K .......... .......... .......... .......... .......... 62% 42.4M 0s\n",
            " 35500K .......... .......... .......... .......... .......... 62% 82.5M 0s\n",
            " 35550K .......... .......... .......... .......... .......... 62% 71.1M 0s\n",
            " 35600K .......... .......... .......... .......... .......... 62% 72.2M 0s\n",
            " 35650K .......... .......... .......... .......... .......... 62% 57.2M 0s\n",
            " 35700K .......... .......... .......... .......... .......... 62% 58.0M 0s\n",
            " 35750K .......... .......... .......... .......... .......... 62% 72.8M 0s\n",
            " 35800K .......... .......... .......... .......... .......... 62% 62.9M 0s\n",
            " 35850K .......... .......... .......... .......... .......... 62% 38.0M 0s\n",
            " 35900K .......... .......... .......... .......... .......... 62% 60.0M 0s\n",
            " 35950K .......... .......... .......... .......... .......... 63% 69.8M 0s\n",
            " 36000K .......... .......... .......... .......... .......... 63% 83.7M 0s\n",
            " 36050K .......... .......... .......... .......... .......... 63% 85.0M 0s\n",
            " 36100K .......... .......... .......... .......... .......... 63% 93.7M 0s\n",
            " 36150K .......... .......... .......... .......... .......... 63% 33.4M 0s\n",
            " 36200K .......... .......... .......... .......... .......... 63% 58.7M 0s\n",
            " 36250K .......... .......... .......... .......... .......... 63% 70.5M 0s\n",
            " 36300K .......... .......... .......... .......... .......... 63% 77.9M 0s\n",
            " 36350K .......... .......... .......... .......... .......... 63% 34.1M 0s\n",
            " 36400K .......... .......... .......... .......... .......... 63% 58.3M 0s\n",
            " 36450K .......... .......... .......... .......... .......... 63% 93.9M 0s\n",
            " 36500K .......... .......... .......... .......... .......... 64% 94.9M 0s\n",
            " 36550K .......... .......... .......... .......... .......... 64% 81.6M 0s\n",
            " 36600K .......... .......... .......... .......... .......... 64% 54.2M 0s\n",
            " 36650K .......... .......... .......... .......... .......... 64% 52.0M 0s\n",
            " 36700K .......... .......... .......... .......... .......... 64% 81.4M 0s\n",
            " 36750K .......... .......... .......... .......... .......... 64% 68.0M 0s\n",
            " 36800K .......... .......... .......... .......... .......... 64% 71.1M 0s\n",
            " 36850K .......... .......... .......... .......... .......... 64% 38.2M 0s\n",
            " 36900K .......... .......... .......... .......... .......... 64% 86.8M 0s\n",
            " 36950K .......... .......... .......... .......... .......... 64% 76.0M 0s\n",
            " 37000K .......... .......... .......... .......... .......... 64% 87.6M 0s\n",
            " 37050K .......... .......... .......... .......... .......... 64% 64.5M 0s\n",
            " 37100K .......... .......... .......... .......... .......... 65% 78.5M 0s\n",
            " 37150K .......... .......... .......... .......... .......... 65% 71.8M 0s\n",
            " 37200K .......... .......... .......... .......... .......... 65% 88.1M 0s\n",
            " 37250K .......... .......... .......... .......... .......... 65% 77.2M 0s\n",
            " 37300K .......... .......... .......... .......... .......... 65% 82.3M 0s\n",
            " 37350K .......... .......... .......... .......... .......... 65% 36.1M 0s\n",
            " 37400K .......... .......... .......... .......... .......... 65% 77.9M 0s\n",
            " 37450K .......... .......... .......... .......... .......... 65% 72.8M 0s\n",
            " 37500K .......... .......... .......... .......... .......... 65% 15.0M 0s\n",
            " 37550K .......... .......... .......... .......... .......... 65% 5.96M 0s\n",
            " 37600K .......... .......... .......... .......... .......... 65% 94.0M 0s\n",
            " 37650K .......... .......... .......... .......... .......... 66% 96.3M 0s\n",
            " 37700K .......... .......... .......... .......... .......... 66% 96.1M 0s\n",
            " 37750K .......... .......... .......... .......... .......... 66% 82.4M 0s\n",
            " 37800K .......... .......... .......... .......... .......... 66%  103M 0s\n",
            " 37850K .......... .......... .......... .......... .......... 66%  105M 0s\n",
            " 37900K .......... .......... .......... .......... .......... 66% 34.8M 0s\n",
            " 37950K .......... .......... .......... .......... .......... 66% 80.6M 0s\n",
            " 38000K .......... .......... .......... .......... .......... 66%  111M 0s\n",
            " 38050K .......... .......... .......... .......... .......... 66%  117M 0s\n",
            " 38100K .......... .......... .......... .......... .......... 66%  116M 0s\n",
            " 38150K .......... .......... .......... .......... .......... 66% 28.8M 0s\n",
            " 38200K .......... .......... .......... .......... .......... 66% 82.1M 0s\n",
            " 38250K .......... .......... .......... .......... .......... 67% 80.7M 0s\n",
            " 38300K .......... .......... .......... .......... .......... 67% 95.1M 0s\n",
            " 38350K .......... .......... .......... .......... .......... 67% 79.0M 0s\n",
            " 38400K .......... .......... .......... .......... .......... 67% 33.7M 0s\n",
            " 38450K .......... .......... .......... .......... .......... 67% 96.9M 0s\n",
            " 38500K .......... .......... .......... .......... .......... 67% 96.9M 0s\n",
            " 38550K .......... .......... .......... .......... .......... 67% 82.9M 0s\n",
            " 38600K .......... .......... .......... .......... .......... 67% 97.4M 0s\n",
            " 38650K .......... .......... .......... .......... .......... 67%  113M 0s\n",
            " 38700K .......... .......... .......... .......... .......... 67%  108M 0s\n",
            " 38750K .......... .......... .......... .......... .......... 67% 86.2M 0s\n",
            " 38800K .......... .......... .......... .......... .......... 68%  105M 0s\n",
            " 38850K .......... .......... .......... .......... .......... 68% 94.8M 0s\n",
            " 38900K .......... .......... .......... .......... .......... 68% 33.4M 0s\n",
            " 38950K .......... .......... .......... .......... .......... 68% 89.0M 0s\n",
            " 39000K .......... .......... .......... .......... .......... 68% 97.5M 0s\n",
            " 39050K .......... .......... .......... .......... .......... 68% 97.1M 0s\n",
            " 39100K .......... .......... .......... .......... .......... 68%  101M 0s\n",
            " 39150K .......... .......... .......... .......... .......... 68% 90.1M 0s\n",
            " 39200K .......... .......... .......... .......... .......... 68% 99.2M 0s\n",
            " 39250K .......... .......... .......... .......... .......... 68% 70.9M 0s\n",
            " 39300K .......... .......... .......... .......... .......... 68% 98.9M 0s\n",
            " 39350K .......... .......... .......... .......... .......... 69% 83.3M 0s\n",
            " 39400K .......... .......... .......... .......... .......... 69% 44.0M 0s\n",
            " 39450K .......... .......... .......... .......... .......... 69% 93.2M 0s\n",
            " 39500K .......... .......... .......... .......... .......... 69% 99.1M 0s\n",
            " 39550K .......... .......... .......... .......... .......... 69% 80.2M 0s\n",
            " 39600K .......... .......... .......... .......... .......... 69% 89.6M 0s\n",
            " 39650K .......... .......... .......... .......... .......... 69% 52.8M 0s\n",
            " 39700K .......... .......... .......... .......... .......... 69% 62.2M 0s\n",
            " 39750K .......... .......... .......... .......... .......... 69% 39.3M 0s\n",
            " 39800K .......... .......... .......... .......... .......... 69% 54.9M 0s\n",
            " 39850K .......... .......... .......... .......... .......... 69% 44.9M 0s\n",
            " 39900K .......... .......... .......... .......... .......... 69% 45.0M 0s\n",
            " 39950K .......... .......... .......... .......... .......... 70% 18.0M 0s\n",
            " 40000K .......... .......... .......... .......... .......... 70% 53.0M 0s\n",
            " 40050K .......... .......... .......... .......... .......... 70% 72.3M 0s\n",
            " 40100K .......... .......... .......... .......... .......... 70% 70.0M 0s\n",
            " 40150K .......... .......... .......... .......... .......... 70% 46.7M 0s\n",
            " 40200K .......... .......... .......... .......... .......... 70% 66.7M 0s\n",
            " 40250K .......... .......... .......... .......... .......... 70% 74.9M 0s\n",
            " 40300K .......... .......... .......... .......... .......... 70% 75.5M 0s\n",
            " 40350K .......... .......... .......... .......... .......... 70% 63.4M 0s\n",
            " 40400K .......... .......... .......... .......... .......... 70% 71.6M 0s\n",
            " 40450K .......... .......... .......... .......... .......... 70% 31.6M 0s\n",
            " 40500K .......... .......... .......... .......... .......... 71% 64.5M 0s\n",
            " 40550K .......... .......... .......... .......... .......... 71% 63.2M 0s\n",
            " 40600K .......... .......... .......... .......... .......... 71% 71.8M 0s\n",
            " 40650K .......... .......... .......... .......... .......... 71% 74.0M 0s\n",
            " 40700K .......... .......... .......... .......... .......... 71% 66.5M 0s\n",
            " 40750K .......... .......... .......... .......... .......... 71% 61.6M 0s\n",
            " 40800K .......... .......... .......... .......... .......... 71% 53.0M 0s\n",
            " 40850K .......... .......... .......... .......... .......... 71% 53.0M 0s\n",
            " 40900K .......... .......... .......... .......... .......... 71% 84.9M 0s\n",
            " 40950K .......... .......... .......... .......... .......... 71% 41.5M 0s\n",
            " 41000K .......... .......... .......... .......... .......... 71% 96.6M 0s\n",
            " 41050K .......... .......... .......... .......... .......... 71% 96.2M 0s\n",
            " 41100K .......... .......... .......... .......... .......... 72% 92.9M 0s\n",
            " 41150K .......... .......... .......... .......... .......... 72% 76.8M 0s\n",
            " 41200K .......... .......... .......... .......... .......... 72% 86.7M 0s\n",
            " 41250K .......... .......... .......... .......... .......... 72% 87.7M 0s\n",
            " 41300K .......... .......... .......... .......... .......... 72% 90.5M 0s\n",
            " 41350K .......... .......... .......... .......... .......... 72% 83.1M 0s\n",
            " 41400K .......... .......... .......... .......... .......... 72% 51.5M 0s\n",
            " 41450K .......... .......... .......... .......... .......... 72% 30.6M 0s\n",
            " 41500K .......... .......... .......... .......... .......... 72% 57.1M 0s\n",
            " 41550K .......... .......... .......... .......... .......... 72% 73.1M 0s\n",
            " 41600K .......... .......... .......... .......... .......... 72% 87.1M 0s\n",
            " 41650K .......... .......... .......... .......... .......... 73% 95.9M 0s\n",
            " 41700K .......... .......... .......... .......... .......... 73% 85.0M 0s\n",
            " 41750K .......... .......... .......... .......... .......... 73% 77.1M 0s\n",
            " 41800K .......... .......... .......... .......... .......... 73% 87.0M 0s\n",
            " 41850K .......... .......... .......... .......... .......... 73% 93.6M 0s\n",
            " 41900K .......... .......... .......... .......... .......... 73% 89.3M 0s\n",
            " 41950K .......... .......... .......... .......... .......... 73% 38.6M 0s\n",
            " 42000K .......... .......... .......... .......... .......... 73% 81.0M 0s\n",
            " 42050K .......... .......... .......... .......... .......... 73% 89.1M 0s\n",
            " 42100K .......... .......... .......... .......... .......... 73% 91.6M 0s\n",
            " 42150K .......... .......... .......... .......... .......... 73% 47.6M 0s\n",
            " 42200K .......... .......... .......... .......... .......... 73% 53.0M 0s\n",
            " 42250K .......... .......... .......... .......... .......... 74% 38.6M 0s\n",
            " 42300K .......... .......... .......... .......... .......... 74% 75.8M 0s\n",
            " 42350K .......... .......... .......... .......... .......... 74% 80.7M 0s\n",
            " 42400K .......... .......... .......... .......... .......... 74% 95.2M 0s\n",
            " 42450K .......... .......... .......... .......... .......... 74% 87.6M 0s\n",
            " 42500K .......... .......... .......... .......... .......... 74% 41.0M 0s\n",
            " 42550K .......... .......... .......... .......... .......... 74% 76.5M 0s\n",
            " 42600K .......... .......... .......... .......... .......... 74% 59.2M 0s\n",
            " 42650K .......... .......... .......... .......... .......... 74% 54.1M 0s\n",
            " 42700K .......... .......... .......... .......... .......... 74% 54.2M 0s\n",
            " 42750K .......... .......... .......... .......... .......... 74% 70.9M 0s\n",
            " 42800K .......... .......... .......... .......... .......... 75% 83.7M 0s\n",
            " 42850K .......... .......... .......... .......... .......... 75% 85.4M 0s\n",
            " 42900K .......... .......... .......... .......... .......... 75% 87.8M 0s\n",
            " 42950K .......... .......... .......... .......... .......... 75% 67.3M 0s\n",
            " 43000K .......... .......... .......... .......... .......... 75% 39.2M 0s\n",
            " 43050K .......... .......... .......... .......... .......... 75% 86.4M 0s\n",
            " 43100K .......... .......... .......... .......... .......... 75% 82.5M 0s\n",
            " 43150K .......... .......... .......... .......... .......... 75% 69.7M 0s\n",
            " 43200K .......... .......... .......... .......... .......... 75% 86.3M 0s\n",
            " 43250K .......... .......... .......... .......... .......... 75% 92.2M 0s\n",
            " 43300K .......... .......... .......... .......... .......... 75% 90.7M 0s\n",
            " 43350K .......... .......... .......... .......... .......... 76% 81.9M 0s\n",
            " 43400K .......... .......... .......... .......... .......... 76% 89.6M 0s\n",
            " 43450K .......... .......... .......... .......... .......... 76% 5.21M 0s\n",
            " 43500K .......... .......... .......... .......... .......... 76% 27.6M 0s\n",
            " 43550K .......... .......... .......... .......... .......... 76% 68.9M 0s\n",
            " 43600K .......... .......... .......... .......... .......... 76% 82.8M 0s\n",
            " 43650K .......... .......... .......... .......... .......... 76% 78.9M 0s\n",
            " 43700K .......... .......... .......... .......... .......... 76% 12.0M 0s\n",
            " 43750K .......... .......... .......... .......... .......... 76% 55.2M 0s\n",
            " 43800K .......... .......... .......... .......... .......... 76% 62.3M 0s\n",
            " 43850K .......... .......... .......... .......... .......... 76% 76.6M 0s\n",
            " 43900K .......... .......... .......... .......... .......... 76% 9.24M 0s\n",
            " 43950K .......... .......... .......... .......... .......... 77% 33.3M 0s\n",
            " 44000K .......... .......... .......... .......... .......... 77% 29.1M 0s\n",
            " 44050K .......... .......... .......... .......... .......... 77% 51.3M 0s\n",
            " 44100K .......... .......... .......... .......... .......... 77% 83.4M 0s\n",
            " 44150K .......... .......... .......... .......... .......... 77% 70.3M 0s\n",
            " 44200K .......... .......... .......... .......... .......... 77% 85.5M 0s\n",
            " 44250K .......... .......... .......... .......... .......... 77% 68.7M 0s\n",
            " 44300K .......... .......... .......... .......... .......... 77% 78.8M 0s\n",
            " 44350K .......... .......... .......... .......... .......... 77% 46.9M 0s\n",
            " 44400K .......... .......... .......... .......... .......... 77% 43.4M 0s\n",
            " 44450K .......... .......... .......... .......... .......... 77% 82.0M 0s\n",
            " 44500K .......... .......... .......... .......... .......... 78% 51.4M 0s\n",
            " 44550K .......... .......... .......... .......... .......... 78% 23.3M 0s\n",
            " 44600K .......... .......... .......... .......... .......... 78% 46.6M 0s\n",
            " 44650K .......... .......... .......... .......... .......... 78% 45.4M 0s\n",
            " 44700K .......... .......... .......... .......... .......... 78% 42.8M 0s\n",
            " 44750K .......... .......... .......... .......... .......... 78% 40.2M 0s\n",
            " 44800K .......... .......... .......... .......... .......... 78% 36.3M 0s\n",
            " 44850K .......... .......... .......... .......... .......... 78% 49.2M 0s\n",
            " 44900K .......... .......... .......... .......... .......... 78% 49.5M 0s\n",
            " 44950K .......... .......... .......... .......... .......... 78% 61.9M 0s\n",
            " 45000K .......... .......... .......... .......... .......... 78% 63.0M 0s\n",
            " 45050K .......... .......... .......... .......... .......... 78% 28.3M 0s\n",
            " 45100K .......... .......... .......... .......... .......... 79% 57.4M 0s\n",
            " 45150K .......... .......... .......... .......... .......... 79% 42.5M 0s\n",
            " 45200K .......... .......... .......... .......... .......... 79% 55.8M 0s\n",
            " 45250K .......... .......... .......... .......... .......... 79% 63.5M 0s\n",
            " 45300K .......... .......... .......... .......... .......... 79% 48.9M 0s\n",
            " 45350K .......... .......... .......... .......... .......... 79% 58.8M 0s\n",
            " 45400K .......... .......... .......... .......... .......... 79% 65.6M 0s\n",
            " 45450K .......... .......... .......... .......... .......... 79% 61.3M 0s\n",
            " 45500K .......... .......... .......... .......... .......... 79% 45.4M 0s\n",
            " 45550K .......... .......... .......... .......... .......... 79% 22.7M 0s\n",
            " 45600K .......... .......... .......... .......... .......... 79% 45.3M 0s\n",
            " 45650K .......... .......... .......... .......... .......... 80% 46.7M 0s\n",
            " 45700K .......... .......... .......... .......... .......... 80% 44.4M 0s\n",
            " 45750K .......... .......... .......... .......... .......... 80% 27.4M 0s\n",
            " 45800K .......... .......... .......... .......... .......... 80% 47.5M 0s\n",
            " 45850K .......... .......... .......... .......... .......... 80% 44.5M 0s\n",
            " 45900K .......... .......... .......... .......... .......... 80% 44.2M 0s\n",
            " 45950K .......... .......... .......... .......... .......... 80% 33.5M 0s\n",
            " 46000K .......... .......... .......... .......... .......... 80% 47.6M 0s\n",
            " 46050K .......... .......... .......... .......... .......... 80% 24.6M 0s\n",
            " 46100K .......... .......... .......... .......... .......... 80% 41.9M 0s\n",
            " 46150K .......... .......... .......... .......... .......... 80% 43.7M 0s\n",
            " 46200K .......... .......... .......... .......... .......... 81% 63.0M 0s\n",
            " 46250K .......... .......... .......... .......... .......... 81% 77.3M 0s\n",
            " 46300K .......... .......... .......... .......... .......... 81% 61.8M 0s\n",
            " 46350K .......... .......... .......... .......... .......... 81% 53.6M 0s\n",
            " 46400K .......... .......... .......... .......... .......... 81% 83.9M 0s\n",
            " 46450K .......... .......... .......... .......... .......... 81% 62.4M 0s\n",
            " 46500K .......... .......... .......... .......... .......... 81% 79.9M 0s\n",
            " 46550K .......... .......... .......... .......... .......... 81% 57.5M 0s\n",
            " 46600K .......... .......... .......... .......... .......... 81% 36.0M 0s\n",
            " 46650K .......... .......... .......... .......... .......... 81% 57.3M 0s\n",
            " 46700K .......... .......... .......... .......... .......... 81% 55.6M 0s\n",
            " 46750K .......... .......... .......... .......... .......... 81% 18.5M 0s\n",
            " 46800K .......... .......... .......... .......... .......... 82% 41.3M 0s\n",
            " 46850K .......... .......... .......... .......... .......... 82% 33.2M 0s\n",
            " 46900K .......... .......... .......... .......... .......... 82% 80.1M 0s\n",
            " 46950K .......... .......... .......... .......... .......... 82% 34.0M 0s\n",
            " 47000K .......... .......... .......... .......... .......... 82% 21.4M 0s\n",
            " 47050K .......... .......... .......... .......... .......... 82% 87.0M 0s\n",
            " 47100K .......... .......... .......... .......... .......... 82% 33.6M 0s\n",
            " 47150K .......... .......... .......... .......... .......... 82% 55.1M 0s\n",
            " 47200K .......... .......... .......... .......... .......... 82% 78.1M 0s\n",
            " 47250K .......... .......... .......... .......... .......... 82% 79.7M 0s\n",
            " 47300K .......... .......... .......... .......... .......... 82% 57.3M 0s\n",
            " 47350K .......... .......... .......... .......... .......... 83% 53.8M 0s\n",
            " 47400K .......... .......... .......... .......... .......... 83% 83.8M 0s\n",
            " 47450K .......... .......... .......... .......... .......... 83% 59.4M 0s\n",
            " 47500K .......... .......... .......... .......... .......... 83% 76.6M 0s\n",
            " 47550K .......... .......... .......... .......... .......... 83% 53.9M 0s\n",
            " 47600K .......... .......... .......... .......... .......... 83% 37.2M 0s\n",
            " 47650K .......... .......... .......... .......... .......... 83% 50.7M 0s\n",
            " 47700K .......... .......... .......... .......... .......... 83% 73.2M 0s\n",
            " 47750K .......... .......... .......... .......... .......... 83% 48.0M 0s\n",
            " 47800K .......... .......... .......... .......... .......... 83% 61.2M 0s\n",
            " 47850K .......... .......... .......... .......... .......... 83% 82.1M 0s\n",
            " 47900K .......... .......... .......... .......... .......... 83% 52.8M 0s\n",
            " 47950K .......... .......... .......... .......... .......... 84% 69.2M 0s\n",
            " 48000K .......... .......... .......... .......... .......... 84% 51.7M 0s\n",
            " 48050K .......... .......... .......... .......... .......... 84% 78.6M 0s\n",
            " 48100K .......... .......... .......... .......... .......... 84% 35.8M 0s\n",
            " 48150K .......... .......... .......... .......... .......... 84% 63.5M 0s\n",
            " 48200K .......... .......... .......... .......... .......... 84% 78.5M 0s\n",
            " 48250K .......... .......... .......... .......... .......... 84% 49.4M 0s\n",
            " 48300K .......... .......... .......... .......... .......... 84% 79.1M 0s\n",
            " 48350K .......... .......... .......... .......... .......... 84% 45.0M 0s\n",
            " 48400K .......... .......... .......... .......... .......... 84% 79.1M 0s\n",
            " 48450K .......... .......... .......... .......... .......... 84% 60.9M 0s\n",
            " 48500K .......... .......... .......... .......... .......... 85% 54.3M 0s\n",
            " 48550K .......... .......... .......... .......... .......... 85% 47.1M 0s\n",
            " 48600K .......... .......... .......... .......... .......... 85% 75.0M 0s\n",
            " 48650K .......... .......... .......... .......... .......... 85% 32.9M 0s\n",
            " 48700K .......... .......... .......... .......... .......... 85% 55.0M 0s\n",
            " 48750K .......... .......... .......... .......... .......... 85% 50.2M 0s\n",
            " 48800K .......... .......... .......... .......... .......... 85% 53.0M 0s\n",
            " 48850K .......... .......... .......... .......... .......... 85% 73.7M 0s\n",
            " 48900K .......... .......... .......... .......... .......... 85% 48.6M 0s\n",
            " 48950K .......... .......... .......... .......... .......... 85% 68.9M 0s\n",
            " 49000K .......... .......... .......... .......... .......... 85% 59.0M 0s\n",
            " 49050K .......... .......... .......... .......... .......... 85% 82.6M 0s\n",
            " 49100K .......... .......... .......... .......... .......... 86% 82.6M 0s\n",
            " 49150K .......... .......... .......... .......... .......... 86% 29.8M 0s\n",
            " 49200K .......... .......... .......... .......... .......... 86% 65.0M 0s\n",
            " 49250K .......... .......... .......... .......... .......... 86% 46.5M 0s\n",
            " 49300K .......... .......... .......... .......... .......... 86% 82.9M 0s\n",
            " 49350K .......... .......... .......... .......... .......... 86% 56.3M 0s\n",
            " 49400K .......... .......... .......... .......... .......... 86% 57.2M 0s\n",
            " 49450K .......... .......... .......... .......... .......... 86% 60.6M 0s\n",
            " 49500K .......... .......... .......... .......... .......... 86% 58.6M 0s\n",
            " 49550K .......... .......... .......... .......... .......... 86% 47.8M 0s\n",
            " 49600K .......... .......... .......... .......... .......... 86% 56.4M 0s\n",
            " 49650K .......... .......... .......... .......... .......... 87% 30.2M 0s\n",
            " 49700K .......... .......... .......... .......... .......... 87% 64.4M 0s\n",
            " 49750K .......... .......... .......... .......... .......... 87% 54.0M 0s\n",
            " 49800K .......... .......... .......... .......... .......... 87% 52.1M 0s\n",
            " 49850K .......... .......... .......... .......... .......... 87% 68.7M 0s\n",
            " 49900K .......... .......... .......... .......... .......... 87% 53.0M 0s\n",
            " 49950K .......... .......... .......... .......... .......... 87% 58.7M 0s\n",
            " 50000K .......... .......... .......... .......... .......... 87% 40.7M 0s\n",
            " 50050K .......... .......... .......... .......... .......... 87% 79.1M 0s\n",
            " 50100K .......... .......... .......... .......... .......... 87% 64.4M 0s\n",
            " 50150K .......... .......... .......... .......... .......... 87% 36.8M 0s\n",
            " 50200K .......... .......... .......... .......... .......... 88% 44.3M 0s\n",
            " 50250K .......... .......... .......... .......... .......... 88% 81.3M 0s\n",
            " 50300K .......... .......... .......... .......... .......... 88% 86.8M 0s\n",
            " 50350K .......... .......... .......... .......... .......... 88% 55.4M 0s\n",
            " 50400K .......... .......... .......... .......... .......... 88% 70.0M 0s\n",
            " 50450K .......... .......... .......... .......... .......... 88% 46.0M 0s\n",
            " 50500K .......... .......... .......... .......... .......... 88% 86.0M 0s\n",
            " 50550K .......... .......... .......... .......... .......... 88% 69.9M 0s\n",
            " 50600K .......... .......... .......... .......... .......... 88% 51.2M 0s\n",
            " 50650K .......... .......... .......... .......... .......... 88% 80.4M 0s\n",
            " 50700K .......... .......... .......... .......... .......... 88% 35.0M 0s\n",
            " 50750K .......... .......... .......... .......... .......... 88% 67.8M 0s\n",
            " 50800K .......... .......... .......... .......... .......... 89% 53.1M 0s\n",
            " 50850K .......... .......... .......... .......... .......... 89% 68.0M 0s\n",
            " 50900K .......... .......... .......... .......... .......... 89% 58.3M 0s\n",
            " 50950K .......... .......... .......... .......... .......... 89% 53.9M 0s\n",
            " 51000K .......... .......... .......... .......... .......... 89% 73.9M 0s\n",
            " 51050K .......... .......... .......... .......... .......... 89% 43.3M 0s\n",
            " 51100K .......... .......... .......... .......... .......... 89% 55.2M 0s\n",
            " 51150K .......... .......... .......... .......... .......... 89% 61.5M 0s\n",
            " 51200K .......... .......... .......... .......... .......... 89% 31.4M 0s\n",
            " 51250K .......... .......... .......... .......... .......... 89% 42.6M 0s\n",
            " 51300K .......... .......... .......... .......... .......... 89% 56.0M 0s\n",
            " 51350K .......... .......... .......... .......... .......... 90% 55.9M 0s\n",
            " 51400K .......... .......... .......... .......... .......... 90% 76.9M 0s\n",
            " 51450K .......... .......... .......... .......... .......... 90% 83.1M 0s\n",
            " 51500K .......... .......... .......... .......... .......... 90% 80.7M 0s\n",
            " 51550K .......... .......... .......... .......... .......... 90% 70.0M 0s\n",
            " 51600K .......... .......... .......... .......... .......... 90% 85.5M 0s\n",
            " 51650K .......... .......... .......... .......... .......... 90% 78.4M 0s\n",
            " 51700K .......... .......... .......... .......... .......... 90% 38.3M 0s\n",
            " 51750K .......... .......... .......... .......... .......... 90% 65.7M 0s\n",
            " 51800K .......... .......... .......... .......... .......... 90% 86.1M 0s\n",
            " 51850K .......... .......... .......... .......... .......... 90% 75.4M 0s\n",
            " 51900K .......... .......... .......... .......... .......... 90% 74.4M 0s\n",
            " 51950K .......... .......... .......... .......... .......... 91% 66.1M 0s\n",
            " 52000K .......... .......... .......... .......... .......... 91% 79.3M 0s\n",
            " 52050K .......... .......... .......... .......... .......... 91% 77.6M 0s\n",
            " 52100K .......... .......... .......... .......... .......... 91% 79.5M 0s\n",
            " 52150K .......... .......... .......... .......... .......... 91% 72.0M 0s\n",
            " 52200K .......... .......... .......... .......... .......... 91% 36.6M 0s\n",
            " 52250K .......... .......... .......... .......... .......... 91% 18.0M 0s\n",
            " 52300K .......... .......... .......... .......... .......... 91% 40.4M 0s\n",
            " 52350K .......... .......... .......... .......... .......... 91% 32.5M 0s\n",
            " 52400K .......... .......... .......... .......... .......... 91% 21.8M 0s\n",
            " 52450K .......... .......... .......... .......... .......... 91% 50.7M 0s\n",
            " 52500K .......... .......... .......... .......... .......... 92% 51.0M 0s\n",
            " 52550K .......... .......... .......... .......... .......... 92% 54.2M 0s\n",
            " 52600K .......... .......... .......... .......... .......... 92% 58.1M 0s\n",
            " 52650K .......... .......... .......... .......... .......... 92% 51.5M 0s\n",
            " 52700K .......... .......... .......... .......... .......... 92% 54.4M 0s\n",
            " 52750K .......... .......... .......... .......... .......... 92% 23.9M 0s\n",
            " 52800K .......... .......... .......... .......... .......... 92% 63.5M 0s\n",
            " 52850K .......... .......... .......... .......... .......... 92% 61.3M 0s\n",
            " 52900K .......... .......... .......... .......... .......... 92% 55.4M 0s\n",
            " 52950K .......... .......... .......... .......... .......... 92% 61.4M 0s\n",
            " 53000K .......... .......... .......... .......... .......... 92% 55.4M 0s\n",
            " 53050K .......... .......... .......... .......... .......... 92% 67.8M 0s\n",
            " 53100K .......... .......... .......... .......... .......... 93% 58.9M 0s\n",
            " 53150K .......... .......... .......... .......... .......... 93% 58.0M 0s\n",
            " 53200K .......... .......... .......... .......... .......... 93% 49.2M 0s\n",
            " 53250K .......... .......... .......... .......... .......... 93% 26.0M 0s\n",
            " 53300K .......... .......... .......... .......... .......... 93% 70.3M 0s\n",
            " 53350K .......... .......... .......... .......... .......... 93% 22.5M 0s\n",
            " 53400K .......... .......... .......... .......... .......... 93% 47.5M 0s\n",
            " 53450K .......... .......... .......... .......... .......... 93% 78.5M 0s\n",
            " 53500K .......... .......... .......... .......... .......... 93% 62.7M 0s\n",
            " 53550K .......... .......... .......... .......... .......... 93% 58.4M 0s\n",
            " 53600K .......... .......... .......... .......... .......... 93% 49.6M 0s\n",
            " 53650K .......... .......... .......... .......... .......... 94% 51.2M 0s\n",
            " 53700K .......... .......... .......... .......... .......... 94% 51.0M 0s\n",
            " 53750K .......... .......... .......... .......... .......... 94% 28.7M 0s\n",
            " 53800K .......... .......... .......... .......... .......... 94% 54.8M 0s\n",
            " 53850K .......... .......... .......... .......... .......... 94% 71.0M 0s\n",
            " 53900K .......... .......... .......... .......... .......... 94% 66.0M 0s\n",
            " 53950K .......... .......... .......... .......... .......... 94% 58.4M 0s\n",
            " 54000K .......... .......... .......... .......... .......... 94% 70.1M 0s\n",
            " 54050K .......... .......... .......... .......... .......... 94% 71.2M 0s\n",
            " 54100K .......... .......... .......... .......... .......... 94% 74.9M 0s\n",
            " 54150K .......... .......... .......... .......... .......... 94% 67.2M 0s\n",
            " 54200K .......... .......... .......... .......... .......... 95% 24.1M 0s\n",
            " 54250K .......... .......... .......... .......... .......... 95% 37.1M 0s\n",
            " 54300K .......... .......... .......... .......... .......... 95% 76.9M 0s\n",
            " 54350K .......... .......... .......... .......... .......... 95% 61.5M 0s\n",
            " 54400K .......... .......... .......... .......... .......... 95% 74.1M 0s\n",
            " 54450K .......... .......... .......... .......... .......... 95% 73.7M 0s\n",
            " 54500K .......... .......... .......... .......... .......... 95% 76.7M 0s\n",
            " 54550K .......... .......... .......... .......... .......... 95% 67.8M 0s\n",
            " 54600K .......... .......... .......... .......... .......... 95% 58.6M 0s\n",
            " 54650K .......... .......... .......... .......... .......... 95% 71.1M 0s\n",
            " 54700K .......... .......... .......... .......... .......... 95% 75.3M 0s\n",
            " 54750K .......... .......... .......... .......... .......... 95% 35.9M 0s\n",
            " 54800K .......... .......... .......... .......... .......... 96% 67.3M 0s\n",
            " 54850K .......... .......... .......... .......... .......... 96% 36.7M 0s\n",
            " 54900K .......... .......... .......... .......... .......... 96% 81.3M 0s\n",
            " 54950K .......... .......... .......... .......... .......... 96% 71.2M 0s\n",
            " 55000K .......... .......... .......... .......... .......... 96% 75.4M 0s\n",
            " 55050K .......... .......... .......... .......... .......... 96% 75.9M 0s\n",
            " 55100K .......... .......... .......... .......... .......... 96% 74.8M 0s\n",
            " 55150K .......... .......... .......... .......... .......... 96% 63.3M 0s\n",
            " 55200K .......... .......... .......... .......... .......... 96% 76.1M 0s\n",
            " 55250K .......... .......... .......... .......... .......... 96% 74.3M 0s\n",
            " 55300K .......... .......... .......... .......... .......... 96% 34.5M 0s\n",
            " 55350K .......... .......... .......... .......... .......... 97% 56.6M 0s\n",
            " 55400K .......... .......... .......... .......... .......... 97% 67.9M 0s\n",
            " 55450K .......... .......... .......... .......... .......... 97% 82.3M 0s\n",
            " 55500K .......... .......... .......... .......... .......... 97% 67.5M 0s\n",
            " 55550K .......... .......... .......... .......... .......... 97% 18.9M 0s\n",
            " 55600K .......... .......... .......... .......... .......... 97% 79.8M 0s\n",
            " 55650K .......... .......... .......... .......... .......... 97% 78.9M 0s\n",
            " 55700K .......... .......... .......... .......... .......... 97% 77.5M 0s\n",
            " 55750K .......... .......... .......... .......... .......... 97% 68.6M 0s\n",
            " 55800K .......... .......... .......... .......... .......... 97% 37.8M 0s\n",
            " 55850K .......... .......... .......... .......... .......... 97% 77.3M 0s\n",
            " 55900K .......... .......... .......... .......... .......... 97% 76.5M 0s\n",
            " 55950K .......... .......... .......... .......... .......... 98% 64.9M 0s\n",
            " 56000K .......... .......... .......... .......... .......... 98% 79.2M 0s\n",
            " 56050K .......... .......... .......... .......... .......... 98% 77.3M 0s\n",
            " 56100K .......... .......... .......... .......... .......... 98% 77.8M 0s\n",
            " 56150K .......... .......... .......... .......... .......... 98% 68.3M 0s\n",
            " 56200K .......... .......... .......... .......... .......... 98% 87.2M 0s\n",
            " 56250K .......... .......... .......... .......... .......... 98% 85.1M 0s\n",
            " 56300K .......... .......... .......... .......... .......... 98% 38.7M 0s\n",
            " 56350K .......... .......... .......... .......... .......... 98% 67.0M 0s\n",
            " 56400K .......... .......... .......... .......... .......... 98% 76.3M 0s\n",
            " 56450K .......... .......... .......... .......... .......... 98% 75.5M 0s\n",
            " 56500K .......... .......... .......... .......... .......... 99% 67.5M 0s\n",
            " 56550K .......... .......... .......... .......... .......... 99% 66.5M 0s\n",
            " 56600K .......... .......... .......... .......... .......... 99% 71.0M 0s\n",
            " 56650K .......... .......... .......... .......... .......... 99% 68.0M 0s\n",
            " 56700K .......... .......... .......... .......... .......... 99% 70.9M 0s\n",
            " 56750K .......... .......... .......... .......... .......... 99% 69.6M 0s\n",
            " 56800K .......... .......... .......... .......... .......... 99% 44.3M 0s\n",
            " 56850K .......... .......... .......... .......... .......... 99% 70.2M 0s\n",
            " 56900K .......... .......... .......... .......... .......... 99% 76.1M 0s\n",
            " 56950K .......... .......... .......... .......... .......... 99% 57.3M 0s\n",
            " 57000K .......... .......... .......... .......... .......... 99% 76.4M 0s\n",
            " 57050K .......... .......... .......... .......... ........  100% 80.0M=1.1s\n",
            "\n",
            "2021-06-14 15:18:01 (50.7 MB/s) - ‘Miniconda3-4.5.4-Linux-x86_64.sh.3’ saved [58468498/58468498]\n",
            "\n",
            "Python 3.6.5 :: Anaconda, Inc.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSA0UkjqX5Qi",
        "outputId": "563f7596-a982-4f8c-d4b1-11a0c9861c96"
      },
      "source": [
        "%%bash\n",
        "conda install --channel defaults conda python=3.6 --yes\n",
        "conda update --channel defaults --all --yes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - conda\n",
            "    - python=3.6\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ca-certificates-2021.5.25  |       h06a4308_1         118 KB\n",
            "    certifi-2021.5.30          |   py36h06a4308_0         141 KB\n",
            "    yaml-0.2.5                 |       h7b6447c_0          87 KB\n",
            "    python-3.6.13              |       h12debd9_1        32.5 MB\n",
            "    openssl-1.1.1k             |       h27cfd23_0         3.8 MB\n",
            "    chardet-4.0.0              |py36h06a4308_1003         213 KB\n",
            "    wheel-0.36.2               |     pyhd3eb1b0_0          31 KB\n",
            "    urllib3-1.26.4             |     pyhd3eb1b0_0          99 KB\n",
            "    pip-21.1.2                 |   py36h06a4308_0         2.1 MB\n",
            "    ld_impl_linux-64-2.35.1    |       h7274673_9         637 KB\n",
            "    libgomp-9.3.0              |      h5101ec6_17         378 KB\n",
            "    pycosat-0.6.3              |   py36h27cfd23_0         107 KB\n",
            "    libgcc-ng-9.3.0            |      h5101ec6_17         7.8 MB\n",
            "    pycparser-2.20             |             py_2          94 KB\n",
            "    cryptography-3.4.7         |   py36hd23ed53_0         1.0 MB\n",
            "    pyopenssl-20.0.1           |     pyhd3eb1b0_1          48 KB\n",
            "    ncurses-6.2                |       he6710b0_1         1.1 MB\n",
            "    six-1.15.0                 |     pyhd3eb1b0_0          13 KB\n",
            "    libstdcxx-ng-9.3.0         |      hd4cf53a_17         4.0 MB\n",
            "    conda-4.10.1               |   py36h06a4308_1         3.1 MB\n",
            "    libffi-3.3                 |       he6710b0_2          54 KB\n",
            "    idna-2.10                  |     pyhd3eb1b0_0          52 KB\n",
            "    brotlipy-0.7.0             |py36h27cfd23_1003         349 KB\n",
            "    _openmp_mutex-4.5          |            1_gnu          22 KB\n",
            "    tqdm-4.59.0                |     pyhd3eb1b0_1          90 KB\n",
            "    tk-8.6.10                  |       hbc83047_0         3.2 MB\n",
            "    readline-8.1               |       h27cfd23_0         464 KB\n",
            "    setuptools-52.0.0          |   py36h06a4308_0         933 KB\n",
            "    cffi-1.14.5                |   py36h261ae71_0         224 KB\n",
            "    _libgcc_mutex-0.1          |             main           3 KB\n",
            "    pysocks-1.7.1              |   py36h06a4308_0          30 KB\n",
            "    requests-2.25.1            |     pyhd3eb1b0_0          51 KB\n",
            "    conda-package-handling-1.7.3|   py36h27cfd23_1         946 KB\n",
            "    xz-5.2.5                   |       h7b6447c_0         438 KB\n",
            "    ruamel_yaml-0.15.100       |   py36h27cfd23_0         268 KB\n",
            "    sqlite-3.35.4              |       hdfb4753_0         1.4 MB\n",
            "    zlib-1.2.11                |       h7b6447c_3         120 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        65.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    _libgcc_mutex:          0.1-main               \n",
            "    _openmp_mutex:          4.5-1_gnu              \n",
            "    brotlipy:               0.7.0-py36h27cfd23_1003\n",
            "    conda-package-handling: 1.7.3-py36h27cfd23_1   \n",
            "    ld_impl_linux-64:       2.35.1-h7274673_9      \n",
            "    libgomp:                9.3.0-h5101ec6_17      \n",
            "    tqdm:                   4.59.0-pyhd3eb1b0_1    \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    ca-certificates:        2018.03.07-0            --> 2021.5.25-h06a4308_1    \n",
            "    certifi:                2018.4.16-py36_0        --> 2021.5.30-py36h06a4308_0\n",
            "    cffi:                   1.11.5-py36h9745a5d_0   --> 1.14.5-py36h261ae71_0   \n",
            "    chardet:                3.0.4-py36h0f667ec_1    --> 4.0.0-py36h06a4308_1003 \n",
            "    conda:                  4.5.4-py36_0            --> 4.10.1-py36h06a4308_1   \n",
            "    cryptography:           2.2.2-py36h14c3975_0    --> 3.4.7-py36hd23ed53_0    \n",
            "    idna:                   2.6-py36h82fb2a8_1      --> 2.10-pyhd3eb1b0_0       \n",
            "    libffi:                 3.2.1-hd88cf55_4        --> 3.3-he6710b0_2          \n",
            "    libgcc-ng:              7.2.0-hdf63c60_3        --> 9.3.0-h5101ec6_17       \n",
            "    libstdcxx-ng:           7.2.0-hdf63c60_3        --> 9.3.0-hd4cf53a_17       \n",
            "    ncurses:                6.1-hf484d3e_0          --> 6.2-he6710b0_1          \n",
            "    openssl:                1.0.2o-h20670df_0       --> 1.1.1k-h27cfd23_0       \n",
            "    pip:                    10.0.1-py36_0           --> 21.1.2-py36h06a4308_0   \n",
            "    pycosat:                0.6.3-py36h0a5515d_0    --> 0.6.3-py36h27cfd23_0    \n",
            "    pycparser:              2.18-py36hf9f622e_1     --> 2.20-py_2               \n",
            "    pyopenssl:              18.0.0-py36_0           --> 20.0.1-pyhd3eb1b0_1     \n",
            "    pysocks:                1.6.8-py36_0            --> 1.7.1-py36h06a4308_0    \n",
            "    python:                 3.6.5-hc3d631a_2        --> 3.6.13-h12debd9_1       \n",
            "    readline:               7.0-ha6073c6_4          --> 8.1-h27cfd23_0          \n",
            "    requests:               2.18.4-py36he2e5f8d_1   --> 2.25.1-pyhd3eb1b0_0     \n",
            "    ruamel_yaml:            0.15.37-py36h14c3975_2  --> 0.15.100-py36h27cfd23_0 \n",
            "    setuptools:             39.2.0-py36_0           --> 52.0.0-py36h06a4308_0   \n",
            "    six:                    1.11.0-py36h372c433_1   --> 1.15.0-pyhd3eb1b0_0     \n",
            "    sqlite:                 3.23.1-he433501_0       --> 3.35.4-hdfb4753_0       \n",
            "    tk:                     8.6.7-hc745277_3        --> 8.6.10-hbc83047_0       \n",
            "    urllib3:                1.22-py36hbe7ace6_0     --> 1.26.4-pyhd3eb1b0_0     \n",
            "    wheel:                  0.31.1-py36_0           --> 0.36.2-pyhd3eb1b0_0     \n",
            "    xz:                     5.2.4-h14c3975_4        --> 5.2.5-h7b6447c_0        \n",
            "    yaml:                   0.1.7-had09818_2        --> 0.2.5-h7b6447c_0        \n",
            "    zlib:                   1.2.11-ha838bed_2       --> 1.2.11-h7b6447c_3       \n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    six-1.15.0                 |   py36h06a4308_0          27 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:          27 KB\n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  asn1crypto-0.24.0-py36_0\n",
            "  conda-env-2.6.0-h36134e3_1\n",
            "  libedit-3.1.20170329-h6b74fdf_2\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  six                pkgs/main/noarch::six-1.15.0-pyhd3eb1~ --> pkgs/main/linux-64::six-1.15.0-py36h06a4308_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\rsix-1.15.0           | 27 KB     |            |   0% \rsix-1.15.0           | 27 KB     | ########## | 100% \n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rca-certificates-2021 |  118 KB |            |   0% \rca-certificates-2021 |  118 KB | ########## | 100% \n",
            "\rcertifi-2021.5.30    |  141 KB |            |   0% \rcertifi-2021.5.30    |  141 KB | ########## | 100% \n",
            "\ryaml-0.2.5           |   87 KB |            |   0% \ryaml-0.2.5           |   87 KB | ########## | 100% \n",
            "\rpython-3.6.13        | 32.5 MB |            |   0% \rpython-3.6.13        | 32.5 MB | ##9        |  30% \rpython-3.6.13        | 32.5 MB | ######6    |  66% \rpython-3.6.13        | 32.5 MB | ########3  |  84% \rpython-3.6.13        | 32.5 MB | #########5 |  96% \rpython-3.6.13        | 32.5 MB | ########## | 100% \n",
            "\ropenssl-1.1.1k       |  3.8 MB |            |   0% \ropenssl-1.1.1k       |  3.8 MB | #######6   |  76% \ropenssl-1.1.1k       |  3.8 MB | #########9 |  99% \ropenssl-1.1.1k       |  3.8 MB | ########## | 100% \n",
            "\rchardet-4.0.0        |  213 KB |            |   0% \rchardet-4.0.0        |  213 KB | ########## | 100% \n",
            "\rwheel-0.36.2         |   31 KB |            |   0% \rwheel-0.36.2         |   31 KB | ########## | 100% \n",
            "\rurllib3-1.26.4       |   99 KB |            |   0% \rurllib3-1.26.4       |   99 KB | ########## | 100% \n",
            "\rpip-21.1.2           |  2.1 MB |            |   0% \rpip-21.1.2           |  2.1 MB | #######7   |  78% \rpip-21.1.2           |  2.1 MB | #########3 |  94% \rpip-21.1.2           |  2.1 MB | ########## | 100% \n",
            "\rld_impl_linux-64-2.3 |  637 KB |            |   0% \rld_impl_linux-64-2.3 |  637 KB | #########5 |  95% \rld_impl_linux-64-2.3 |  637 KB | ########## | 100% \n",
            "\rlibgomp-9.3.0        |  378 KB |            |   0% \rlibgomp-9.3.0        |  378 KB | ########## | 100% \n",
            "\rpycosat-0.6.3        |  107 KB |            |   0% \rpycosat-0.6.3        |  107 KB | ########## | 100% \n",
            "\rlibgcc-ng-9.3.0      |  7.8 MB |            |   0% \rlibgcc-ng-9.3.0      |  7.8 MB | #######5   |  75% \rlibgcc-ng-9.3.0      |  7.8 MB | #########7 |  98% \rlibgcc-ng-9.3.0      |  7.8 MB | ########## | 100% \n",
            "\rpycparser-2.20       |   94 KB |            |   0% \rpycparser-2.20       |   94 KB | ########## | 100% \n",
            "\rcryptography-3.4.7   |  1.0 MB |            |   0% \rcryptography-3.4.7   |  1.0 MB | #######9   |  80% \rcryptography-3.4.7   |  1.0 MB | ########## | 100% \n",
            "\rpyopenssl-20.0.1     |   48 KB |            |   0% \rpyopenssl-20.0.1     |   48 KB | ########## | 100% \n",
            "\rncurses-6.2          |  1.1 MB |            |   0% \rncurses-6.2          |  1.1 MB | ########1  |  81% \rncurses-6.2          |  1.1 MB | ########## | 100% \n",
            "\rsix-1.15.0           |   13 KB |            |   0% \rsix-1.15.0           |   13 KB | ########## | 100% \n",
            "\rlibstdcxx-ng-9.3.0   |  4.0 MB |            |   0% \rlibstdcxx-ng-9.3.0   |  4.0 MB | #######7   |  77% \rlibstdcxx-ng-9.3.0   |  4.0 MB | ########## | 100% \n",
            "\rconda-4.10.1         |  3.1 MB |            |   0% \rconda-4.10.1         |  3.1 MB | #######6   |  77% \rconda-4.10.1         |  3.1 MB | #########  |  90% \rconda-4.10.1         |  3.1 MB | ########## | 100% \n",
            "\rlibffi-3.3           |   54 KB |            |   0% \rlibffi-3.3           |   54 KB | ########## | 100% \n",
            "\ridna-2.10            |   52 KB |            |   0% \ridna-2.10            |   52 KB | ########## | 100% \n",
            "\rbrotlipy-0.7.0       |  349 KB |            |   0% \rbrotlipy-0.7.0       |  349 KB | ########## | 100% \n",
            "\r_openmp_mutex-4.5    |   22 KB |            |   0% \r_openmp_mutex-4.5    |   22 KB | ########## | 100% \n",
            "\rtqdm-4.59.0          |   90 KB |            |   0% \rtqdm-4.59.0          |   90 KB | ########## | 100% \n",
            "\rtk-8.6.10            |  3.2 MB |            |   0% \rtk-8.6.10            |  3.2 MB | #######7   |  78% \rtk-8.6.10            |  3.2 MB | ########## | 100% \n",
            "\rreadline-8.1         |  464 KB |            |   0% \rreadline-8.1         |  464 KB | ########## | 100% \n",
            "\rsetuptools-52.0.0    |  933 KB |            |   0% \rsetuptools-52.0.0    |  933 KB | ########3  |  84% \rsetuptools-52.0.0    |  933 KB | ########## | 100% \n",
            "\rcffi-1.14.5          |  224 KB |            |   0% \rcffi-1.14.5          |  224 KB | ########## | 100% \n",
            "\r_libgcc_mutex-0.1    |    3 KB |            |   0% \r_libgcc_mutex-0.1    |    3 KB | ########## | 100% \n",
            "\rpysocks-1.7.1        |   30 KB |            |   0% \rpysocks-1.7.1        |   30 KB | ########## | 100% \n",
            "\rrequests-2.25.1      |   51 KB |            |   0% \rrequests-2.25.1      |   51 KB | ########## | 100% \n",
            "\rconda-package-handli |  946 KB |            |   0% \rconda-package-handli |  946 KB | #########4 |  94% \rconda-package-handli |  946 KB | ########## | 100% \n",
            "\rxz-5.2.5             |  438 KB |            |   0% \rxz-5.2.5             |  438 KB | ########## | 100% \n",
            "\rruamel_yaml-0.15.100 |  268 KB |            |   0% \rruamel_yaml-0.15.100 |  268 KB | ########## | 100% \n",
            "\rsqlite-3.35.4        |  1.4 MB |            |   0% \rsqlite-3.35.4        |  1.4 MB | ########7  |  87% \rsqlite-3.35.4        |  1.4 MB | ########## | 100% \n",
            "\rzlib-1.2.11          |  120 KB |            |   0% \rzlib-1.2.11          |  120 KB | ########## | 100% \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFdj7T8IX_ly"
      },
      "source": [
        "import sys\n",
        "_ = (sys.path.append(\"/usr/local/lib/python3.6/site-packages\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HigwFGgOYLRn",
        "outputId": "fe4285f8-56fd-46cf-dd9c-a74d83f8b5aa"
      },
      "source": [
        "!conda install caffe-gpu --yes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - caffe-gpu\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    backcall-0.2.0             |     pyhd3eb1b0_0          13 KB\n",
            "    blas-1.0                   |              mkl           6 KB\n",
            "    boost-1.67.0               |           py36_4          11 KB\n",
            "    bzip2-1.0.8                |       h7b6447c_0          78 KB\n",
            "    caffe-gpu-1.0              |   py36h999e8d7_5         3.8 MB\n",
            "    cairo-1.16.0               |       hf32fb01_1         1.0 MB\n",
            "    cloudpickle-1.6.0          |             py_0          30 KB\n",
            "    cudatoolkit-10.0.130       |                0       261.2 MB\n",
            "    cudnn-7.6.5                |       cuda10.0_0       165.0 MB\n",
            "    cycler-0.10.0              |           py36_0          13 KB\n",
            "    cytoolz-0.11.0             |   py36h7b6447c_0         329 KB\n",
            "    dask-core-2021.3.0         |     pyhd3eb1b0_0         659 KB\n",
            "    dbus-1.13.18               |       hb2f20db_0         504 KB\n",
            "    decorator-5.0.9            |     pyhd3eb1b0_0          12 KB\n",
            "    expat-2.4.1                |       h2531618_2         168 KB\n",
            "    ffmpeg-4.0                 |       hcdf2ecd_0        53.3 MB\n",
            "    fontconfig-2.13.1          |       h6c09931_0         250 KB\n",
            "    freeglut-3.0.0             |       hf484d3e_5         176 KB\n",
            "    freetype-2.10.4            |       h5ab3b9f_0         596 KB\n",
            "    gflags-2.2.2               |       he6710b0_0         126 KB\n",
            "    glib-2.68.2                |       h36276a3_0         3.0 MB\n",
            "    glog-0.3.5                 |       hf484d3e_1         138 KB\n",
            "    graphite2-1.3.14           |       h23475e2_0          99 KB\n",
            "    gst-plugins-base-1.14.0    |       h8213a91_2         4.9 MB\n",
            "    gstreamer-1.14.0           |       h28cd5cc_2         3.2 MB\n",
            "    h5py-2.8.0                 |   py36h989c5e5_3         911 KB\n",
            "    harfbuzz-1.8.8             |       hffaf4a1_0         507 KB\n",
            "    hdf5-1.10.2                |       hba1933b_1         3.8 MB\n",
            "    icu-58.2                   |       he6710b0_3        10.5 MB\n",
            "    imageio-2.9.0              |     pyhd3eb1b0_0         3.0 MB\n",
            "    intel-openmp-2021.2.0      |     h06a4308_610         1.3 MB\n",
            "    ipython-7.16.1             |   py36h5ca1d4c_0         999 KB\n",
            "    ipython_genutils-0.2.0     |     pyhd3eb1b0_1          27 KB\n",
            "    jasper-2.0.14              |       h07fcdf6_1         707 KB\n",
            "    jedi-0.17.0                |           py36_0         780 KB\n",
            "    jpeg-9b                    |       h024ee3a_2         214 KB\n",
            "    kiwisolver-1.3.1           |   py36h2531618_0          80 KB\n",
            "    lcms2-2.12                 |       h3be6417_0         312 KB\n",
            "    leveldb-1.20               |       hf484d3e_1         253 KB\n",
            "    libboost-1.67.0            |       h46d08c1_4        13.0 MB\n",
            "    libgfortran-ng-7.5.0       |      ha8ba4b0_17          22 KB\n",
            "    libgfortran4-7.5.0         |      ha8ba4b0_17         995 KB\n",
            "    libglu-9.0.0               |       hf484d3e_1         271 KB\n",
            "    libopencv-3.4.2            |       hb342d67_1        21.8 MB\n",
            "    libopus-1.3.1              |       h7b6447c_0         491 KB\n",
            "    libpng-1.6.37              |       hbc83047_0         278 KB\n",
            "    libprotobuf-3.14.0         |       h8c45485_0         2.0 MB\n",
            "    libtiff-4.2.0              |       h85742a9_0         502 KB\n",
            "    libuuid-1.0.3              |       h1bed415_2          15 KB\n",
            "    libvpx-1.7.0               |       h439df22_0         1.2 MB\n",
            "    libwebp-base-1.2.0         |       h27cfd23_0         437 KB\n",
            "    libxcb-1.14                |       h7b6447c_0         505 KB\n",
            "    libxml2-2.9.10             |       hb55368b_3         1.2 MB\n",
            "    lmdb-0.9.29                |       h2531618_0         424 KB\n",
            "    lz4-c-1.9.3                |       h2531618_0         186 KB\n",
            "    matplotlib-3.3.4           |   py36h06a4308_0          26 KB\n",
            "    matplotlib-base-3.3.4      |   py36h62a2d02_0         5.1 MB\n",
            "    mkl-2020.2                 |              256       138.3 MB\n",
            "    mkl-service-2.3.0          |   py36he8ac12f_0          52 KB\n",
            "    mkl_fft-1.3.0              |   py36h54f3939_0         170 KB\n",
            "    mkl_random-1.1.1           |   py36h0573a6f_0         327 KB\n",
            "    networkx-2.5               |             py_0         1.1 MB\n",
            "    numpy-1.19.2               |   py36h54aff64_0          22 KB\n",
            "    numpy-base-1.19.2          |   py36hfa32c7d_0         4.1 MB\n",
            "    olefile-0.46               |           py36_0          48 KB\n",
            "    pandas-1.1.5               |   py36ha9443f7_0         8.2 MB\n",
            "    parso-0.8.2                |     pyhd3eb1b0_0          69 KB\n",
            "    pcre-8.44                  |       he6710b0_0         212 KB\n",
            "    pexpect-4.8.0              |     pyhd3eb1b0_3          53 KB\n",
            "    pickleshare-0.7.5          |  pyhd3eb1b0_1003          13 KB\n",
            "    pillow-8.2.0               |   py36he98fc37_0         627 KB\n",
            "    pixman-0.40.0              |       h7b6447c_0         370 KB\n",
            "    prompt-toolkit-3.0.17      |     pyh06a4308_0         256 KB\n",
            "    protobuf-3.14.0            |   py36h2531618_1         303 KB\n",
            "    ptyprocess-0.7.0           |     pyhd3eb1b0_2          17 KB\n",
            "    py-boost-1.67.0            |   py36h04863e7_4         278 KB\n",
            "    py-opencv-3.4.2            |   py36hb342d67_1         1.0 MB\n",
            "    pygments-2.9.0             |     pyhd3eb1b0_0         721 KB\n",
            "    pyparsing-2.4.7            |     pyhd3eb1b0_0          59 KB\n",
            "    pyqt-5.9.2                 |   py36h05f1152_2         4.5 MB\n",
            "    python-dateutil-2.8.1      |     pyhd3eb1b0_0         221 KB\n",
            "    python-gflags-3.1.2        |   py36h06a4308_0          70 KB\n",
            "    python-leveldb-0.201       |   py36h2531618_0          26 KB\n",
            "    pytz-2021.1                |     pyhd3eb1b0_0         181 KB\n",
            "    pywavelets-1.1.1           |   py36h7b6447c_2         3.5 MB\n",
            "    pyyaml-5.4.1               |   py36h27cfd23_1         170 KB\n",
            "    qt-5.9.7                   |       h5867ecd_1        68.5 MB\n",
            "    scikit-image-0.16.2        |   py36h0573a6f_0        23.1 MB\n",
            "    scipy-1.5.2                |   py36h0b6359f_0        14.4 MB\n",
            "    sip-4.19.8                 |   py36hf484d3e_0         274 KB\n",
            "    snappy-1.1.8               |       he6710b0_0          40 KB\n",
            "    toolz-0.11.1               |     pyhd3eb1b0_0          46 KB\n",
            "    tornado-6.1                |   py36h27cfd23_0         581 KB\n",
            "    traitlets-4.3.3            |           py36_0         140 KB\n",
            "    wcwidth-0.2.5              |             py_0          29 KB\n",
            "    zstd-1.4.9                 |       haebb681_0         480 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       842.8 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  backcall           pkgs/main/noarch::backcall-0.2.0-pyhd3eb1b0_0\n",
            "  blas               pkgs/main/linux-64::blas-1.0-mkl\n",
            "  boost              pkgs/main/linux-64::boost-1.67.0-py36_4\n",
            "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h7b6447c_0\n",
            "  caffe-gpu          pkgs/main/linux-64::caffe-gpu-1.0-py36h999e8d7_5\n",
            "  cairo              pkgs/main/linux-64::cairo-1.16.0-hf32fb01_1\n",
            "  cloudpickle        pkgs/main/noarch::cloudpickle-1.6.0-py_0\n",
            "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.0.130-0\n",
            "  cudnn              pkgs/main/linux-64::cudnn-7.6.5-cuda10.0_0\n",
            "  cycler             pkgs/main/linux-64::cycler-0.10.0-py36_0\n",
            "  cytoolz            pkgs/main/linux-64::cytoolz-0.11.0-py36h7b6447c_0\n",
            "  dask-core          pkgs/main/noarch::dask-core-2021.3.0-pyhd3eb1b0_0\n",
            "  dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0\n",
            "  decorator          pkgs/main/noarch::decorator-5.0.9-pyhd3eb1b0_0\n",
            "  expat              pkgs/main/linux-64::expat-2.4.1-h2531618_2\n",
            "  ffmpeg             pkgs/main/linux-64::ffmpeg-4.0-hcdf2ecd_0\n",
            "  fontconfig         pkgs/main/linux-64::fontconfig-2.13.1-h6c09931_0\n",
            "  freeglut           pkgs/main/linux-64::freeglut-3.0.0-hf484d3e_5\n",
            "  freetype           pkgs/main/linux-64::freetype-2.10.4-h5ab3b9f_0\n",
            "  gflags             pkgs/main/linux-64::gflags-2.2.2-he6710b0_0\n",
            "  glib               pkgs/main/linux-64::glib-2.68.2-h36276a3_0\n",
            "  glog               pkgs/main/linux-64::glog-0.3.5-hf484d3e_1\n",
            "  graphite2          pkgs/main/linux-64::graphite2-1.3.14-h23475e2_0\n",
            "  gst-plugins-base   pkgs/main/linux-64::gst-plugins-base-1.14.0-h8213a91_2\n",
            "  gstreamer          pkgs/main/linux-64::gstreamer-1.14.0-h28cd5cc_2\n",
            "  h5py               pkgs/main/linux-64::h5py-2.8.0-py36h989c5e5_3\n",
            "  harfbuzz           pkgs/main/linux-64::harfbuzz-1.8.8-hffaf4a1_0\n",
            "  hdf5               pkgs/main/linux-64::hdf5-1.10.2-hba1933b_1\n",
            "  icu                pkgs/main/linux-64::icu-58.2-he6710b0_3\n",
            "  imageio            pkgs/main/noarch::imageio-2.9.0-pyhd3eb1b0_0\n",
            "  intel-openmp       pkgs/main/linux-64::intel-openmp-2021.2.0-h06a4308_610\n",
            "  ipython            pkgs/main/linux-64::ipython-7.16.1-py36h5ca1d4c_0\n",
            "  ipython_genutils   pkgs/main/noarch::ipython_genutils-0.2.0-pyhd3eb1b0_1\n",
            "  jasper             pkgs/main/linux-64::jasper-2.0.14-h07fcdf6_1\n",
            "  jedi               pkgs/main/linux-64::jedi-0.17.0-py36_0\n",
            "  jpeg               pkgs/main/linux-64::jpeg-9b-h024ee3a_2\n",
            "  kiwisolver         pkgs/main/linux-64::kiwisolver-1.3.1-py36h2531618_0\n",
            "  lcms2              pkgs/main/linux-64::lcms2-2.12-h3be6417_0\n",
            "  leveldb            pkgs/main/linux-64::leveldb-1.20-hf484d3e_1\n",
            "  libboost           pkgs/main/linux-64::libboost-1.67.0-h46d08c1_4\n",
            "  libgfortran-ng     pkgs/main/linux-64::libgfortran-ng-7.5.0-ha8ba4b0_17\n",
            "  libgfortran4       pkgs/main/linux-64::libgfortran4-7.5.0-ha8ba4b0_17\n",
            "  libglu             pkgs/main/linux-64::libglu-9.0.0-hf484d3e_1\n",
            "  libopencv          pkgs/main/linux-64::libopencv-3.4.2-hb342d67_1\n",
            "  libopus            pkgs/main/linux-64::libopus-1.3.1-h7b6447c_0\n",
            "  libpng             pkgs/main/linux-64::libpng-1.6.37-hbc83047_0\n",
            "  libprotobuf        pkgs/main/linux-64::libprotobuf-3.14.0-h8c45485_0\n",
            "  libtiff            pkgs/main/linux-64::libtiff-4.2.0-h85742a9_0\n",
            "  libuuid            pkgs/main/linux-64::libuuid-1.0.3-h1bed415_2\n",
            "  libvpx             pkgs/main/linux-64::libvpx-1.7.0-h439df22_0\n",
            "  libwebp-base       pkgs/main/linux-64::libwebp-base-1.2.0-h27cfd23_0\n",
            "  libxcb             pkgs/main/linux-64::libxcb-1.14-h7b6447c_0\n",
            "  libxml2            pkgs/main/linux-64::libxml2-2.9.10-hb55368b_3\n",
            "  lmdb               pkgs/main/linux-64::lmdb-0.9.29-h2531618_0\n",
            "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.3-h2531618_0\n",
            "  matplotlib         pkgs/main/linux-64::matplotlib-3.3.4-py36h06a4308_0\n",
            "  matplotlib-base    pkgs/main/linux-64::matplotlib-base-3.3.4-py36h62a2d02_0\n",
            "  mkl                pkgs/main/linux-64::mkl-2020.2-256\n",
            "  mkl-service        pkgs/main/linux-64::mkl-service-2.3.0-py36he8ac12f_0\n",
            "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.3.0-py36h54f3939_0\n",
            "  mkl_random         pkgs/main/linux-64::mkl_random-1.1.1-py36h0573a6f_0\n",
            "  networkx           pkgs/main/noarch::networkx-2.5-py_0\n",
            "  numpy              pkgs/main/linux-64::numpy-1.19.2-py36h54aff64_0\n",
            "  numpy-base         pkgs/main/linux-64::numpy-base-1.19.2-py36hfa32c7d_0\n",
            "  olefile            pkgs/main/linux-64::olefile-0.46-py36_0\n",
            "  pandas             pkgs/main/linux-64::pandas-1.1.5-py36ha9443f7_0\n",
            "  parso              pkgs/main/noarch::parso-0.8.2-pyhd3eb1b0_0\n",
            "  pcre               pkgs/main/linux-64::pcre-8.44-he6710b0_0\n",
            "  pexpect            pkgs/main/noarch::pexpect-4.8.0-pyhd3eb1b0_3\n",
            "  pickleshare        pkgs/main/noarch::pickleshare-0.7.5-pyhd3eb1b0_1003\n",
            "  pillow             pkgs/main/linux-64::pillow-8.2.0-py36he98fc37_0\n",
            "  pixman             pkgs/main/linux-64::pixman-0.40.0-h7b6447c_0\n",
            "  prompt-toolkit     pkgs/main/noarch::prompt-toolkit-3.0.17-pyh06a4308_0\n",
            "  protobuf           pkgs/main/linux-64::protobuf-3.14.0-py36h2531618_1\n",
            "  ptyprocess         pkgs/main/noarch::ptyprocess-0.7.0-pyhd3eb1b0_2\n",
            "  py-boost           pkgs/main/linux-64::py-boost-1.67.0-py36h04863e7_4\n",
            "  py-opencv          pkgs/main/linux-64::py-opencv-3.4.2-py36hb342d67_1\n",
            "  pygments           pkgs/main/noarch::pygments-2.9.0-pyhd3eb1b0_0\n",
            "  pyparsing          pkgs/main/noarch::pyparsing-2.4.7-pyhd3eb1b0_0\n",
            "  pyqt               pkgs/main/linux-64::pyqt-5.9.2-py36h05f1152_2\n",
            "  python-dateutil    pkgs/main/noarch::python-dateutil-2.8.1-pyhd3eb1b0_0\n",
            "  python-gflags      pkgs/main/linux-64::python-gflags-3.1.2-py36h06a4308_0\n",
            "  python-leveldb     pkgs/main/linux-64::python-leveldb-0.201-py36h2531618_0\n",
            "  pytz               pkgs/main/noarch::pytz-2021.1-pyhd3eb1b0_0\n",
            "  pywavelets         pkgs/main/linux-64::pywavelets-1.1.1-py36h7b6447c_2\n",
            "  pyyaml             pkgs/main/linux-64::pyyaml-5.4.1-py36h27cfd23_1\n",
            "  qt                 pkgs/main/linux-64::qt-5.9.7-h5867ecd_1\n",
            "  scikit-image       pkgs/main/linux-64::scikit-image-0.16.2-py36h0573a6f_0\n",
            "  scipy              pkgs/main/linux-64::scipy-1.5.2-py36h0b6359f_0\n",
            "  sip                pkgs/main/linux-64::sip-4.19.8-py36hf484d3e_0\n",
            "  snappy             pkgs/main/linux-64::snappy-1.1.8-he6710b0_0\n",
            "  toolz              pkgs/main/noarch::toolz-0.11.1-pyhd3eb1b0_0\n",
            "  tornado            pkgs/main/linux-64::tornado-6.1-py36h27cfd23_0\n",
            "  traitlets          pkgs/main/linux-64::traitlets-4.3.3-py36_0\n",
            "  wcwidth            pkgs/main/noarch::wcwidth-0.2.5-py_0\n",
            "  zstd               pkgs/main/linux-64::zstd-1.4.9-haebb681_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "cudatoolkit-10.0.130 | 261.2 MB  | : 100% 1.0/1 [00:05<00:00,  5.88s/it]              \n",
            "dask-core-2021.3.0   | 659 KB    | : 100% 1.0/1 [00:00<00:00,  9.36it/s]\n",
            "libglu-9.0.0         | 271 KB    | : 100% 1.0/1 [00:00<00:00, 13.34it/s]\n",
            "zstd-1.4.9           | 480 KB    | : 100% 1.0/1 [00:00<00:00, 11.33it/s]\n",
            "libtiff-4.2.0        | 502 KB    | : 100% 1.0/1 [00:00<00:00, 11.67it/s]\n",
            "libuuid-1.0.3        | 15 KB     | : 100% 1.0/1 [00:00<00:00,  1.71it/s]\n",
            "hdf5-1.10.2          | 3.8 MB    | : 100% 1.0/1 [00:00<00:00,  5.53it/s]\n",
            "ipython_genutils-0.2 | 27 KB     | : 100% 1.0/1 [00:00<00:00, 12.45it/s]\n",
            "leveldb-1.20         | 253 KB    | : 100% 1.0/1 [00:00<00:00, 12.72it/s]\n",
            "jasper-2.0.14        | 707 KB    | : 100% 1.0/1 [00:00<00:00, 10.61it/s]\n",
            "prompt-toolkit-3.0.1 | 256 KB    | : 100% 1.0/1 [00:00<00:00, 12.13it/s]\n",
            "mkl_random-1.1.1     | 327 KB    | : 100% 1.0/1 [00:00<00:00, 13.64it/s]\n",
            "pytz-2021.1          | 181 KB    | : 100% 1.0/1 [00:00<00:00,  9.08it/s]\n",
            "lcms2-2.12           | 312 KB    | : 100% 1.0/1 [00:00<00:00,  9.74it/s]\n",
            "gst-plugins-base-1.1 | 4.9 MB    | : 100% 1.0/1 [00:00<00:00,  4.97it/s]\n",
            "libgfortran4-7.5.0   | 995 KB    | : 100% 1.0/1 [00:00<00:00, 11.99it/s]\n",
            "pygments-2.9.0       | 721 KB    | : 100% 1.0/1 [00:00<00:00,  9.82it/s]\n",
            "bzip2-1.0.8          | 78 KB     | : 100% 1.0/1 [00:00<00:00, 13.71it/s]\n",
            "cairo-1.16.0         | 1.0 MB    | : 100% 1.0/1 [00:00<00:00, 10.09it/s]\n",
            "pcre-8.44            | 212 KB    | : 100% 1.0/1 [00:00<00:00,  5.76it/s]\n",
            "toolz-0.11.1         | 46 KB     | : 100% 1.0/1 [00:00<00:00, 27.62it/s]\n",
            "freetype-2.10.4      | 596 KB    | : 100% 1.0/1 [00:00<00:00, 10.78it/s]\n",
            "gflags-2.2.2         | 126 KB    | : 100% 1.0/1 [00:00<00:00, 14.30it/s]\n",
            "boost-1.67.0         | 11 KB     | : 100% 1.0/1 [00:00<00:00, 17.28it/s]\n",
            "kiwisolver-1.3.1     | 80 KB     | : 100% 1.0/1 [00:00<00:00, 14.70it/s]\n",
            "tornado-6.1          | 581 KB    | : 100% 1.0/1 [00:00<00:00, 11.91it/s]\n",
            "py-boost-1.67.0      | 278 KB    | : 100% 1.0/1 [00:00<00:00,  7.96it/s]\n",
            "pandas-1.1.5         | 8.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.74it/s]\n",
            "ipython-7.16.1       | 999 KB    | : 100% 1.0/1 [00:00<00:00,  6.72it/s]\n",
            "fontconfig-2.13.1    | 250 KB    | : 100% 1.0/1 [00:00<00:00, 11.76it/s]\n",
            "mkl-2020.2           | 138.3 MB  | : 100% 1.0/1 [00:23<00:00, 23.26s/it]               \n",
            "libvpx-1.7.0         | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  6.61it/s]\n",
            "glib-2.68.2          | 3.0 MB    | : 100% 1.0/1 [00:05<00:00,  5.94s/it]\n",
            "matplotlib-base-3.3. | 5.1 MB    | : 100% 1.0/1 [00:00<00:00,  4.07it/s]\n",
            "parso-0.8.2          | 69 KB     | : 100% 1.0/1 [00:00<00:00, 15.01it/s]\n",
            "freeglut-3.0.0       | 176 KB    | : 100% 1.0/1 [00:00<00:00, 12.31it/s]\n",
            "gstreamer-1.14.0     | 3.2 MB    | : 100% 1.0/1 [00:00<00:00,  6.47it/s]\n",
            "protobuf-3.14.0      | 303 KB    | : 100% 1.0/1 [00:00<00:00, 12.68it/s]\n",
            "pyqt-5.9.2           | 4.5 MB    | : 100% 1.0/1 [00:00<00:00,  3.78it/s]\n",
            "ffmpeg-4.0           | 53.3 MB   | : 100% 1.0/1 [00:02<00:00,  2.89s/it]               \n",
            "libopencv-3.4.2      | 21.8 MB   | : 100% 1.0/1 [00:08<00:00,  8.10s/it]\n",
            "backcall-0.2.0       | 13 KB     | : 100% 1.0/1 [00:00<00:00,  6.94it/s]\n",
            "cytoolz-0.11.0       | 329 KB    | : 100% 1.0/1 [00:00<00:00,  7.01it/s]\n",
            "jpeg-9b              | 214 KB    | : 100% 1.0/1 [00:00<00:00, 15.19it/s]\n",
            "libgfortran-ng-7.5.0 | 22 KB     | : 100% 1.0/1 [00:00<00:00, 16.28it/s]\n",
            "libprotobuf-3.14.0   | 2.0 MB    | : 100% 1.0/1 [00:00<00:00,  6.87it/s]\n",
            "cycler-0.10.0        | 13 KB     | : 100% 1.0/1 [00:00<00:00, 14.56it/s]\n",
            "libpng-1.6.37        | 278 KB    | : 100% 1.0/1 [00:00<00:00, 14.85it/s]\n",
            "libwebp-base-1.2.0   | 437 KB    | : 100% 1.0/1 [00:00<00:00, 11.98it/s]\n",
            "pyyaml-5.4.1         | 170 KB    | : 100% 1.0/1 [00:00<00:00, 13.14it/s]\n",
            "icu-58.2             | 10.5 MB   | : 100% 1.0/1 [00:00<00:00,  2.25it/s]\n",
            "h5py-2.8.0           | 911 KB    | : 100% 1.0/1 [00:05<00:00,  5.59s/it]\n",
            "wcwidth-0.2.5        | 29 KB     | : 100% 1.0/1 [00:00<00:00, 15.07it/s]\n",
            "py-opencv-3.4.2      | 1.0 MB    | : 100% 1.0/1 [00:00<00:00, 10.15it/s]\n",
            "libxml2-2.9.10       | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  8.34it/s]\n",
            "libboost-1.67.0      | 13.0 MB   | : 100% 1.0/1 [00:01<00:00,  1.72s/it]\n",
            "scipy-1.5.2          | 14.4 MB   | : 100% 1.0/1 [00:00<00:00,  1.41it/s]\n",
            "mkl_fft-1.3.0        | 170 KB    | : 100% 1.0/1 [00:00<00:00, 10.38it/s]\n",
            "numpy-1.19.2         | 22 KB     | : 100% 1.0/1 [00:00<00:00,  4.47it/s]\n",
            "blas-1.0             | 6 KB      | : 100% 1.0/1 [00:00<00:00, 14.97it/s]\n",
            "dbus-1.13.18         | 504 KB    | : 100% 1.0/1 [00:00<00:00, 10.76it/s]\n",
            "pickleshare-0.7.5    | 13 KB     | : 100% 1.0/1 [00:00<00:00,  4.06it/s]\n",
            "intel-openmp-2021.2. | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  7.63it/s]\n",
            "matplotlib-3.3.4     | 26 KB     | : 100% 1.0/1 [00:00<00:00, 10.39it/s]\n",
            "qt-5.9.7             | 68.5 MB   | : 100% 1.0/1 [00:12<00:00, 12.52s/it]               \n",
            "lmdb-0.9.29          | 424 KB    | : 100% 1.0/1 [00:05<00:00,  5.66s/it]\n",
            "libxcb-1.14          | 505 KB    | : 100% 1.0/1 [00:00<00:00,  9.43it/s]\n",
            "pexpect-4.8.0        | 53 KB     | : 100% 1.0/1 [00:00<00:00, 14.42it/s]\n",
            "python-gflags-3.1.2  | 70 KB     | : 100% 1.0/1 [00:00<00:00, 13.53it/s]\n",
            "sip-4.19.8           | 274 KB    | : 100% 1.0/1 [00:00<00:00, 13.82it/s]\n",
            "pyparsing-2.4.7      | 59 KB     | : 100% 1.0/1 [00:00<00:00, 29.84it/s]\n",
            "pixman-0.40.0        | 370 KB    | : 100% 1.0/1 [00:00<00:00, 11.30it/s]\n",
            "expat-2.4.1          | 168 KB    | : 100% 1.0/1 [00:00<00:00, 13.88it/s]\n",
            "glog-0.3.5           | 138 KB    | : 100% 1.0/1 [00:00<00:00, 14.05it/s]\n",
            "python-leveldb-0.201 | 26 KB     | : 100% 1.0/1 [00:00<00:00, 13.44it/s]\n",
            "olefile-0.46         | 48 KB     | : 100% 1.0/1 [00:00<00:00, 13.03it/s]\n",
            "numpy-base-1.19.2    | 4.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.73it/s]\n",
            "jedi-0.17.0          | 780 KB    | : 100% 1.0/1 [00:00<00:00,  4.77it/s]\n",
            "traitlets-4.3.3      | 140 KB    | : 100% 1.0/1 [00:00<00:00, 14.12it/s]\n",
            "imageio-2.9.0        | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  8.18it/s]\n",
            "graphite2-1.3.14     | 99 KB     | : 100% 1.0/1 [00:00<00:00,  6.05it/s]\n",
            "cudnn-7.6.5          | 165.0 MB  | : 100% 1.0/1 [00:14<00:00, 14.49s/it]               \n",
            "pywavelets-1.1.1     | 3.5 MB    | : 100% 1.0/1 [00:00<00:00,  4.74it/s]               \n",
            "mkl-service-2.3.0    | 52 KB     | : 100% 1.0/1 [00:00<00:00, 12.70it/s]\n",
            "python-dateutil-2.8. | 221 KB    | : 100% 1.0/1 [00:00<00:00, 15.87it/s]\n",
            "scikit-image-0.16.2  | 23.1 MB   | : 100% 1.0/1 [00:00<00:00,  1.15it/s]               \n",
            "caffe-gpu-1.0        | 3.8 MB    | : 100% 1.0/1 [00:00<00:00,  1.22it/s]\n",
            "snappy-1.1.8         | 40 KB     | : 100% 1.0/1 [00:00<00:00,  2.41it/s]\n",
            "ptyprocess-0.7.0     | 17 KB     | : 100% 1.0/1 [00:00<00:00, 14.25it/s]\n",
            "cloudpickle-1.6.0    | 30 KB     | : 100% 1.0/1 [00:05<00:00,  5.47s/it]\n",
            "networkx-2.5         | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  6.83it/s]\n",
            "pillow-8.2.0         | 627 KB    | : 100% 1.0/1 [00:00<00:00, 11.57it/s]\n",
            "decorator-5.0.9      | 12 KB     | : 100% 1.0/1 [00:00<00:00, 14.90it/s]\n",
            "harfbuzz-1.8.8       | 507 KB    | : 100% 1.0/1 [00:00<00:00, 12.26it/s]\n",
            "libopus-1.3.1        | 491 KB    | : 100% 1.0/1 [00:00<00:00, 10.35it/s]\n",
            "lz4-c-1.9.3          | 186 KB    | : 100% 1.0/1 [00:00<00:00, 15.06it/s]\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCTKnke81tov"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "alpha_list = np.linspace(-3.0, 3.0, num=61)\n",
        "\n",
        "f = open('./data/demo/list/demo.list', 'w')\n",
        "\n",
        "for alpha in alpha_list:\n",
        "  f.write('./demo/age1'+str(alpha)+'.png\\n')\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMuNZb6pYk6c",
        "outputId": "88cf2161-b006-4d90-d8f7-64fd8117590d"
      },
      "source": [
        "!sh demo_single_path.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(attr_num='40', caffemodel_path='./outputs/single_path_resnet_celeba.caffemodel', feature_layer='pred', gpu='0', mean_file='./data/pretrained/ResNet_mean.binaryproto', pred_file='./result/demo_result.list', prototxt_path='./outputs/deploy_single.prototxt', root_folder='./data', test_file='./data/demo/list/demo.list')\n",
            "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
            "W0614 15:22:20.327713  3510 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface\n",
            "W0614 15:22:20.327796  3510 _caffe.cpp:140] Use this instead (with the named \"weights\" parameter):\n",
            "W0614 15:22:20.327802  3510 _caffe.cpp:142] Net('./outputs/deploy_single.prototxt', 1, weights='./outputs/single_path_resnet_celeba.caffemodel')\n",
            "I0614 15:22:20.515323  3510 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./outputs/deploy_single.prototxt\n",
            "I0614 15:22:20.515410  3510 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
            "W0614 15:22:20.515424  3510 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
            "I0614 15:22:20.516113  3510 net.cpp:51] Initializing net from parameters: \n",
            "name: \"FaceAttribute-Net\"\n",
            "state {\n",
            "  phase: TEST\n",
            "  level: 0\n",
            "}\n",
            "layer {\n",
            "  name: \"input\"\n",
            "  type: \"Input\"\n",
            "  top: \"data\"\n",
            "  input_param {\n",
            "    shape {\n",
            "      dim: 2\n",
            "      dim: 3\n",
            "      dim: 224\n",
            "      dim: 224\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv1\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"data\"\n",
            "  top: \"conv1\"\n",
            "  convolution_param {\n",
            "    num_output: 64\n",
            "    pad: 3\n",
            "    kernel_size: 7\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn_conv1\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"conv1\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale_conv1\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"conv1\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv1_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"conv1\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool1\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"pool1\"\n",
            "  pooling_param {\n",
            "    pool: MAX\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res2a_branch1\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"res2a_branch1\"\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn2a_branch1\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res2a_branch1\"\n",
            "  top: \"res2a_branch1\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale2a_branch1\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res2a_branch1\"\n",
            "  top: \"res2a_branch1\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res2a_branch2a\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"res2a_branch2a\"\n",
            "  convolution_param {\n",
            "    num_output: 64\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn2a_branch2a\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res2a_branch2a\"\n",
            "  top: \"res2a_branch2a\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale2a_branch2a\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res2a_branch2a\"\n",
            "  top: \"res2a_branch2a\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res2a_branch2a_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res2a_branch2a\"\n",
            "  top: \"res2a_branch2a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res2a_branch2b\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res2a_branch2a\"\n",
            "  top: \"res2a_branch2b\"\n",
            "  convolution_param {\n",
            "    num_output: 64\n",
            "    bias_term: false\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn2a_branch2b\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res2a_branch2b\"\n",
            "  top: \"res2a_branch2b\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale2a_branch2b\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res2a_branch2b\"\n",
            "  top: \"res2a_branch2b\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res2a_branch2b_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res2a_branch2b\"\n",
            "  top: \"res2a_branch2b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res2a_branch2c\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res2a_branch2b\"\n",
            "  top: \"res2a_branch2c\"\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn2a_branch2c\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res2a_branch2c\"\n",
            "  top: \"res2a_branch2c\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale2a_branch2c\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res2a_branch2c\"\n",
            "  top: \"res2a_branch2c\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res2a\"\n",
            "  type: \"Eltwise\"\n",
            "  bottom: \"res2a_branch1\"\n",
            "  bottom: \"res2a_branch2c\"\n",
            "  top: \"res2a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res2a_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res2a\"\n",
            "  top: \"res2a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res2b_branch2a\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res2a\"\n",
            "  top: \"res2b_branch2a\"\n",
            "  convolution_param {\n",
            "    num_output: 64\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn2b_branch2a\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res2b_branch2a\"\n",
            "  top: \"res2b_branch2a\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale2b_branch2a\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res2b_branch2a\"\n",
            "  top: \"res2b_branch2a\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res2b_branch2a_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res2b_branch2a\"\n",
            "  top: \"res2b_branch2a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res2b_branch2b\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res2b_branch2a\"\n",
            "  top: \"res2b_branch2b\"\n",
            "  convolution_param {\n",
            "    num_output: 64\n",
            "    bias_term: false\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn2b_branch2b\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res2b_branch2b\"\n",
            "  top: \"res2b_branch2b\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale2b_branch2b\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res2b_branch2b\"\n",
            "  top: \"res2b_branch2b\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res2b_branch2b_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res2b_branch2b\"\n",
            "  top: \"res2b_branch2b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res2b_branch2c\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res2b_branch2b\"\n",
            "  top: \"res2b_branch2c\"\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn2b_branch2c\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res2b_branch2c\"\n",
            "  top: \"res2b_branch2c\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale2b_branch2c\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res2b_branch2c\"\n",
            "  top: \"res2b_branch2c\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res2b\"\n",
            "  type: \"Eltwise\"\n",
            "  bottom: \"res2a\"\n",
            "  bottom: \"res2b_branch2c\"\n",
            "  top: \"res2b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res2b_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res2b\"\n",
            "  top: \"res2b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res2c_branch2a\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res2b\"\n",
            "  top: \"res2c_branch2a\"\n",
            "  convolution_param {\n",
            "    num_output: 64\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn2c_branch2a\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res2c_branch2a\"\n",
            "  top: \"res2c_branch2a\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale2c_branch2a\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res2c_branch2a\"\n",
            "  top: \"res2c_branch2a\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res2c_branch2a_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res2c_branch2a\"\n",
            "  top: \"res2c_branch2a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res2c_branch2b\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res2c_branch2a\"\n",
            "  top: \"res2c_branch2b\"\n",
            "  convolution_param {\n",
            "    num_output: 64\n",
            "    bias_term: false\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn2c_branch2b\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res2c_branch2b\"\n",
            "  top: \"res2c_branch2b\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale2c_branch2b\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res2c_branch2b\"\n",
            "  top: \"res2c_branch2b\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res2c_branch2b_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res2c_branch2b\"\n",
            "  top: \"res2c_branch2b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res2c_branch2c\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res2c_branch2b\"\n",
            "  top: \"res2c_branch2c\"\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn2c_branch2c\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res2c_branch2c\"\n",
            "  top: \"res2c_branch2c\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale2c_branch2c\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res2c_branch2c\"\n",
            "  top: \"res2c_branch2c\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res2c\"\n",
            "  type: \"Eltwise\"\n",
            "  bottom: \"res2b\"\n",
            "  bottom: \"res2c_branch2c\"\n",
            "  top: \"res2c\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res2c_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res2c\"\n",
            "  top: \"res2c\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res3a_branch1\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res2c\"\n",
            "  top: \"res3a_branch1\"\n",
            "  convolution_param {\n",
            "    num_output: 512\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn3a_branch1\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res3a_branch1\"\n",
            "  top: \"res3a_branch1\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale3a_branch1\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res3a_branch1\"\n",
            "  top: \"res3a_branch1\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res3a_branch2a\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res2c\"\n",
            "  top: \"res3a_branch2a\"\n",
            "  convolution_param {\n",
            "    num_output: 128\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn3a_branch2a\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res3a_branch2a\"\n",
            "  top: \"res3a_branch2a\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale3a_branch2a\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res3a_branch2a\"\n",
            "  top: \"res3a_branch2a\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res3a_branch2a_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res3a_branch2a\"\n",
            "  top: \"res3a_branch2a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res3a_branch2b\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res3a_branch2a\"\n",
            "  top: \"res3a_branch2b\"\n",
            "  convolution_param {\n",
            "    num_output: 128\n",
            "    bias_term: false\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn3a_branch2b\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res3a_branch2b\"\n",
            "  top: \"res3a_branch2b\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale3a_branch2b\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res3a_branch2b\"\n",
            "  top: \"res3a_branch2b\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res3a_branch2b_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res3a_branch2b\"\n",
            "  top: \"res3a_branch2b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res3a_branch2c\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res3a_branch2b\"\n",
            "  top: \"res3a_branch2c\"\n",
            "  convolution_param {\n",
            "    num_output: 512\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn3a_branch2c\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res3a_branch2c\"\n",
            "  top: \"res3a_branch2c\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale3a_branch2c\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res3a_branch2c\"\n",
            "  top: \"res3a_branch2c\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res3a\"\n",
            "  type: \"Eltwise\"\n",
            "  bottom: \"res3a_branch1\"\n",
            "  bottom: \"res3a_branch2c\"\n",
            "  top: \"res3a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res3a_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res3a\"\n",
            "  top: \"res3a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res3b_branch2a\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res3a\"\n",
            "  top: \"res3b_branch2a\"\n",
            "  convolution_param {\n",
            "    num_output: 128\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn3b_branch2a\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res3b_branch2a\"\n",
            "  top: \"res3b_branch2a\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale3b_branch2a\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res3b_branch2a\"\n",
            "  top: \"res3b_branch2a\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res3b_branch2a_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res3b_branch2a\"\n",
            "  top: \"res3b_branch2a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res3b_branch2b\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res3b_branch2a\"\n",
            "  top: \"res3b_branch2b\"\n",
            "  convolution_param {\n",
            "    num_output: 128\n",
            "    bias_term: false\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn3b_branch2b\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res3b_branch2b\"\n",
            "  top: \"res3b_branch2b\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale3b_branch2b\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res3b_branch2b\"\n",
            "  top: \"res3b_branch2b\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res3b_branch2b_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res3b_branch2b\"\n",
            "  top: \"res3b_branch2b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res3b_branch2c\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res3b_branch2b\"\n",
            "  top: \"res3b_branch2c\"\n",
            "  convolution_param {\n",
            "    num_output: 512\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn3b_branch2c\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res3b_branch2c\"\n",
            "  top: \"res3b_branch2c\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale3b_branch2c\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res3b_branch2c\"\n",
            "  top: \"res3b_branch2c\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res3b\"\n",
            "  type: \"Eltwise\"\n",
            "  bottom: \"res3a\"\n",
            "  bottom: \"res3b_branch2c\"\n",
            "  top: \"res3b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res3b_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res3b\"\n",
            "  top: \"res3b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res3c_branch2a\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res3b\"\n",
            "  top: \"res3c_branch2a\"\n",
            "  convolution_param {\n",
            "    num_output: 128\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn3c_branch2a\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res3c_branch2a\"\n",
            "  top: \"res3c_branch2a\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale3c_branch2a\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res3c_branch2a\"\n",
            "  top: \"res3c_branch2a\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res3c_branch2a_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res3c_branch2a\"\n",
            "  top: \"res3c_branch2a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res3c_branch2b\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res3c_branch2a\"\n",
            "  top: \"res3c_branch2b\"\n",
            "  convolution_param {\n",
            "    num_output: 128\n",
            "    bias_term: false\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn3c_branch2b\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res3c_branch2b\"\n",
            "  top: \"res3c_branch2b\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale3c_branch2b\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res3c_branch2b\"\n",
            "  top: \"res3c_branch2b\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res3c_branch2b_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res3c_branch2b\"\n",
            "  top: \"res3c_branch2b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res3c_branch2c\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res3c_branch2b\"\n",
            "  top: \"res3c_branch2c\"\n",
            "  convolution_param {\n",
            "    num_output: 512\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn3c_branch2c\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res3c_branch2c\"\n",
            "  top: \"res3c_branch2c\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale3c_branch2c\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res3c_branch2c\"\n",
            "  top: \"res3c_branch2c\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res3c\"\n",
            "  type: \"Eltwise\"\n",
            "  bottom: \"res3b\"\n",
            "  bottom: \"res3c_branch2c\"\n",
            "  top: \"res3c\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res3c_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res3c\"\n",
            "  top: \"res3c\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res3d_branch2a\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res3c\"\n",
            "  top: \"res3d_branch2a\"\n",
            "  convolution_param {\n",
            "    num_output: 128\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn3d_branch2a\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res3d_branch2a\"\n",
            "  top: \"res3d_branch2a\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale3d_branch2a\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res3d_branch2a\"\n",
            "  top: \"res3d_branch2a\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res3d_branch2a_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res3d_branch2a\"\n",
            "  top: \"res3d_branch2a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res3d_branch2b\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res3d_branch2a\"\n",
            "  top: \"res3d_branch2b\"\n",
            "  convolution_param {\n",
            "    num_output: 128\n",
            "    bias_term: false\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn3d_branch2b\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res3d_branch2b\"\n",
            "  top: \"res3d_branch2b\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale3d_branch2b\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res3d_branch2b\"\n",
            "  top: \"res3d_branch2b\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res3d_branch2b_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res3d_branch2b\"\n",
            "  top: \"res3d_branch2b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res3d_branch2c\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res3d_branch2b\"\n",
            "  top: \"res3d_branch2c\"\n",
            "  convolution_param {\n",
            "    num_output: 512\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn3d_branch2c\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res3d_branch2c\"\n",
            "  top: \"res3d_branch2c\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale3d_branch2c\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res3d_branch2c\"\n",
            "  top: \"res3d_branch2c\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res3d\"\n",
            "  type: \"Eltwise\"\n",
            "  bottom: \"res3c\"\n",
            "  bottom: \"res3d_branch2c\"\n",
            "  top: \"res3d\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res3d_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res3d\"\n",
            "  top: \"res3d\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4a_branch1\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res3d\"\n",
            "  top: \"res4a_branch1\"\n",
            "  convolution_param {\n",
            "    num_output: 1024\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4a_branch1\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4a_branch1\"\n",
            "  top: \"res4a_branch1\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4a_branch1\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4a_branch1\"\n",
            "  top: \"res4a_branch1\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4a_branch2a\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res3d\"\n",
            "  top: \"res4a_branch2a\"\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4a_branch2a\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4a_branch2a\"\n",
            "  top: \"res4a_branch2a\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4a_branch2a\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4a_branch2a\"\n",
            "  top: \"res4a_branch2a\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4a_branch2a_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res4a_branch2a\"\n",
            "  top: \"res4a_branch2a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4a_branch2b\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4a_branch2a\"\n",
            "  top: \"res4a_branch2b\"\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    bias_term: false\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4a_branch2b\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4a_branch2b\"\n",
            "  top: \"res4a_branch2b\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4a_branch2b\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4a_branch2b\"\n",
            "  top: \"res4a_branch2b\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4a_branch2b_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res4a_branch2b\"\n",
            "  top: \"res4a_branch2b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4a_branch2c\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4a_branch2b\"\n",
            "  top: \"res4a_branch2c\"\n",
            "  convolution_param {\n",
            "    num_output: 1024\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4a_branch2c\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4a_branch2c\"\n",
            "  top: \"res4a_branch2c\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4a_branch2c\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4a_branch2c\"\n",
            "  top: \"res4a_branch2c\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4a\"\n",
            "  type: \"Eltwise\"\n",
            "  bottom: \"res4a_branch1\"\n",
            "  bottom: \"res4a_branch2c\"\n",
            "  top: \"res4a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4a_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res4a\"\n",
            "  top: \"res4a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4b_branch2a\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4a\"\n",
            "  top: \"res4b_branch2a\"\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4b_branch2a\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4b_branch2a\"\n",
            "  top: \"res4b_branch2a\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4b_branch2a\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4b_branch2a\"\n",
            "  top: \"res4b_branch2a\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4b_branch2a_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res4b_branch2a\"\n",
            "  top: \"res4b_branch2a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4b_branch2b\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4b_branch2a\"\n",
            "  top: \"res4b_branch2b\"\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    bias_term: false\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4b_branch2b\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4b_branch2b\"\n",
            "  top: \"res4b_branch2b\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4b_branch2b\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4b_branch2b\"\n",
            "  top: \"res4b_branch2b\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4b_branch2b_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res4b_branch2b\"\n",
            "  top: \"res4b_branch2b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4b_branch2c\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4b_branch2b\"\n",
            "  top: \"res4b_branch2c\"\n",
            "  convolution_param {\n",
            "    num_output: 1024\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4b_branch2c\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4b_branch2c\"\n",
            "  top: \"res4b_branch2c\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4b_branch2c\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4b_branch2c\"\n",
            "  top: \"res4b_branch2c\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4b\"\n",
            "  type: \"Eltwise\"\n",
            "  bottom: \"res4a\"\n",
            "  bottom: \"res4b_branch2c\"\n",
            "  top: \"res4b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4b_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res4b\"\n",
            "  top: \"res4b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4c_branch2a\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4b\"\n",
            "  top: \"res4c_branch2a\"\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4c_branch2a\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4c_branch2a\"\n",
            "  top: \"res4c_branch2a\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4c_branch2a\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4c_branch2a\"\n",
            "  top: \"res4c_branch2a\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4c_branch2a_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res4c_branch2a\"\n",
            "  top: \"res4c_branch2a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4c_branch2b\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4c_branch2a\"\n",
            "  top: \"res4c_branch2b\"\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    bias_term: false\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4c_branch2b\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4c_branch2b\"\n",
            "  top: \"res4c_branch2b\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4c_branch2b\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4c_branch2b\"\n",
            "  top: \"res4c_branch2b\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4c_branch2b_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res4c_branch2b\"\n",
            "  top: \"res4c_branch2b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4c_branch2c\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4c_branch2b\"\n",
            "  top: \"res4c_branch2c\"\n",
            "  convolution_param {\n",
            "    num_output: 1024\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4c_branch2c\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4c_branch2c\"\n",
            "  top: \"res4c_branch2c\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4c_branch2c\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4c_branch2c\"\n",
            "  top: \"res4c_branch2c\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4c\"\n",
            "  type: \"Eltwise\"\n",
            "  bottom: \"res4b\"\n",
            "  bottom: \"res4c_branch2c\"\n",
            "  top: \"res4c\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4c_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res4c\"\n",
            "  top: \"res4c\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4d_branch2a\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4c\"\n",
            "  top: \"res4d_branch2a\"\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4d_branch2a\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4d_branch2a\"\n",
            "  top: \"res4d_branch2a\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4d_branch2a\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4d_branch2a\"\n",
            "  top: \"res4d_branch2a\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4d_branch2a_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res4d_branch2a\"\n",
            "  top: \"res4d_branch2a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4d_branch2b\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4d_branch2a\"\n",
            "  top: \"res4d_branch2b\"\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    bias_term: false\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4d_branch2b\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4d_branch2b\"\n",
            "  top: \"res4d_branch2b\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4d_branch2b\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4d_branch2b\"\n",
            "  top: \"res4d_branch2b\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4d_branch2b_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res4d_branch2b\"\n",
            "  top: \"res4d_branch2b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4d_branch2c\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4d_branch2b\"\n",
            "  top: \"res4d_branch2c\"\n",
            "  convolution_param {\n",
            "    num_output: 1024\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4d_branch2c\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4d_branch2c\"\n",
            "  top: \"res4d_branch2c\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4d_branch2c\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4d_branch2c\"\n",
            "  top: \"res4d_branch2c\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4d\"\n",
            "  type: \"Eltwise\"\n",
            "  bottom: \"res4c\"\n",
            "  bottom: \"res4d_branch2c\"\n",
            "  top: \"res4d\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4d_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res4d\"\n",
            "  top: \"res4d\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4e_branch2a\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4d\"\n",
            "  top: \"res4e_branch2a\"\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4e_branch2a\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4e_branch2a\"\n",
            "  top: \"res4e_branch2a\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4e_branch2a\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4e_branch2a\"\n",
            "  top: \"res4e_branch2a\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4e_branch2a_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res4e_branch2a\"\n",
            "  top: \"res4e_branch2a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4e_branch2b\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4e_branch2a\"\n",
            "  top: \"res4e_branch2b\"\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    bias_term: false\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4e_branch2b\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4e_branch2b\"\n",
            "  top: \"res4e_branch2b\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4e_branch2b\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4e_branch2b\"\n",
            "  top: \"res4e_branch2b\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4e_branch2b_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res4e_branch2b\"\n",
            "  top: \"res4e_branch2b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4e_branch2c\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4e_branch2b\"\n",
            "  top: \"res4e_branch2c\"\n",
            "  convolution_param {\n",
            "    num_output: 1024\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4e_branch2c\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4e_branch2c\"\n",
            "  top: \"res4e_branch2c\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4e_branch2c\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4e_branch2c\"\n",
            "  top: \"res4e_branch2c\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4e\"\n",
            "  type: \"Eltwise\"\n",
            "  bottom: \"res4d\"\n",
            "  bottom: \"res4e_branch2c\"\n",
            "  top: \"res4e\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4e_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res4e\"\n",
            "  top: \"res4e\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4f_branch2a\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4e\"\n",
            "  top: \"res4f_branch2a\"\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4f_branch2a\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4f_branch2a\"\n",
            "  top: \"res4f_branch2a\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4f_branch2a\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4f_branch2a\"\n",
            "  top: \"res4f_branch2a\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4f_branch2a_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res4f_branch2a\"\n",
            "  top: \"res4f_branch2a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4f_branch2b\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4f_branch2a\"\n",
            "  top: \"res4f_branch2b\"\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    bias_term: false\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4f_branch2b\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4f_branch2b\"\n",
            "  top: \"res4f_branch2b\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4f_branch2b\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4f_branch2b\"\n",
            "  top: \"res4f_branch2b\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4f_branch2b_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res4f_branch2b\"\n",
            "  top: \"res4f_branch2b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4f_branch2c\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4f_branch2b\"\n",
            "  top: \"res4f_branch2c\"\n",
            "  convolution_param {\n",
            "    num_output: 1024\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn4f_branch2c\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res4f_branch2c\"\n",
            "  top: \"res4f_branch2c\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale4f_branch2c\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res4f_branch2c\"\n",
            "  top: \"res4f_branch2c\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res4f\"\n",
            "  type: \"Eltwise\"\n",
            "  bottom: \"res4e\"\n",
            "  bottom: \"res4f_branch2c\"\n",
            "  top: \"res4f\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res4f_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res4f\"\n",
            "  top: \"res4f\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res5a_branch1\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4f\"\n",
            "  top: \"res5a_branch1\"\n",
            "  convolution_param {\n",
            "    num_output: 2048\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn5a_branch1\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res5a_branch1\"\n",
            "  top: \"res5a_branch1\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale5a_branch1\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res5a_branch1\"\n",
            "  top: \"res5a_branch1\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res5a_branch2a\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res4f\"\n",
            "  top: \"res5a_branch2a\"\n",
            "  convolution_param {\n",
            "    num_output: 512\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn5a_branch2a\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res5a_branch2a\"\n",
            "  top: \"res5a_branch2a\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale5a_branch2a\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res5a_branch2a\"\n",
            "  top: \"res5a_branch2a\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res5a_branch2a_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res5a_branch2a\"\n",
            "  top: \"res5a_branch2a\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res5a_branch2b\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res5a_branch2a\"\n",
            "  top: \"res5a_branch2b\"\n",
            "  convolution_param {\n",
            "    num_output: 512\n",
            "    bias_term: false\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn5a_branch2b\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res5a_branch2b\"\n",
            "  top: \"res5a_branch2b\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale5a_branch2b\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res5a_branch2b\"\n",
            "  top: \"res5a_branch2b\"\n",
            "  scale_param {\n",
            "    bias_term: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"res5a_branch2b_relu\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"res5a_branch2b\"\n",
            "  top: \"res5a_branch2b\"\n",
            "}\n",
            "layer {\n",
            "  name: \"res5a_branch2c\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"res5a_branch2b\"\n",
            "  top: \"res5a_branch2c\"\n",
            "  convolution_param {\n",
            "    num_output: 2048\n",
            "    bias_term: false\n",
            "    pad: 0\n",
            "    kernel_size: 1\n",
            "    stride: 1\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"bn5a_branch2c\"\n",
            "  type: \"BatchNorm\"\n",
            "  bottom: \"res5a_branch2c\"\n",
            "  top: \"res5a_branch2c\"\n",
            "  batch_norm_param {\n",
            "    use_global_stats: true\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"scale5a_branch2c\"\n",
            "  type: \"Scale\"\n",
            "  bottom: \"res5a_branch2c\"\n",
            "  top: \"res5a_branch2c\"\n",
            "  sca\n",
            "I0614 15:22:20.571897  3510 layer_factory.hpp:77] Creating layer input\n",
            "I0614 15:22:20.571936  3510 net.cpp:84] Creating Layer input\n",
            "I0614 15:22:20.571946  3510 net.cpp:380] input -> data\n",
            "I0614 15:22:20.588968  3510 net.cpp:122] Setting up input\n",
            "I0614 15:22:20.588996  3510 net.cpp:129] Top shape: 2 3 224 224 (301056)\n",
            "I0614 15:22:20.589005  3510 net.cpp:137] Memory required for data: 1204224\n",
            "I0614 15:22:20.589015  3510 layer_factory.hpp:77] Creating layer conv1\n",
            "I0614 15:22:20.589041  3510 net.cpp:84] Creating Layer conv1\n",
            "I0614 15:22:20.589049  3510 net.cpp:406] conv1 <- data\n",
            "I0614 15:22:20.589061  3510 net.cpp:380] conv1 -> conv1\n",
            "I0614 15:22:21.606884  3510 net.cpp:122] Setting up conv1\n",
            "I0614 15:22:21.606937  3510 net.cpp:129] Top shape: 2 64 112 112 (1605632)\n",
            "I0614 15:22:21.606951  3510 net.cpp:137] Memory required for data: 7626752\n",
            "I0614 15:22:21.606984  3510 layer_factory.hpp:77] Creating layer bn_conv1\n",
            "I0614 15:22:21.607000  3510 net.cpp:84] Creating Layer bn_conv1\n",
            "I0614 15:22:21.607008  3510 net.cpp:406] bn_conv1 <- conv1\n",
            "I0614 15:22:21.607018  3510 net.cpp:367] bn_conv1 -> conv1 (in-place)\n",
            "I0614 15:22:21.607142  3510 net.cpp:122] Setting up bn_conv1\n",
            "I0614 15:22:21.607156  3510 net.cpp:129] Top shape: 2 64 112 112 (1605632)\n",
            "I0614 15:22:21.607162  3510 net.cpp:137] Memory required for data: 14049280\n",
            "I0614 15:22:21.607175  3510 layer_factory.hpp:77] Creating layer scale_conv1\n",
            "I0614 15:22:21.607187  3510 net.cpp:84] Creating Layer scale_conv1\n",
            "I0614 15:22:21.607194  3510 net.cpp:406] scale_conv1 <- conv1\n",
            "I0614 15:22:21.607203  3510 net.cpp:367] scale_conv1 -> conv1 (in-place)\n",
            "I0614 15:22:21.607232  3510 layer_factory.hpp:77] Creating layer scale_conv1\n",
            "I0614 15:22:21.607307  3510 net.cpp:122] Setting up scale_conv1\n",
            "I0614 15:22:21.607318  3510 net.cpp:129] Top shape: 2 64 112 112 (1605632)\n",
            "I0614 15:22:21.607322  3510 net.cpp:137] Memory required for data: 20471808\n",
            "I0614 15:22:21.607331  3510 layer_factory.hpp:77] Creating layer conv1_relu\n",
            "I0614 15:22:21.607340  3510 net.cpp:84] Creating Layer conv1_relu\n",
            "I0614 15:22:21.607348  3510 net.cpp:406] conv1_relu <- conv1\n",
            "I0614 15:22:21.607354  3510 net.cpp:367] conv1_relu -> conv1 (in-place)\n",
            "I0614 15:22:21.607758  3510 net.cpp:122] Setting up conv1_relu\n",
            "I0614 15:22:21.607782  3510 net.cpp:129] Top shape: 2 64 112 112 (1605632)\n",
            "I0614 15:22:21.607789  3510 net.cpp:137] Memory required for data: 26894336\n",
            "I0614 15:22:21.607793  3510 layer_factory.hpp:77] Creating layer pool1\n",
            "I0614 15:22:21.607801  3510 net.cpp:84] Creating Layer pool1\n",
            "I0614 15:22:21.607810  3510 net.cpp:406] pool1 <- conv1\n",
            "I0614 15:22:21.607820  3510 net.cpp:380] pool1 -> pool1\n",
            "I0614 15:22:21.607856  3510 net.cpp:122] Setting up pool1\n",
            "I0614 15:22:21.607867  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.607872  3510 net.cpp:137] Memory required for data: 28499968\n",
            "I0614 15:22:21.607875  3510 layer_factory.hpp:77] Creating layer pool1_pool1_0_split\n",
            "I0614 15:22:21.607883  3510 net.cpp:84] Creating Layer pool1_pool1_0_split\n",
            "I0614 15:22:21.607890  3510 net.cpp:406] pool1_pool1_0_split <- pool1\n",
            "I0614 15:22:21.607897  3510 net.cpp:380] pool1_pool1_0_split -> pool1_pool1_0_split_0\n",
            "I0614 15:22:21.607906  3510 net.cpp:380] pool1_pool1_0_split -> pool1_pool1_0_split_1\n",
            "I0614 15:22:21.607937  3510 net.cpp:122] Setting up pool1_pool1_0_split\n",
            "I0614 15:22:21.607949  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.607954  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.607959  3510 net.cpp:137] Memory required for data: 31711232\n",
            "I0614 15:22:21.607965  3510 layer_factory.hpp:77] Creating layer res2a_branch1\n",
            "I0614 15:22:21.607975  3510 net.cpp:84] Creating Layer res2a_branch1\n",
            "I0614 15:22:21.607983  3510 net.cpp:406] res2a_branch1 <- pool1_pool1_0_split_0\n",
            "I0614 15:22:21.607990  3510 net.cpp:380] res2a_branch1 -> res2a_branch1\n",
            "I0614 15:22:21.609396  3510 net.cpp:122] Setting up res2a_branch1\n",
            "I0614 15:22:21.609421  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.609426  3510 net.cpp:137] Memory required for data: 38133760\n",
            "I0614 15:22:21.609433  3510 layer_factory.hpp:77] Creating layer bn2a_branch1\n",
            "I0614 15:22:21.609442  3510 net.cpp:84] Creating Layer bn2a_branch1\n",
            "I0614 15:22:21.609448  3510 net.cpp:406] bn2a_branch1 <- res2a_branch1\n",
            "I0614 15:22:21.609457  3510 net.cpp:367] bn2a_branch1 -> res2a_branch1 (in-place)\n",
            "I0614 15:22:21.609544  3510 net.cpp:122] Setting up bn2a_branch1\n",
            "I0614 15:22:21.609555  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.609560  3510 net.cpp:137] Memory required for data: 44556288\n",
            "I0614 15:22:21.609570  3510 layer_factory.hpp:77] Creating layer scale2a_branch1\n",
            "I0614 15:22:21.609580  3510 net.cpp:84] Creating Layer scale2a_branch1\n",
            "I0614 15:22:21.609586  3510 net.cpp:406] scale2a_branch1 <- res2a_branch1\n",
            "I0614 15:22:21.609593  3510 net.cpp:367] scale2a_branch1 -> res2a_branch1 (in-place)\n",
            "I0614 15:22:21.609619  3510 layer_factory.hpp:77] Creating layer scale2a_branch1\n",
            "I0614 15:22:21.609679  3510 net.cpp:122] Setting up scale2a_branch1\n",
            "I0614 15:22:21.609688  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.609694  3510 net.cpp:137] Memory required for data: 50978816\n",
            "I0614 15:22:21.609700  3510 layer_factory.hpp:77] Creating layer res2a_branch2a\n",
            "I0614 15:22:21.609710  3510 net.cpp:84] Creating Layer res2a_branch2a\n",
            "I0614 15:22:21.609717  3510 net.cpp:406] res2a_branch2a <- pool1_pool1_0_split_1\n",
            "I0614 15:22:21.609725  3510 net.cpp:380] res2a_branch2a -> res2a_branch2a\n",
            "I0614 15:22:21.612197  3510 net.cpp:122] Setting up res2a_branch2a\n",
            "I0614 15:22:21.612217  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.612222  3510 net.cpp:137] Memory required for data: 52584448\n",
            "I0614 15:22:21.612231  3510 layer_factory.hpp:77] Creating layer bn2a_branch2a\n",
            "I0614 15:22:21.612237  3510 net.cpp:84] Creating Layer bn2a_branch2a\n",
            "I0614 15:22:21.612252  3510 net.cpp:406] bn2a_branch2a <- res2a_branch2a\n",
            "I0614 15:22:21.612259  3510 net.cpp:367] bn2a_branch2a -> res2a_branch2a (in-place)\n",
            "I0614 15:22:21.612357  3510 net.cpp:122] Setting up bn2a_branch2a\n",
            "I0614 15:22:21.612367  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.612371  3510 net.cpp:137] Memory required for data: 54190080\n",
            "I0614 15:22:21.612382  3510 layer_factory.hpp:77] Creating layer scale2a_branch2a\n",
            "I0614 15:22:21.612392  3510 net.cpp:84] Creating Layer scale2a_branch2a\n",
            "I0614 15:22:21.612399  3510 net.cpp:406] scale2a_branch2a <- res2a_branch2a\n",
            "I0614 15:22:21.612406  3510 net.cpp:367] scale2a_branch2a -> res2a_branch2a (in-place)\n",
            "I0614 15:22:21.612430  3510 layer_factory.hpp:77] Creating layer scale2a_branch2a\n",
            "I0614 15:22:21.612491  3510 net.cpp:122] Setting up scale2a_branch2a\n",
            "I0614 15:22:21.612509  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.612512  3510 net.cpp:137] Memory required for data: 55795712\n",
            "I0614 15:22:21.612519  3510 layer_factory.hpp:77] Creating layer res2a_branch2a_relu\n",
            "I0614 15:22:21.612529  3510 net.cpp:84] Creating Layer res2a_branch2a_relu\n",
            "I0614 15:22:21.612536  3510 net.cpp:406] res2a_branch2a_relu <- res2a_branch2a\n",
            "I0614 15:22:21.612543  3510 net.cpp:367] res2a_branch2a_relu -> res2a_branch2a (in-place)\n",
            "I0614 15:22:21.613054  3510 net.cpp:122] Setting up res2a_branch2a_relu\n",
            "I0614 15:22:21.613075  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.613078  3510 net.cpp:137] Memory required for data: 57401344\n",
            "I0614 15:22:21.613083  3510 layer_factory.hpp:77] Creating layer res2a_branch2b\n",
            "I0614 15:22:21.613093  3510 net.cpp:84] Creating Layer res2a_branch2b\n",
            "I0614 15:22:21.613098  3510 net.cpp:406] res2a_branch2b <- res2a_branch2a\n",
            "I0614 15:22:21.613112  3510 net.cpp:380] res2a_branch2b -> res2a_branch2b\n",
            "I0614 15:22:21.614827  3510 net.cpp:122] Setting up res2a_branch2b\n",
            "I0614 15:22:21.614850  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.614856  3510 net.cpp:137] Memory required for data: 59006976\n",
            "I0614 15:22:21.614863  3510 layer_factory.hpp:77] Creating layer bn2a_branch2b\n",
            "I0614 15:22:21.614871  3510 net.cpp:84] Creating Layer bn2a_branch2b\n",
            "I0614 15:22:21.614876  3510 net.cpp:406] bn2a_branch2b <- res2a_branch2b\n",
            "I0614 15:22:21.614895  3510 net.cpp:367] bn2a_branch2b -> res2a_branch2b (in-place)\n",
            "I0614 15:22:21.615010  3510 net.cpp:122] Setting up bn2a_branch2b\n",
            "I0614 15:22:21.615020  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.615025  3510 net.cpp:137] Memory required for data: 60612608\n",
            "I0614 15:22:21.615033  3510 layer_factory.hpp:77] Creating layer scale2a_branch2b\n",
            "I0614 15:22:21.615044  3510 net.cpp:84] Creating Layer scale2a_branch2b\n",
            "I0614 15:22:21.615051  3510 net.cpp:406] scale2a_branch2b <- res2a_branch2b\n",
            "I0614 15:22:21.615056  3510 net.cpp:367] scale2a_branch2b -> res2a_branch2b (in-place)\n",
            "I0614 15:22:21.615079  3510 layer_factory.hpp:77] Creating layer scale2a_branch2b\n",
            "I0614 15:22:21.615150  3510 net.cpp:122] Setting up scale2a_branch2b\n",
            "I0614 15:22:21.615160  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.615164  3510 net.cpp:137] Memory required for data: 62218240\n",
            "I0614 15:22:21.615171  3510 layer_factory.hpp:77] Creating layer res2a_branch2b_relu\n",
            "I0614 15:22:21.615178  3510 net.cpp:84] Creating Layer res2a_branch2b_relu\n",
            "I0614 15:22:21.615185  3510 net.cpp:406] res2a_branch2b_relu <- res2a_branch2b\n",
            "I0614 15:22:21.615190  3510 net.cpp:367] res2a_branch2b_relu -> res2a_branch2b (in-place)\n",
            "I0614 15:22:21.615629  3510 net.cpp:122] Setting up res2a_branch2b_relu\n",
            "I0614 15:22:21.615651  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.615656  3510 net.cpp:137] Memory required for data: 63823872\n",
            "I0614 15:22:21.615661  3510 layer_factory.hpp:77] Creating layer res2a_branch2c\n",
            "I0614 15:22:21.615669  3510 net.cpp:84] Creating Layer res2a_branch2c\n",
            "I0614 15:22:21.615675  3510 net.cpp:406] res2a_branch2c <- res2a_branch2b\n",
            "I0614 15:22:21.615684  3510 net.cpp:380] res2a_branch2c -> res2a_branch2c\n",
            "I0614 15:22:21.617357  3510 net.cpp:122] Setting up res2a_branch2c\n",
            "I0614 15:22:21.617378  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.617383  3510 net.cpp:137] Memory required for data: 70246400\n",
            "I0614 15:22:21.617391  3510 layer_factory.hpp:77] Creating layer bn2a_branch2c\n",
            "I0614 15:22:21.617399  3510 net.cpp:84] Creating Layer bn2a_branch2c\n",
            "I0614 15:22:21.617404  3510 net.cpp:406] bn2a_branch2c <- res2a_branch2c\n",
            "I0614 15:22:21.617424  3510 net.cpp:367] bn2a_branch2c -> res2a_branch2c (in-place)\n",
            "I0614 15:22:21.617514  3510 net.cpp:122] Setting up bn2a_branch2c\n",
            "I0614 15:22:21.617527  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.617530  3510 net.cpp:137] Memory required for data: 76668928\n",
            "I0614 15:22:21.617538  3510 layer_factory.hpp:77] Creating layer scale2a_branch2c\n",
            "I0614 15:22:21.617548  3510 net.cpp:84] Creating Layer scale2a_branch2c\n",
            "I0614 15:22:21.617554  3510 net.cpp:406] scale2a_branch2c <- res2a_branch2c\n",
            "I0614 15:22:21.617560  3510 net.cpp:367] scale2a_branch2c -> res2a_branch2c (in-place)\n",
            "I0614 15:22:21.617584  3510 layer_factory.hpp:77] Creating layer scale2a_branch2c\n",
            "I0614 15:22:21.617647  3510 net.cpp:122] Setting up scale2a_branch2c\n",
            "I0614 15:22:21.617657  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.617662  3510 net.cpp:137] Memory required for data: 83091456\n",
            "I0614 15:22:21.617669  3510 layer_factory.hpp:77] Creating layer res2a\n",
            "I0614 15:22:21.617678  3510 net.cpp:84] Creating Layer res2a\n",
            "I0614 15:22:21.617683  3510 net.cpp:406] res2a <- res2a_branch1\n",
            "I0614 15:22:21.617689  3510 net.cpp:406] res2a <- res2a_branch2c\n",
            "I0614 15:22:21.617697  3510 net.cpp:380] res2a -> res2a\n",
            "I0614 15:22:21.617712  3510 net.cpp:122] Setting up res2a\n",
            "I0614 15:22:21.617722  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.617727  3510 net.cpp:137] Memory required for data: 89513984\n",
            "I0614 15:22:21.617731  3510 layer_factory.hpp:77] Creating layer res2a_relu\n",
            "I0614 15:22:21.617738  3510 net.cpp:84] Creating Layer res2a_relu\n",
            "I0614 15:22:21.617743  3510 net.cpp:406] res2a_relu <- res2a\n",
            "I0614 15:22:21.617748  3510 net.cpp:367] res2a_relu -> res2a (in-place)\n",
            "I0614 15:22:21.618216  3510 net.cpp:122] Setting up res2a_relu\n",
            "I0614 15:22:21.618234  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.618239  3510 net.cpp:137] Memory required for data: 95936512\n",
            "I0614 15:22:21.618244  3510 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split\n",
            "I0614 15:22:21.618252  3510 net.cpp:84] Creating Layer res2a_res2a_relu_0_split\n",
            "I0614 15:22:21.618257  3510 net.cpp:406] res2a_res2a_relu_0_split <- res2a\n",
            "I0614 15:22:21.618264  3510 net.cpp:380] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0\n",
            "I0614 15:22:21.618279  3510 net.cpp:380] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1\n",
            "I0614 15:22:21.618316  3510 net.cpp:122] Setting up res2a_res2a_relu_0_split\n",
            "I0614 15:22:21.618327  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.618333  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.618337  3510 net.cpp:137] Memory required for data: 108781568\n",
            "I0614 15:22:21.618342  3510 layer_factory.hpp:77] Creating layer res2b_branch2a\n",
            "I0614 15:22:21.618350  3510 net.cpp:84] Creating Layer res2b_branch2a\n",
            "I0614 15:22:21.618356  3510 net.cpp:406] res2b_branch2a <- res2a_res2a_relu_0_split_0\n",
            "I0614 15:22:21.618362  3510 net.cpp:380] res2b_branch2a -> res2b_branch2a\n",
            "I0614 15:22:21.621223  3510 net.cpp:122] Setting up res2b_branch2a\n",
            "I0614 15:22:21.621243  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.621248  3510 net.cpp:137] Memory required for data: 110387200\n",
            "I0614 15:22:21.621256  3510 layer_factory.hpp:77] Creating layer bn2b_branch2a\n",
            "I0614 15:22:21.621271  3510 net.cpp:84] Creating Layer bn2b_branch2a\n",
            "I0614 15:22:21.621276  3510 net.cpp:406] bn2b_branch2a <- res2b_branch2a\n",
            "I0614 15:22:21.621286  3510 net.cpp:367] bn2b_branch2a -> res2b_branch2a (in-place)\n",
            "I0614 15:22:21.621378  3510 net.cpp:122] Setting up bn2b_branch2a\n",
            "I0614 15:22:21.621388  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.621393  3510 net.cpp:137] Memory required for data: 111992832\n",
            "I0614 15:22:21.621404  3510 layer_factory.hpp:77] Creating layer scale2b_branch2a\n",
            "I0614 15:22:21.621423  3510 net.cpp:84] Creating Layer scale2b_branch2a\n",
            "I0614 15:22:21.621430  3510 net.cpp:406] scale2b_branch2a <- res2b_branch2a\n",
            "I0614 15:22:21.621443  3510 net.cpp:367] scale2b_branch2a -> res2b_branch2a (in-place)\n",
            "I0614 15:22:21.621469  3510 layer_factory.hpp:77] Creating layer scale2b_branch2a\n",
            "I0614 15:22:21.621531  3510 net.cpp:122] Setting up scale2b_branch2a\n",
            "I0614 15:22:21.621548  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.621554  3510 net.cpp:137] Memory required for data: 113598464\n",
            "I0614 15:22:21.621562  3510 layer_factory.hpp:77] Creating layer res2b_branch2a_relu\n",
            "I0614 15:22:21.621572  3510 net.cpp:84] Creating Layer res2b_branch2a_relu\n",
            "I0614 15:22:21.621579  3510 net.cpp:406] res2b_branch2a_relu <- res2b_branch2a\n",
            "I0614 15:22:21.621585  3510 net.cpp:367] res2b_branch2a_relu -> res2b_branch2a (in-place)\n",
            "I0614 15:22:21.621920  3510 net.cpp:122] Setting up res2b_branch2a_relu\n",
            "I0614 15:22:21.621948  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.621953  3510 net.cpp:137] Memory required for data: 115204096\n",
            "I0614 15:22:21.621958  3510 layer_factory.hpp:77] Creating layer res2b_branch2b\n",
            "I0614 15:22:21.621974  3510 net.cpp:84] Creating Layer res2b_branch2b\n",
            "I0614 15:22:21.621984  3510 net.cpp:406] res2b_branch2b <- res2b_branch2a\n",
            "I0614 15:22:21.621990  3510 net.cpp:380] res2b_branch2b -> res2b_branch2b\n",
            "I0614 15:22:21.623920  3510 net.cpp:122] Setting up res2b_branch2b\n",
            "I0614 15:22:21.623952  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.623957  3510 net.cpp:137] Memory required for data: 116809728\n",
            "I0614 15:22:21.623965  3510 layer_factory.hpp:77] Creating layer bn2b_branch2b\n",
            "I0614 15:22:21.623972  3510 net.cpp:84] Creating Layer bn2b_branch2b\n",
            "I0614 15:22:21.623986  3510 net.cpp:406] bn2b_branch2b <- res2b_branch2b\n",
            "I0614 15:22:21.623993  3510 net.cpp:367] bn2b_branch2b -> res2b_branch2b (in-place)\n",
            "I0614 15:22:21.624095  3510 net.cpp:122] Setting up bn2b_branch2b\n",
            "I0614 15:22:21.624115  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.624120  3510 net.cpp:137] Memory required for data: 118415360\n",
            "I0614 15:22:21.624130  3510 layer_factory.hpp:77] Creating layer scale2b_branch2b\n",
            "I0614 15:22:21.624140  3510 net.cpp:84] Creating Layer scale2b_branch2b\n",
            "I0614 15:22:21.624147  3510 net.cpp:406] scale2b_branch2b <- res2b_branch2b\n",
            "I0614 15:22:21.624155  3510 net.cpp:367] scale2b_branch2b -> res2b_branch2b (in-place)\n",
            "I0614 15:22:21.624181  3510 layer_factory.hpp:77] Creating layer scale2b_branch2b\n",
            "I0614 15:22:21.624236  3510 net.cpp:122] Setting up scale2b_branch2b\n",
            "I0614 15:22:21.624245  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.624250  3510 net.cpp:137] Memory required for data: 120020992\n",
            "I0614 15:22:21.624258  3510 layer_factory.hpp:77] Creating layer res2b_branch2b_relu\n",
            "I0614 15:22:21.624266  3510 net.cpp:84] Creating Layer res2b_branch2b_relu\n",
            "I0614 15:22:21.624274  3510 net.cpp:406] res2b_branch2b_relu <- res2b_branch2b\n",
            "I0614 15:22:21.624287  3510 net.cpp:367] res2b_branch2b_relu -> res2b_branch2b (in-place)\n",
            "I0614 15:22:21.624675  3510 net.cpp:122] Setting up res2b_branch2b_relu\n",
            "I0614 15:22:21.624696  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.624701  3510 net.cpp:137] Memory required for data: 121626624\n",
            "I0614 15:22:21.624706  3510 layer_factory.hpp:77] Creating layer res2b_branch2c\n",
            "I0614 15:22:21.624714  3510 net.cpp:84] Creating Layer res2b_branch2c\n",
            "I0614 15:22:21.624723  3510 net.cpp:406] res2b_branch2c <- res2b_branch2b\n",
            "I0614 15:22:21.624730  3510 net.cpp:380] res2b_branch2c -> res2b_branch2c\n",
            "I0614 15:22:21.627526  3510 net.cpp:122] Setting up res2b_branch2c\n",
            "I0614 15:22:21.627549  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.627554  3510 net.cpp:137] Memory required for data: 128049152\n",
            "I0614 15:22:21.627562  3510 layer_factory.hpp:77] Creating layer bn2b_branch2c\n",
            "I0614 15:22:21.627569  3510 net.cpp:84] Creating Layer bn2b_branch2c\n",
            "I0614 15:22:21.627578  3510 net.cpp:406] bn2b_branch2c <- res2b_branch2c\n",
            "I0614 15:22:21.627585  3510 net.cpp:367] bn2b_branch2c -> res2b_branch2c (in-place)\n",
            "I0614 15:22:21.627689  3510 net.cpp:122] Setting up bn2b_branch2c\n",
            "I0614 15:22:21.627699  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.627704  3510 net.cpp:137] Memory required for data: 134471680\n",
            "I0614 15:22:21.627712  3510 layer_factory.hpp:77] Creating layer scale2b_branch2c\n",
            "I0614 15:22:21.627722  3510 net.cpp:84] Creating Layer scale2b_branch2c\n",
            "I0614 15:22:21.627729  3510 net.cpp:406] scale2b_branch2c <- res2b_branch2c\n",
            "I0614 15:22:21.627737  3510 net.cpp:367] scale2b_branch2c -> res2b_branch2c (in-place)\n",
            "I0614 15:22:21.627761  3510 layer_factory.hpp:77] Creating layer scale2b_branch2c\n",
            "I0614 15:22:21.678588  3510 net.cpp:122] Setting up scale2b_branch2c\n",
            "I0614 15:22:21.678622  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.678630  3510 net.cpp:137] Memory required for data: 140894208\n",
            "I0614 15:22:21.678645  3510 layer_factory.hpp:77] Creating layer res2b\n",
            "I0614 15:22:21.678655  3510 net.cpp:84] Creating Layer res2b\n",
            "I0614 15:22:21.678663  3510 net.cpp:406] res2b <- res2a_res2a_relu_0_split_1\n",
            "I0614 15:22:21.678673  3510 net.cpp:406] res2b <- res2b_branch2c\n",
            "I0614 15:22:21.678680  3510 net.cpp:380] res2b -> res2b\n",
            "I0614 15:22:21.678704  3510 net.cpp:122] Setting up res2b\n",
            "I0614 15:22:21.678714  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.678720  3510 net.cpp:137] Memory required for data: 147316736\n",
            "I0614 15:22:21.678727  3510 layer_factory.hpp:77] Creating layer res2b_relu\n",
            "I0614 15:22:21.678736  3510 net.cpp:84] Creating Layer res2b_relu\n",
            "I0614 15:22:21.678743  3510 net.cpp:406] res2b_relu <- res2b\n",
            "I0614 15:22:21.678751  3510 net.cpp:367] res2b_relu -> res2b (in-place)\n",
            "I0614 15:22:21.679482  3510 net.cpp:122] Setting up res2b_relu\n",
            "I0614 15:22:21.679507  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.679512  3510 net.cpp:137] Memory required for data: 153739264\n",
            "I0614 15:22:21.679518  3510 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split\n",
            "I0614 15:22:21.679527  3510 net.cpp:84] Creating Layer res2b_res2b_relu_0_split\n",
            "I0614 15:22:21.679533  3510 net.cpp:406] res2b_res2b_relu_0_split <- res2b\n",
            "I0614 15:22:21.679541  3510 net.cpp:380] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0\n",
            "I0614 15:22:21.679551  3510 net.cpp:380] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1\n",
            "I0614 15:22:21.679620  3510 net.cpp:122] Setting up res2b_res2b_relu_0_split\n",
            "I0614 15:22:21.679631  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.679637  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.679641  3510 net.cpp:137] Memory required for data: 166584320\n",
            "I0614 15:22:21.679646  3510 layer_factory.hpp:77] Creating layer res2c_branch2a\n",
            "I0614 15:22:21.679654  3510 net.cpp:84] Creating Layer res2c_branch2a\n",
            "I0614 15:22:21.679670  3510 net.cpp:406] res2c_branch2a <- res2b_res2b_relu_0_split_0\n",
            "I0614 15:22:21.679677  3510 net.cpp:380] res2c_branch2a -> res2c_branch2a\n",
            "I0614 15:22:21.681777  3510 net.cpp:122] Setting up res2c_branch2a\n",
            "I0614 15:22:21.681802  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.681807  3510 net.cpp:137] Memory required for data: 168189952\n",
            "I0614 15:22:21.681816  3510 layer_factory.hpp:77] Creating layer bn2c_branch2a\n",
            "I0614 15:22:21.681824  3510 net.cpp:84] Creating Layer bn2c_branch2a\n",
            "I0614 15:22:21.681830  3510 net.cpp:406] bn2c_branch2a <- res2c_branch2a\n",
            "I0614 15:22:21.681838  3510 net.cpp:367] bn2c_branch2a -> res2c_branch2a (in-place)\n",
            "I0614 15:22:21.681962  3510 net.cpp:122] Setting up bn2c_branch2a\n",
            "I0614 15:22:21.681972  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.681977  3510 net.cpp:137] Memory required for data: 169795584\n",
            "I0614 15:22:21.681986  3510 layer_factory.hpp:77] Creating layer scale2c_branch2a\n",
            "I0614 15:22:21.681998  3510 net.cpp:84] Creating Layer scale2c_branch2a\n",
            "I0614 15:22:21.682005  3510 net.cpp:406] scale2c_branch2a <- res2c_branch2a\n",
            "I0614 15:22:21.682013  3510 net.cpp:367] scale2c_branch2a -> res2c_branch2a (in-place)\n",
            "I0614 15:22:21.682040  3510 layer_factory.hpp:77] Creating layer scale2c_branch2a\n",
            "I0614 15:22:21.682113  3510 net.cpp:122] Setting up scale2c_branch2a\n",
            "I0614 15:22:21.682123  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.682127  3510 net.cpp:137] Memory required for data: 171401216\n",
            "I0614 15:22:21.682134  3510 layer_factory.hpp:77] Creating layer res2c_branch2a_relu\n",
            "I0614 15:22:21.682142  3510 net.cpp:84] Creating Layer res2c_branch2a_relu\n",
            "I0614 15:22:21.682147  3510 net.cpp:406] res2c_branch2a_relu <- res2c_branch2a\n",
            "I0614 15:22:21.682153  3510 net.cpp:367] res2c_branch2a_relu -> res2c_branch2a (in-place)\n",
            "I0614 15:22:21.682613  3510 net.cpp:122] Setting up res2c_branch2a_relu\n",
            "I0614 15:22:21.682636  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.682641  3510 net.cpp:137] Memory required for data: 173006848\n",
            "I0614 15:22:21.682646  3510 layer_factory.hpp:77] Creating layer res2c_branch2b\n",
            "I0614 15:22:21.682654  3510 net.cpp:84] Creating Layer res2c_branch2b\n",
            "I0614 15:22:21.682660  3510 net.cpp:406] res2c_branch2b <- res2c_branch2a\n",
            "I0614 15:22:21.682667  3510 net.cpp:380] res2c_branch2b -> res2c_branch2b\n",
            "I0614 15:22:21.684453  3510 net.cpp:122] Setting up res2c_branch2b\n",
            "I0614 15:22:21.684489  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.684494  3510 net.cpp:137] Memory required for data: 174612480\n",
            "I0614 15:22:21.684505  3510 layer_factory.hpp:77] Creating layer bn2c_branch2b\n",
            "I0614 15:22:21.684520  3510 net.cpp:84] Creating Layer bn2c_branch2b\n",
            "I0614 15:22:21.684525  3510 net.cpp:406] bn2c_branch2b <- res2c_branch2b\n",
            "I0614 15:22:21.684540  3510 net.cpp:367] bn2c_branch2b -> res2c_branch2b (in-place)\n",
            "I0614 15:22:21.684644  3510 net.cpp:122] Setting up bn2c_branch2b\n",
            "I0614 15:22:21.684654  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.684659  3510 net.cpp:137] Memory required for data: 176218112\n",
            "I0614 15:22:21.684667  3510 layer_factory.hpp:77] Creating layer scale2c_branch2b\n",
            "I0614 15:22:21.684677  3510 net.cpp:84] Creating Layer scale2c_branch2b\n",
            "I0614 15:22:21.684682  3510 net.cpp:406] scale2c_branch2b <- res2c_branch2b\n",
            "I0614 15:22:21.684689  3510 net.cpp:367] scale2c_branch2b -> res2c_branch2b (in-place)\n",
            "I0614 15:22:21.684715  3510 layer_factory.hpp:77] Creating layer scale2c_branch2b\n",
            "I0614 15:22:21.684780  3510 net.cpp:122] Setting up scale2c_branch2b\n",
            "I0614 15:22:21.684789  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.684794  3510 net.cpp:137] Memory required for data: 177823744\n",
            "I0614 15:22:21.684800  3510 layer_factory.hpp:77] Creating layer res2c_branch2b_relu\n",
            "I0614 15:22:21.684808  3510 net.cpp:84] Creating Layer res2c_branch2b_relu\n",
            "I0614 15:22:21.684814  3510 net.cpp:406] res2c_branch2b_relu <- res2c_branch2b\n",
            "I0614 15:22:21.684819  3510 net.cpp:367] res2c_branch2b_relu -> res2c_branch2b (in-place)\n",
            "I0614 15:22:21.685317  3510 net.cpp:122] Setting up res2c_branch2b_relu\n",
            "I0614 15:22:21.685338  3510 net.cpp:129] Top shape: 2 64 56 56 (401408)\n",
            "I0614 15:22:21.685343  3510 net.cpp:137] Memory required for data: 179429376\n",
            "I0614 15:22:21.685348  3510 layer_factory.hpp:77] Creating layer res2c_branch2c\n",
            "I0614 15:22:21.685362  3510 net.cpp:84] Creating Layer res2c_branch2c\n",
            "I0614 15:22:21.685376  3510 net.cpp:406] res2c_branch2c <- res2c_branch2b\n",
            "I0614 15:22:21.685384  3510 net.cpp:380] res2c_branch2c -> res2c_branch2c\n",
            "I0614 15:22:21.688350  3510 net.cpp:122] Setting up res2c_branch2c\n",
            "I0614 15:22:21.688372  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.688377  3510 net.cpp:137] Memory required for data: 185851904\n",
            "I0614 15:22:21.688386  3510 layer_factory.hpp:77] Creating layer bn2c_branch2c\n",
            "I0614 15:22:21.688395  3510 net.cpp:84] Creating Layer bn2c_branch2c\n",
            "I0614 15:22:21.688400  3510 net.cpp:406] bn2c_branch2c <- res2c_branch2c\n",
            "I0614 15:22:21.688406  3510 net.cpp:367] bn2c_branch2c -> res2c_branch2c (in-place)\n",
            "I0614 15:22:21.688516  3510 net.cpp:122] Setting up bn2c_branch2c\n",
            "I0614 15:22:21.688527  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.688532  3510 net.cpp:137] Memory required for data: 192274432\n",
            "I0614 15:22:21.688545  3510 layer_factory.hpp:77] Creating layer scale2c_branch2c\n",
            "I0614 15:22:21.688555  3510 net.cpp:84] Creating Layer scale2c_branch2c\n",
            "I0614 15:22:21.688560  3510 net.cpp:406] scale2c_branch2c <- res2c_branch2c\n",
            "I0614 15:22:21.688566  3510 net.cpp:367] scale2c_branch2c -> res2c_branch2c (in-place)\n",
            "I0614 15:22:21.688602  3510 layer_factory.hpp:77] Creating layer scale2c_branch2c\n",
            "I0614 15:22:21.688663  3510 net.cpp:122] Setting up scale2c_branch2c\n",
            "I0614 15:22:21.688674  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.688679  3510 net.cpp:137] Memory required for data: 198696960\n",
            "I0614 15:22:21.688686  3510 layer_factory.hpp:77] Creating layer res2c\n",
            "I0614 15:22:21.688695  3510 net.cpp:84] Creating Layer res2c\n",
            "I0614 15:22:21.688700  3510 net.cpp:406] res2c <- res2b_res2b_relu_0_split_1\n",
            "I0614 15:22:21.688706  3510 net.cpp:406] res2c <- res2c_branch2c\n",
            "I0614 15:22:21.688714  3510 net.cpp:380] res2c -> res2c\n",
            "I0614 15:22:21.688730  3510 net.cpp:122] Setting up res2c\n",
            "I0614 15:22:21.688738  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.688743  3510 net.cpp:137] Memory required for data: 205119488\n",
            "I0614 15:22:21.688748  3510 layer_factory.hpp:77] Creating layer res2c_relu\n",
            "I0614 15:22:21.688755  3510 net.cpp:84] Creating Layer res2c_relu\n",
            "I0614 15:22:21.688760  3510 net.cpp:406] res2c_relu <- res2c\n",
            "I0614 15:22:21.688766  3510 net.cpp:367] res2c_relu -> res2c (in-place)\n",
            "I0614 15:22:21.689254  3510 net.cpp:122] Setting up res2c_relu\n",
            "I0614 15:22:21.689286  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.689292  3510 net.cpp:137] Memory required for data: 211542016\n",
            "I0614 15:22:21.689298  3510 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split\n",
            "I0614 15:22:21.689311  3510 net.cpp:84] Creating Layer res2c_res2c_relu_0_split\n",
            "I0614 15:22:21.689321  3510 net.cpp:406] res2c_res2c_relu_0_split <- res2c\n",
            "I0614 15:22:21.689328  3510 net.cpp:380] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0\n",
            "I0614 15:22:21.689337  3510 net.cpp:380] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1\n",
            "I0614 15:22:21.689368  3510 net.cpp:122] Setting up res2c_res2c_relu_0_split\n",
            "I0614 15:22:21.689378  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.689384  3510 net.cpp:129] Top shape: 2 256 56 56 (1605632)\n",
            "I0614 15:22:21.689390  3510 net.cpp:137] Memory required for data: 224387072\n",
            "I0614 15:22:21.689395  3510 layer_factory.hpp:77] Creating layer res3a_branch1\n",
            "I0614 15:22:21.689404  3510 net.cpp:84] Creating Layer res3a_branch1\n",
            "I0614 15:22:21.689410  3510 net.cpp:406] res3a_branch1 <- res2c_res2c_relu_0_split_0\n",
            "I0614 15:22:21.689416  3510 net.cpp:380] res3a_branch1 -> res3a_branch1\n",
            "I0614 15:22:21.692176  3510 net.cpp:122] Setting up res3a_branch1\n",
            "I0614 15:22:21.692198  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.692203  3510 net.cpp:137] Memory required for data: 227598336\n",
            "I0614 15:22:21.692210  3510 layer_factory.hpp:77] Creating layer bn3a_branch1\n",
            "I0614 15:22:21.692219  3510 net.cpp:84] Creating Layer bn3a_branch1\n",
            "I0614 15:22:21.692225  3510 net.cpp:406] bn3a_branch1 <- res3a_branch1\n",
            "I0614 15:22:21.692232  3510 net.cpp:367] bn3a_branch1 -> res3a_branch1 (in-place)\n",
            "I0614 15:22:21.692349  3510 net.cpp:122] Setting up bn3a_branch1\n",
            "I0614 15:22:21.692360  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.692364  3510 net.cpp:137] Memory required for data: 230809600\n",
            "I0614 15:22:21.692373  3510 layer_factory.hpp:77] Creating layer scale3a_branch1\n",
            "I0614 15:22:21.692384  3510 net.cpp:84] Creating Layer scale3a_branch1\n",
            "I0614 15:22:21.692389  3510 net.cpp:406] scale3a_branch1 <- res3a_branch1\n",
            "I0614 15:22:21.692395  3510 net.cpp:367] scale3a_branch1 -> res3a_branch1 (in-place)\n",
            "I0614 15:22:21.692418  3510 layer_factory.hpp:77] Creating layer scale3a_branch1\n",
            "I0614 15:22:21.692481  3510 net.cpp:122] Setting up scale3a_branch1\n",
            "I0614 15:22:21.692492  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.692497  3510 net.cpp:137] Memory required for data: 234020864\n",
            "I0614 15:22:21.692503  3510 layer_factory.hpp:77] Creating layer res3a_branch2a\n",
            "I0614 15:22:21.692512  3510 net.cpp:84] Creating Layer res3a_branch2a\n",
            "I0614 15:22:21.692517  3510 net.cpp:406] res3a_branch2a <- res2c_res2c_relu_0_split_1\n",
            "I0614 15:22:21.692523  3510 net.cpp:380] res3a_branch2a -> res3a_branch2a\n",
            "I0614 15:22:21.694149  3510 net.cpp:122] Setting up res3a_branch2a\n",
            "I0614 15:22:21.694170  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.694175  3510 net.cpp:137] Memory required for data: 234823680\n",
            "I0614 15:22:21.694182  3510 layer_factory.hpp:77] Creating layer bn3a_branch2a\n",
            "I0614 15:22:21.694200  3510 net.cpp:84] Creating Layer bn3a_branch2a\n",
            "I0614 15:22:21.694211  3510 net.cpp:406] bn3a_branch2a <- res3a_branch2a\n",
            "I0614 15:22:21.694217  3510 net.cpp:367] bn3a_branch2a -> res3a_branch2a (in-place)\n",
            "I0614 15:22:21.694326  3510 net.cpp:122] Setting up bn3a_branch2a\n",
            "I0614 15:22:21.694337  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.694341  3510 net.cpp:137] Memory required for data: 235626496\n",
            "I0614 15:22:21.694350  3510 layer_factory.hpp:77] Creating layer scale3a_branch2a\n",
            "I0614 15:22:21.694360  3510 net.cpp:84] Creating Layer scale3a_branch2a\n",
            "I0614 15:22:21.694366  3510 net.cpp:406] scale3a_branch2a <- res3a_branch2a\n",
            "I0614 15:22:21.694372  3510 net.cpp:367] scale3a_branch2a -> res3a_branch2a (in-place)\n",
            "I0614 15:22:21.694398  3510 layer_factory.hpp:77] Creating layer scale3a_branch2a\n",
            "I0614 15:22:21.694451  3510 net.cpp:122] Setting up scale3a_branch2a\n",
            "I0614 15:22:21.694461  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.694465  3510 net.cpp:137] Memory required for data: 236429312\n",
            "I0614 15:22:21.694473  3510 layer_factory.hpp:77] Creating layer res3a_branch2a_relu\n",
            "I0614 15:22:21.694481  3510 net.cpp:84] Creating Layer res3a_branch2a_relu\n",
            "I0614 15:22:21.694487  3510 net.cpp:406] res3a_branch2a_relu <- res3a_branch2a\n",
            "I0614 15:22:21.694492  3510 net.cpp:367] res3a_branch2a_relu -> res3a_branch2a (in-place)\n",
            "I0614 15:22:21.696200  3510 net.cpp:122] Setting up res3a_branch2a_relu\n",
            "I0614 15:22:21.696223  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.696228  3510 net.cpp:137] Memory required for data: 237232128\n",
            "I0614 15:22:21.696233  3510 layer_factory.hpp:77] Creating layer res3a_branch2b\n",
            "I0614 15:22:21.696257  3510 net.cpp:84] Creating Layer res3a_branch2b\n",
            "I0614 15:22:21.696264  3510 net.cpp:406] res3a_branch2b <- res3a_branch2a\n",
            "I0614 15:22:21.696272  3510 net.cpp:380] res3a_branch2b -> res3a_branch2b\n",
            "I0614 15:22:21.698495  3510 net.cpp:122] Setting up res3a_branch2b\n",
            "I0614 15:22:21.698514  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.698519  3510 net.cpp:137] Memory required for data: 238034944\n",
            "I0614 15:22:21.698527  3510 layer_factory.hpp:77] Creating layer bn3a_branch2b\n",
            "I0614 15:22:21.698534  3510 net.cpp:84] Creating Layer bn3a_branch2b\n",
            "I0614 15:22:21.698539  3510 net.cpp:406] bn3a_branch2b <- res3a_branch2b\n",
            "I0614 15:22:21.698544  3510 net.cpp:367] bn3a_branch2b -> res3a_branch2b (in-place)\n",
            "I0614 15:22:21.698663  3510 net.cpp:122] Setting up bn3a_branch2b\n",
            "I0614 15:22:21.698670  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.698674  3510 net.cpp:137] Memory required for data: 238837760\n",
            "I0614 15:22:21.698683  3510 layer_factory.hpp:77] Creating layer scale3a_branch2b\n",
            "I0614 15:22:21.698689  3510 net.cpp:84] Creating Layer scale3a_branch2b\n",
            "I0614 15:22:21.698694  3510 net.cpp:406] scale3a_branch2b <- res3a_branch2b\n",
            "I0614 15:22:21.698699  3510 net.cpp:367] scale3a_branch2b -> res3a_branch2b (in-place)\n",
            "I0614 15:22:21.698724  3510 layer_factory.hpp:77] Creating layer scale3a_branch2b\n",
            "I0614 15:22:21.698792  3510 net.cpp:122] Setting up scale3a_branch2b\n",
            "I0614 15:22:21.698799  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.698804  3510 net.cpp:137] Memory required for data: 239640576\n",
            "I0614 15:22:21.698812  3510 layer_factory.hpp:77] Creating layer res3a_branch2b_relu\n",
            "I0614 15:22:21.698817  3510 net.cpp:84] Creating Layer res3a_branch2b_relu\n",
            "I0614 15:22:21.698822  3510 net.cpp:406] res3a_branch2b_relu <- res3a_branch2b\n",
            "I0614 15:22:21.698827  3510 net.cpp:367] res3a_branch2b_relu -> res3a_branch2b (in-place)\n",
            "I0614 15:22:21.699515  3510 net.cpp:122] Setting up res3a_branch2b_relu\n",
            "I0614 15:22:21.699532  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.699537  3510 net.cpp:137] Memory required for data: 240443392\n",
            "I0614 15:22:21.699542  3510 layer_factory.hpp:77] Creating layer res3a_branch2c\n",
            "I0614 15:22:21.699551  3510 net.cpp:84] Creating Layer res3a_branch2c\n",
            "I0614 15:22:21.699556  3510 net.cpp:406] res3a_branch2c <- res3a_branch2b\n",
            "I0614 15:22:21.699563  3510 net.cpp:380] res3a_branch2c -> res3a_branch2c\n",
            "I0614 15:22:21.701740  3510 net.cpp:122] Setting up res3a_branch2c\n",
            "I0614 15:22:21.701766  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.701774  3510 net.cpp:137] Memory required for data: 243654656\n",
            "I0614 15:22:21.701786  3510 layer_factory.hpp:77] Creating layer bn3a_branch2c\n",
            "I0614 15:22:21.701797  3510 net.cpp:84] Creating Layer bn3a_branch2c\n",
            "I0614 15:22:21.701805  3510 net.cpp:406] bn3a_branch2c <- res3a_branch2c\n",
            "I0614 15:22:21.701812  3510 net.cpp:367] bn3a_branch2c -> res3a_branch2c (in-place)\n",
            "I0614 15:22:21.702086  3510 net.cpp:122] Setting up bn3a_branch2c\n",
            "I0614 15:22:21.702109  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.702114  3510 net.cpp:137] Memory required for data: 246865920\n",
            "I0614 15:22:21.702126  3510 layer_factory.hpp:77] Creating layer scale3a_branch2c\n",
            "I0614 15:22:21.702136  3510 net.cpp:84] Creating Layer scale3a_branch2c\n",
            "I0614 15:22:21.702143  3510 net.cpp:406] scale3a_branch2c <- res3a_branch2c\n",
            "I0614 15:22:21.702152  3510 net.cpp:367] scale3a_branch2c -> res3a_branch2c (in-place)\n",
            "I0614 15:22:21.702179  3510 layer_factory.hpp:77] Creating layer scale3a_branch2c\n",
            "I0614 15:22:21.702255  3510 net.cpp:122] Setting up scale3a_branch2c\n",
            "I0614 15:22:21.702265  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.702270  3510 net.cpp:137] Memory required for data: 250077184\n",
            "I0614 15:22:21.702280  3510 layer_factory.hpp:77] Creating layer res3a\n",
            "I0614 15:22:21.702288  3510 net.cpp:84] Creating Layer res3a\n",
            "I0614 15:22:21.702296  3510 net.cpp:406] res3a <- res3a_branch1\n",
            "I0614 15:22:21.702303  3510 net.cpp:406] res3a <- res3a_branch2c\n",
            "I0614 15:22:21.702311  3510 net.cpp:380] res3a -> res3a\n",
            "I0614 15:22:21.702328  3510 net.cpp:122] Setting up res3a\n",
            "I0614 15:22:21.702337  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.702344  3510 net.cpp:137] Memory required for data: 253288448\n",
            "I0614 15:22:21.702351  3510 layer_factory.hpp:77] Creating layer res3a_relu\n",
            "I0614 15:22:21.702360  3510 net.cpp:84] Creating Layer res3a_relu\n",
            "I0614 15:22:21.702368  3510 net.cpp:406] res3a_relu <- res3a\n",
            "I0614 15:22:21.702375  3510 net.cpp:367] res3a_relu -> res3a (in-place)\n",
            "I0614 15:22:21.702850  3510 net.cpp:122] Setting up res3a_relu\n",
            "I0614 15:22:21.702872  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.702877  3510 net.cpp:137] Memory required for data: 256499712\n",
            "I0614 15:22:21.702883  3510 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split\n",
            "I0614 15:22:21.702890  3510 net.cpp:84] Creating Layer res3a_res3a_relu_0_split\n",
            "I0614 15:22:21.702906  3510 net.cpp:406] res3a_res3a_relu_0_split <- res3a\n",
            "I0614 15:22:21.702913  3510 net.cpp:380] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0\n",
            "I0614 15:22:21.702937  3510 net.cpp:380] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1\n",
            "I0614 15:22:21.702971  3510 net.cpp:122] Setting up res3a_res3a_relu_0_split\n",
            "I0614 15:22:21.702981  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.702987  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.702996  3510 net.cpp:137] Memory required for data: 262922240\n",
            "I0614 15:22:21.703002  3510 layer_factory.hpp:77] Creating layer res3b_branch2a\n",
            "I0614 15:22:21.703023  3510 net.cpp:84] Creating Layer res3b_branch2a\n",
            "I0614 15:22:21.703032  3510 net.cpp:406] res3b_branch2a <- res3a_res3a_relu_0_split_0\n",
            "I0614 15:22:21.703039  3510 net.cpp:380] res3b_branch2a -> res3b_branch2a\n",
            "I0614 15:22:21.706207  3510 net.cpp:122] Setting up res3b_branch2a\n",
            "I0614 15:22:21.706230  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.706235  3510 net.cpp:137] Memory required for data: 263725056\n",
            "I0614 15:22:21.706243  3510 layer_factory.hpp:77] Creating layer bn3b_branch2a\n",
            "I0614 15:22:21.706251  3510 net.cpp:84] Creating Layer bn3b_branch2a\n",
            "I0614 15:22:21.706257  3510 net.cpp:406] bn3b_branch2a <- res3b_branch2a\n",
            "I0614 15:22:21.706265  3510 net.cpp:367] bn3b_branch2a -> res3b_branch2a (in-place)\n",
            "I0614 15:22:21.706357  3510 net.cpp:122] Setting up bn3b_branch2a\n",
            "I0614 15:22:21.706367  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.706370  3510 net.cpp:137] Memory required for data: 264527872\n",
            "I0614 15:22:21.706379  3510 layer_factory.hpp:77] Creating layer scale3b_branch2a\n",
            "I0614 15:22:21.706390  3510 net.cpp:84] Creating Layer scale3b_branch2a\n",
            "I0614 15:22:21.706395  3510 net.cpp:406] scale3b_branch2a <- res3b_branch2a\n",
            "I0614 15:22:21.706401  3510 net.cpp:367] scale3b_branch2a -> res3b_branch2a (in-place)\n",
            "I0614 15:22:21.780807  3510 layer_factory.hpp:77] Creating layer scale3b_branch2a\n",
            "I0614 15:22:21.780915  3510 net.cpp:122] Setting up scale3b_branch2a\n",
            "I0614 15:22:21.780946  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.780956  3510 net.cpp:137] Memory required for data: 265330688\n",
            "I0614 15:22:21.780994  3510 layer_factory.hpp:77] Creating layer res3b_branch2a_relu\n",
            "I0614 15:22:21.781004  3510 net.cpp:84] Creating Layer res3b_branch2a_relu\n",
            "I0614 15:22:21.781039  3510 net.cpp:406] res3b_branch2a_relu <- res3b_branch2a\n",
            "I0614 15:22:21.781049  3510 net.cpp:367] res3b_branch2a_relu -> res3b_branch2a (in-place)\n",
            "I0614 15:22:21.781620  3510 net.cpp:122] Setting up res3b_branch2a_relu\n",
            "I0614 15:22:21.781649  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.781658  3510 net.cpp:137] Memory required for data: 266133504\n",
            "I0614 15:22:21.781667  3510 layer_factory.hpp:77] Creating layer res3b_branch2b\n",
            "I0614 15:22:21.781679  3510 net.cpp:84] Creating Layer res3b_branch2b\n",
            "I0614 15:22:21.781688  3510 net.cpp:406] res3b_branch2b <- res3b_branch2a\n",
            "I0614 15:22:21.781706  3510 net.cpp:380] res3b_branch2b -> res3b_branch2b\n",
            "I0614 15:22:21.784798  3510 net.cpp:122] Setting up res3b_branch2b\n",
            "I0614 15:22:21.784824  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.784830  3510 net.cpp:137] Memory required for data: 266936320\n",
            "I0614 15:22:21.784838  3510 layer_factory.hpp:77] Creating layer bn3b_branch2b\n",
            "I0614 15:22:21.784848  3510 net.cpp:84] Creating Layer bn3b_branch2b\n",
            "I0614 15:22:21.784854  3510 net.cpp:406] bn3b_branch2b <- res3b_branch2b\n",
            "I0614 15:22:21.784862  3510 net.cpp:367] bn3b_branch2b -> res3b_branch2b (in-place)\n",
            "I0614 15:22:21.784979  3510 net.cpp:122] Setting up bn3b_branch2b\n",
            "I0614 15:22:21.784991  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.784996  3510 net.cpp:137] Memory required for data: 267739136\n",
            "I0614 15:22:21.785003  3510 layer_factory.hpp:77] Creating layer scale3b_branch2b\n",
            "I0614 15:22:21.785017  3510 net.cpp:84] Creating Layer scale3b_branch2b\n",
            "I0614 15:22:21.785025  3510 net.cpp:406] scale3b_branch2b <- res3b_branch2b\n",
            "I0614 15:22:21.785032  3510 net.cpp:367] scale3b_branch2b -> res3b_branch2b (in-place)\n",
            "I0614 15:22:21.785058  3510 layer_factory.hpp:77] Creating layer scale3b_branch2b\n",
            "I0614 15:22:21.785113  3510 net.cpp:122] Setting up scale3b_branch2b\n",
            "I0614 15:22:21.785125  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.785128  3510 net.cpp:137] Memory required for data: 268541952\n",
            "I0614 15:22:21.785135  3510 layer_factory.hpp:77] Creating layer res3b_branch2b_relu\n",
            "I0614 15:22:21.785142  3510 net.cpp:84] Creating Layer res3b_branch2b_relu\n",
            "I0614 15:22:21.785147  3510 net.cpp:406] res3b_branch2b_relu <- res3b_branch2b\n",
            "I0614 15:22:21.785153  3510 net.cpp:367] res3b_branch2b_relu -> res3b_branch2b (in-place)\n",
            "I0614 15:22:21.785629  3510 net.cpp:122] Setting up res3b_branch2b_relu\n",
            "I0614 15:22:21.785650  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.785653  3510 net.cpp:137] Memory required for data: 269344768\n",
            "I0614 15:22:21.785658  3510 layer_factory.hpp:77] Creating layer res3b_branch2c\n",
            "I0614 15:22:21.785667  3510 net.cpp:84] Creating Layer res3b_branch2c\n",
            "I0614 15:22:21.785673  3510 net.cpp:406] res3b_branch2c <- res3b_branch2b\n",
            "I0614 15:22:21.785681  3510 net.cpp:380] res3b_branch2c -> res3b_branch2c\n",
            "I0614 15:22:21.787523  3510 net.cpp:122] Setting up res3b_branch2c\n",
            "I0614 15:22:21.787547  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.787552  3510 net.cpp:137] Memory required for data: 272556032\n",
            "I0614 15:22:21.787560  3510 layer_factory.hpp:77] Creating layer bn3b_branch2c\n",
            "I0614 15:22:21.787568  3510 net.cpp:84] Creating Layer bn3b_branch2c\n",
            "I0614 15:22:21.787575  3510 net.cpp:406] bn3b_branch2c <- res3b_branch2c\n",
            "I0614 15:22:21.787581  3510 net.cpp:367] bn3b_branch2c -> res3b_branch2c (in-place)\n",
            "I0614 15:22:21.787703  3510 net.cpp:122] Setting up bn3b_branch2c\n",
            "I0614 15:22:21.787714  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.787719  3510 net.cpp:137] Memory required for data: 275767296\n",
            "I0614 15:22:21.787729  3510 layer_factory.hpp:77] Creating layer scale3b_branch2c\n",
            "I0614 15:22:21.787739  3510 net.cpp:84] Creating Layer scale3b_branch2c\n",
            "I0614 15:22:21.787744  3510 net.cpp:406] scale3b_branch2c <- res3b_branch2c\n",
            "I0614 15:22:21.787750  3510 net.cpp:367] scale3b_branch2c -> res3b_branch2c (in-place)\n",
            "I0614 15:22:21.787776  3510 layer_factory.hpp:77] Creating layer scale3b_branch2c\n",
            "I0614 15:22:21.787830  3510 net.cpp:122] Setting up scale3b_branch2c\n",
            "I0614 15:22:21.787840  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.787844  3510 net.cpp:137] Memory required for data: 278978560\n",
            "I0614 15:22:21.787851  3510 layer_factory.hpp:77] Creating layer res3b\n",
            "I0614 15:22:21.787860  3510 net.cpp:84] Creating Layer res3b\n",
            "I0614 15:22:21.787866  3510 net.cpp:406] res3b <- res3a_res3a_relu_0_split_1\n",
            "I0614 15:22:21.787871  3510 net.cpp:406] res3b <- res3b_branch2c\n",
            "I0614 15:22:21.787879  3510 net.cpp:380] res3b -> res3b\n",
            "I0614 15:22:21.787896  3510 net.cpp:122] Setting up res3b\n",
            "I0614 15:22:21.787905  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.787910  3510 net.cpp:137] Memory required for data: 282189824\n",
            "I0614 15:22:21.787915  3510 layer_factory.hpp:77] Creating layer res3b_relu\n",
            "I0614 15:22:21.787921  3510 net.cpp:84] Creating Layer res3b_relu\n",
            "I0614 15:22:21.787937  3510 net.cpp:406] res3b_relu <- res3b\n",
            "I0614 15:22:21.787946  3510 net.cpp:367] res3b_relu -> res3b (in-place)\n",
            "I0614 15:22:21.789754  3510 net.cpp:122] Setting up res3b_relu\n",
            "I0614 15:22:21.789793  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.789801  3510 net.cpp:137] Memory required for data: 285401088\n",
            "I0614 15:22:21.789815  3510 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split\n",
            "I0614 15:22:21.789835  3510 net.cpp:84] Creating Layer res3b_res3b_relu_0_split\n",
            "I0614 15:22:21.789845  3510 net.cpp:406] res3b_res3b_relu_0_split <- res3b\n",
            "I0614 15:22:21.789855  3510 net.cpp:380] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0\n",
            "I0614 15:22:21.789865  3510 net.cpp:380] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1\n",
            "I0614 15:22:21.789904  3510 net.cpp:122] Setting up res3b_res3b_relu_0_split\n",
            "I0614 15:22:21.789914  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.789921  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.789934  3510 net.cpp:137] Memory required for data: 291823616\n",
            "I0614 15:22:21.789942  3510 layer_factory.hpp:77] Creating layer res3c_branch2a\n",
            "I0614 15:22:21.789950  3510 net.cpp:84] Creating Layer res3c_branch2a\n",
            "I0614 15:22:21.789956  3510 net.cpp:406] res3c_branch2a <- res3b_res3b_relu_0_split_0\n",
            "I0614 15:22:21.789963  3510 net.cpp:380] res3c_branch2a -> res3c_branch2a\n",
            "I0614 15:22:21.791607  3510 net.cpp:122] Setting up res3c_branch2a\n",
            "I0614 15:22:21.791632  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.791637  3510 net.cpp:137] Memory required for data: 292626432\n",
            "I0614 15:22:21.791646  3510 layer_factory.hpp:77] Creating layer bn3c_branch2a\n",
            "I0614 15:22:21.791653  3510 net.cpp:84] Creating Layer bn3c_branch2a\n",
            "I0614 15:22:21.791659  3510 net.cpp:406] bn3c_branch2a <- res3c_branch2a\n",
            "I0614 15:22:21.791666  3510 net.cpp:367] bn3c_branch2a -> res3c_branch2a (in-place)\n",
            "I0614 15:22:21.791783  3510 net.cpp:122] Setting up bn3c_branch2a\n",
            "I0614 15:22:21.791795  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.791800  3510 net.cpp:137] Memory required for data: 293429248\n",
            "I0614 15:22:21.791807  3510 layer_factory.hpp:77] Creating layer scale3c_branch2a\n",
            "I0614 15:22:21.791818  3510 net.cpp:84] Creating Layer scale3c_branch2a\n",
            "I0614 15:22:21.791823  3510 net.cpp:406] scale3c_branch2a <- res3c_branch2a\n",
            "I0614 15:22:21.791836  3510 net.cpp:367] scale3c_branch2a -> res3c_branch2a (in-place)\n",
            "I0614 15:22:21.791875  3510 layer_factory.hpp:77] Creating layer scale3c_branch2a\n",
            "I0614 15:22:21.791975  3510 net.cpp:122] Setting up scale3c_branch2a\n",
            "I0614 15:22:21.791985  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.791990  3510 net.cpp:137] Memory required for data: 294232064\n",
            "I0614 15:22:21.791997  3510 layer_factory.hpp:77] Creating layer res3c_branch2a_relu\n",
            "I0614 15:22:21.792007  3510 net.cpp:84] Creating Layer res3c_branch2a_relu\n",
            "I0614 15:22:21.792012  3510 net.cpp:406] res3c_branch2a_relu <- res3c_branch2a\n",
            "I0614 15:22:21.792018  3510 net.cpp:367] res3c_branch2a_relu -> res3c_branch2a (in-place)\n",
            "I0614 15:22:21.792529  3510 net.cpp:122] Setting up res3c_branch2a_relu\n",
            "I0614 15:22:21.792552  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.792557  3510 net.cpp:137] Memory required for data: 295034880\n",
            "I0614 15:22:21.792562  3510 layer_factory.hpp:77] Creating layer res3c_branch2b\n",
            "I0614 15:22:21.792570  3510 net.cpp:84] Creating Layer res3c_branch2b\n",
            "I0614 15:22:21.792578  3510 net.cpp:406] res3c_branch2b <- res3c_branch2a\n",
            "I0614 15:22:21.792587  3510 net.cpp:380] res3c_branch2b -> res3c_branch2b\n",
            "I0614 15:22:21.794409  3510 net.cpp:122] Setting up res3c_branch2b\n",
            "I0614 15:22:21.794432  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.794437  3510 net.cpp:137] Memory required for data: 295837696\n",
            "I0614 15:22:21.794445  3510 layer_factory.hpp:77] Creating layer bn3c_branch2b\n",
            "I0614 15:22:21.794453  3510 net.cpp:84] Creating Layer bn3c_branch2b\n",
            "I0614 15:22:21.794459  3510 net.cpp:406] bn3c_branch2b <- res3c_branch2b\n",
            "I0614 15:22:21.794466  3510 net.cpp:367] bn3c_branch2b -> res3c_branch2b (in-place)\n",
            "I0614 15:22:21.794576  3510 net.cpp:122] Setting up bn3c_branch2b\n",
            "I0614 15:22:21.794586  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.794591  3510 net.cpp:137] Memory required for data: 296640512\n",
            "I0614 15:22:21.794600  3510 layer_factory.hpp:77] Creating layer scale3c_branch2b\n",
            "I0614 15:22:21.794618  3510 net.cpp:84] Creating Layer scale3c_branch2b\n",
            "I0614 15:22:21.794626  3510 net.cpp:406] scale3c_branch2b <- res3c_branch2b\n",
            "I0614 15:22:21.794649  3510 net.cpp:367] scale3c_branch2b -> res3c_branch2b (in-place)\n",
            "I0614 15:22:21.794674  3510 layer_factory.hpp:77] Creating layer scale3c_branch2b\n",
            "I0614 15:22:21.794734  3510 net.cpp:122] Setting up scale3c_branch2b\n",
            "I0614 15:22:21.797169  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.797188  3510 net.cpp:137] Memory required for data: 297443328\n",
            "I0614 15:22:21.797199  3510 layer_factory.hpp:77] Creating layer res3c_branch2b_relu\n",
            "I0614 15:22:21.797209  3510 net.cpp:84] Creating Layer res3c_branch2b_relu\n",
            "I0614 15:22:21.797217  3510 net.cpp:406] res3c_branch2b_relu <- res3c_branch2b\n",
            "I0614 15:22:21.797227  3510 net.cpp:367] res3c_branch2b_relu -> res3c_branch2b (in-place)\n",
            "I0614 15:22:21.797726  3510 net.cpp:122] Setting up res3c_branch2b_relu\n",
            "I0614 15:22:21.797747  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.797752  3510 net.cpp:137] Memory required for data: 298246144\n",
            "I0614 15:22:21.797757  3510 layer_factory.hpp:77] Creating layer res3c_branch2c\n",
            "I0614 15:22:21.797765  3510 net.cpp:84] Creating Layer res3c_branch2c\n",
            "I0614 15:22:21.797777  3510 net.cpp:406] res3c_branch2c <- res3c_branch2b\n",
            "I0614 15:22:21.797785  3510 net.cpp:380] res3c_branch2c -> res3c_branch2c\n",
            "I0614 15:22:21.801084  3510 net.cpp:122] Setting up res3c_branch2c\n",
            "I0614 15:22:21.801110  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.801117  3510 net.cpp:137] Memory required for data: 301457408\n",
            "I0614 15:22:21.801129  3510 layer_factory.hpp:77] Creating layer bn3c_branch2c\n",
            "I0614 15:22:21.801139  3510 net.cpp:84] Creating Layer bn3c_branch2c\n",
            "I0614 15:22:21.801148  3510 net.cpp:406] bn3c_branch2c <- res3c_branch2c\n",
            "I0614 15:22:21.801154  3510 net.cpp:367] bn3c_branch2c -> res3c_branch2c (in-place)\n",
            "I0614 15:22:21.801288  3510 net.cpp:122] Setting up bn3c_branch2c\n",
            "I0614 15:22:21.801301  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.801307  3510 net.cpp:137] Memory required for data: 304668672\n",
            "I0614 15:22:21.801319  3510 layer_factory.hpp:77] Creating layer scale3c_branch2c\n",
            "I0614 15:22:21.801328  3510 net.cpp:84] Creating Layer scale3c_branch2c\n",
            "I0614 15:22:21.801337  3510 net.cpp:406] scale3c_branch2c <- res3c_branch2c\n",
            "I0614 15:22:21.801344  3510 net.cpp:367] scale3c_branch2c -> res3c_branch2c (in-place)\n",
            "I0614 15:22:21.801370  3510 layer_factory.hpp:77] Creating layer scale3c_branch2c\n",
            "I0614 15:22:21.801445  3510 net.cpp:122] Setting up scale3c_branch2c\n",
            "I0614 15:22:21.801455  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.801462  3510 net.cpp:137] Memory required for data: 307879936\n",
            "I0614 15:22:21.801472  3510 layer_factory.hpp:77] Creating layer res3c\n",
            "I0614 15:22:21.801481  3510 net.cpp:84] Creating Layer res3c\n",
            "I0614 15:22:21.801488  3510 net.cpp:406] res3c <- res3b_res3b_relu_0_split_1\n",
            "I0614 15:22:21.801496  3510 net.cpp:406] res3c <- res3c_branch2c\n",
            "I0614 15:22:21.801506  3510 net.cpp:380] res3c -> res3c\n",
            "I0614 15:22:21.801519  3510 net.cpp:122] Setting up res3c\n",
            "I0614 15:22:21.801528  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.801532  3510 net.cpp:137] Memory required for data: 311091200\n",
            "I0614 15:22:21.801537  3510 layer_factory.hpp:77] Creating layer res3c_relu\n",
            "I0614 15:22:21.801542  3510 net.cpp:84] Creating Layer res3c_relu\n",
            "I0614 15:22:21.801545  3510 net.cpp:406] res3c_relu <- res3c\n",
            "I0614 15:22:21.801549  3510 net.cpp:367] res3c_relu -> res3c (in-place)\n",
            "I0614 15:22:21.802018  3510 net.cpp:122] Setting up res3c_relu\n",
            "I0614 15:22:21.802039  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.802047  3510 net.cpp:137] Memory required for data: 314302464\n",
            "I0614 15:22:21.802052  3510 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split\n",
            "I0614 15:22:21.802063  3510 net.cpp:84] Creating Layer res3c_res3c_relu_0_split\n",
            "I0614 15:22:21.802071  3510 net.cpp:406] res3c_res3c_relu_0_split <- res3c\n",
            "I0614 15:22:21.802081  3510 net.cpp:380] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0\n",
            "I0614 15:22:21.802093  3510 net.cpp:380] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1\n",
            "I0614 15:22:21.802129  3510 net.cpp:122] Setting up res3c_res3c_relu_0_split\n",
            "I0614 15:22:21.802139  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.802148  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.802155  3510 net.cpp:137] Memory required for data: 320724992\n",
            "I0614 15:22:21.802162  3510 layer_factory.hpp:77] Creating layer res3d_branch2a\n",
            "I0614 15:22:21.802172  3510 net.cpp:84] Creating Layer res3d_branch2a\n",
            "I0614 15:22:21.802181  3510 net.cpp:406] res3d_branch2a <- res3c_res3c_relu_0_split_0\n",
            "I0614 15:22:21.802189  3510 net.cpp:380] res3d_branch2a -> res3d_branch2a\n",
            "I0614 15:22:21.804426  3510 net.cpp:122] Setting up res3d_branch2a\n",
            "I0614 15:22:21.804450  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.804455  3510 net.cpp:137] Memory required for data: 321527808\n",
            "I0614 15:22:21.804463  3510 layer_factory.hpp:77] Creating layer bn3d_branch2a\n",
            "I0614 15:22:21.804477  3510 net.cpp:84] Creating Layer bn3d_branch2a\n",
            "I0614 15:22:21.804486  3510 net.cpp:406] bn3d_branch2a <- res3d_branch2a\n",
            "I0614 15:22:21.804494  3510 net.cpp:367] bn3d_branch2a -> res3d_branch2a (in-place)\n",
            "I0614 15:22:21.804606  3510 net.cpp:122] Setting up bn3d_branch2a\n",
            "I0614 15:22:21.804617  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.804621  3510 net.cpp:137] Memory required for data: 322330624\n",
            "I0614 15:22:21.804662  3510 layer_factory.hpp:77] Creating layer scale3d_branch2a\n",
            "I0614 15:22:21.804672  3510 net.cpp:84] Creating Layer scale3d_branch2a\n",
            "I0614 15:22:21.804677  3510 net.cpp:406] scale3d_branch2a <- res3d_branch2a\n",
            "I0614 15:22:21.804685  3510 net.cpp:367] scale3d_branch2a -> res3d_branch2a (in-place)\n",
            "I0614 15:22:21.804711  3510 layer_factory.hpp:77] Creating layer scale3d_branch2a\n",
            "I0614 15:22:21.804776  3510 net.cpp:122] Setting up scale3d_branch2a\n",
            "I0614 15:22:21.804785  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.804790  3510 net.cpp:137] Memory required for data: 323133440\n",
            "I0614 15:22:21.804800  3510 layer_factory.hpp:77] Creating layer res3d_branch2a_relu\n",
            "I0614 15:22:21.804808  3510 net.cpp:84] Creating Layer res3d_branch2a_relu\n",
            "I0614 15:22:21.804816  3510 net.cpp:406] res3d_branch2a_relu <- res3d_branch2a\n",
            "I0614 15:22:21.804823  3510 net.cpp:367] res3d_branch2a_relu -> res3d_branch2a (in-place)\n",
            "I0614 15:22:21.805326  3510 net.cpp:122] Setting up res3d_branch2a_relu\n",
            "I0614 15:22:21.805348  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.805353  3510 net.cpp:137] Memory required for data: 323936256\n",
            "I0614 15:22:21.805358  3510 layer_factory.hpp:77] Creating layer res3d_branch2b\n",
            "I0614 15:22:21.805372  3510 net.cpp:84] Creating Layer res3d_branch2b\n",
            "I0614 15:22:21.805382  3510 net.cpp:406] res3d_branch2b <- res3d_branch2a\n",
            "I0614 15:22:21.805390  3510 net.cpp:380] res3d_branch2b -> res3d_branch2b\n",
            "I0614 15:22:21.808339  3510 net.cpp:122] Setting up res3d_branch2b\n",
            "I0614 15:22:21.808362  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.808367  3510 net.cpp:137] Memory required for data: 324739072\n",
            "I0614 15:22:21.808374  3510 layer_factory.hpp:77] Creating layer bn3d_branch2b\n",
            "I0614 15:22:21.808387  3510 net.cpp:84] Creating Layer bn3d_branch2b\n",
            "I0614 15:22:21.808393  3510 net.cpp:406] bn3d_branch2b <- res3d_branch2b\n",
            "I0614 15:22:21.808403  3510 net.cpp:367] bn3d_branch2b -> res3d_branch2b (in-place)\n",
            "I0614 15:22:21.808506  3510 net.cpp:122] Setting up bn3d_branch2b\n",
            "I0614 15:22:21.808517  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.808521  3510 net.cpp:137] Memory required for data: 325541888\n",
            "I0614 15:22:21.808531  3510 layer_factory.hpp:77] Creating layer scale3d_branch2b\n",
            "I0614 15:22:21.808542  3510 net.cpp:84] Creating Layer scale3d_branch2b\n",
            "I0614 15:22:21.808548  3510 net.cpp:406] scale3d_branch2b <- res3d_branch2b\n",
            "I0614 15:22:21.808557  3510 net.cpp:367] scale3d_branch2b -> res3d_branch2b (in-place)\n",
            "I0614 15:22:21.808583  3510 layer_factory.hpp:77] Creating layer scale3d_branch2b\n",
            "I0614 15:22:21.808663  3510 net.cpp:122] Setting up scale3d_branch2b\n",
            "I0614 15:22:21.808674  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.808678  3510 net.cpp:137] Memory required for data: 326344704\n",
            "I0614 15:22:21.808688  3510 layer_factory.hpp:77] Creating layer res3d_branch2b_relu\n",
            "I0614 15:22:21.808697  3510 net.cpp:84] Creating Layer res3d_branch2b_relu\n",
            "I0614 15:22:21.808704  3510 net.cpp:406] res3d_branch2b_relu <- res3d_branch2b\n",
            "I0614 15:22:21.808712  3510 net.cpp:367] res3d_branch2b_relu -> res3d_branch2b (in-place)\n",
            "I0614 15:22:21.810379  3510 net.cpp:122] Setting up res3d_branch2b_relu\n",
            "I0614 15:22:21.810402  3510 net.cpp:129] Top shape: 2 128 28 28 (200704)\n",
            "I0614 15:22:21.810407  3510 net.cpp:137] Memory required for data: 327147520\n",
            "I0614 15:22:21.810413  3510 layer_factory.hpp:77] Creating layer res3d_branch2c\n",
            "I0614 15:22:21.810421  3510 net.cpp:84] Creating Layer res3d_branch2c\n",
            "I0614 15:22:21.885030  3510 net.cpp:406] res3d_branch2c <- res3d_branch2b\n",
            "I0614 15:22:21.885053  3510 net.cpp:380] res3d_branch2c -> res3d_branch2c\n",
            "I0614 15:22:21.887921  3510 net.cpp:122] Setting up res3d_branch2c\n",
            "I0614 15:22:21.887964  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.887971  3510 net.cpp:137] Memory required for data: 330358784\n",
            "I0614 15:22:21.887982  3510 layer_factory.hpp:77] Creating layer bn3d_branch2c\n",
            "I0614 15:22:21.887992  3510 net.cpp:84] Creating Layer bn3d_branch2c\n",
            "I0614 15:22:21.888000  3510 net.cpp:406] bn3d_branch2c <- res3d_branch2c\n",
            "I0614 15:22:21.888008  3510 net.cpp:367] bn3d_branch2c -> res3d_branch2c (in-place)\n",
            "I0614 15:22:21.888151  3510 net.cpp:122] Setting up bn3d_branch2c\n",
            "I0614 15:22:21.888165  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.888183  3510 net.cpp:137] Memory required for data: 333570048\n",
            "I0614 15:22:21.888195  3510 layer_factory.hpp:77] Creating layer scale3d_branch2c\n",
            "I0614 15:22:21.888204  3510 net.cpp:84] Creating Layer scale3d_branch2c\n",
            "I0614 15:22:21.888211  3510 net.cpp:406] scale3d_branch2c <- res3d_branch2c\n",
            "I0614 15:22:21.888219  3510 net.cpp:367] scale3d_branch2c -> res3d_branch2c (in-place)\n",
            "I0614 15:22:21.888273  3510 layer_factory.hpp:77] Creating layer scale3d_branch2c\n",
            "I0614 15:22:21.888345  3510 net.cpp:122] Setting up scale3d_branch2c\n",
            "I0614 15:22:21.888365  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.888372  3510 net.cpp:137] Memory required for data: 336781312\n",
            "I0614 15:22:21.888382  3510 layer_factory.hpp:77] Creating layer res3d\n",
            "I0614 15:22:21.888396  3510 net.cpp:84] Creating Layer res3d\n",
            "I0614 15:22:21.888401  3510 net.cpp:406] res3d <- res3c_res3c_relu_0_split_1\n",
            "I0614 15:22:21.888418  3510 net.cpp:406] res3d <- res3d_branch2c\n",
            "I0614 15:22:21.888427  3510 net.cpp:380] res3d -> res3d\n",
            "I0614 15:22:21.888443  3510 net.cpp:122] Setting up res3d\n",
            "I0614 15:22:21.888451  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.888458  3510 net.cpp:137] Memory required for data: 339992576\n",
            "I0614 15:22:21.888463  3510 layer_factory.hpp:77] Creating layer res3d_relu\n",
            "I0614 15:22:21.888470  3510 net.cpp:84] Creating Layer res3d_relu\n",
            "I0614 15:22:21.888476  3510 net.cpp:406] res3d_relu <- res3d\n",
            "I0614 15:22:21.888497  3510 net.cpp:367] res3d_relu -> res3d (in-place)\n",
            "I0614 15:22:21.889183  3510 net.cpp:122] Setting up res3d_relu\n",
            "I0614 15:22:21.889202  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.889209  3510 net.cpp:137] Memory required for data: 343203840\n",
            "I0614 15:22:21.889215  3510 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split\n",
            "I0614 15:22:21.889225  3510 net.cpp:84] Creating Layer res3d_res3d_relu_0_split\n",
            "I0614 15:22:21.889231  3510 net.cpp:406] res3d_res3d_relu_0_split <- res3d\n",
            "I0614 15:22:21.889248  3510 net.cpp:380] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0\n",
            "I0614 15:22:21.889257  3510 net.cpp:380] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1\n",
            "I0614 15:22:21.889287  3510 net.cpp:122] Setting up res3d_res3d_relu_0_split\n",
            "I0614 15:22:21.889297  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.889303  3510 net.cpp:129] Top shape: 2 512 28 28 (802816)\n",
            "I0614 15:22:21.889309  3510 net.cpp:137] Memory required for data: 349626368\n",
            "I0614 15:22:21.889324  3510 layer_factory.hpp:77] Creating layer res4a_branch1\n",
            "I0614 15:22:21.889341  3510 net.cpp:84] Creating Layer res4a_branch1\n",
            "I0614 15:22:21.889348  3510 net.cpp:406] res4a_branch1 <- res3d_res3d_relu_0_split_0\n",
            "I0614 15:22:21.889355  3510 net.cpp:380] res4a_branch1 -> res4a_branch1\n",
            "I0614 15:22:21.893049  3510 net.cpp:122] Setting up res4a_branch1\n",
            "I0614 15:22:21.893075  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.893083  3510 net.cpp:137] Memory required for data: 351232000\n",
            "I0614 15:22:21.893102  3510 layer_factory.hpp:77] Creating layer bn4a_branch1\n",
            "I0614 15:22:21.893122  3510 net.cpp:84] Creating Layer bn4a_branch1\n",
            "I0614 15:22:21.893131  3510 net.cpp:406] bn4a_branch1 <- res4a_branch1\n",
            "I0614 15:22:21.893144  3510 net.cpp:367] bn4a_branch1 -> res4a_branch1 (in-place)\n",
            "I0614 15:22:21.893291  3510 net.cpp:122] Setting up bn4a_branch1\n",
            "I0614 15:22:21.893301  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.893308  3510 net.cpp:137] Memory required for data: 352837632\n",
            "I0614 15:22:21.893319  3510 layer_factory.hpp:77] Creating layer scale4a_branch1\n",
            "I0614 15:22:21.893328  3510 net.cpp:84] Creating Layer scale4a_branch1\n",
            "I0614 15:22:21.893334  3510 net.cpp:406] scale4a_branch1 <- res4a_branch1\n",
            "I0614 15:22:21.893342  3510 net.cpp:367] scale4a_branch1 -> res4a_branch1 (in-place)\n",
            "I0614 15:22:21.893370  3510 layer_factory.hpp:77] Creating layer scale4a_branch1\n",
            "I0614 15:22:21.893436  3510 net.cpp:122] Setting up scale4a_branch1\n",
            "I0614 15:22:21.893445  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.893452  3510 net.cpp:137] Memory required for data: 354443264\n",
            "I0614 15:22:21.893461  3510 layer_factory.hpp:77] Creating layer res4a_branch2a\n",
            "I0614 15:22:21.893471  3510 net.cpp:84] Creating Layer res4a_branch2a\n",
            "I0614 15:22:21.893477  3510 net.cpp:406] res4a_branch2a <- res3d_res3d_relu_0_split_1\n",
            "I0614 15:22:21.893486  3510 net.cpp:380] res4a_branch2a -> res4a_branch2a\n",
            "I0614 15:22:21.897687  3510 net.cpp:122] Setting up res4a_branch2a\n",
            "I0614 15:22:21.897711  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.897719  3510 net.cpp:137] Memory required for data: 354844672\n",
            "I0614 15:22:21.897732  3510 layer_factory.hpp:77] Creating layer bn4a_branch2a\n",
            "I0614 15:22:21.897742  3510 net.cpp:84] Creating Layer bn4a_branch2a\n",
            "I0614 15:22:21.897753  3510 net.cpp:406] bn4a_branch2a <- res4a_branch2a\n",
            "I0614 15:22:21.897759  3510 net.cpp:367] bn4a_branch2a -> res4a_branch2a (in-place)\n",
            "I0614 15:22:21.897897  3510 net.cpp:122] Setting up bn4a_branch2a\n",
            "I0614 15:22:21.897909  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.897917  3510 net.cpp:137] Memory required for data: 355246080\n",
            "I0614 15:22:21.897936  3510 layer_factory.hpp:77] Creating layer scale4a_branch2a\n",
            "I0614 15:22:21.897948  3510 net.cpp:84] Creating Layer scale4a_branch2a\n",
            "I0614 15:22:21.897955  3510 net.cpp:406] scale4a_branch2a <- res4a_branch2a\n",
            "I0614 15:22:21.897964  3510 net.cpp:367] scale4a_branch2a -> res4a_branch2a (in-place)\n",
            "I0614 15:22:21.897991  3510 layer_factory.hpp:77] Creating layer scale4a_branch2a\n",
            "I0614 15:22:21.898079  3510 net.cpp:122] Setting up scale4a_branch2a\n",
            "I0614 15:22:21.898097  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.898102  3510 net.cpp:137] Memory required for data: 355647488\n",
            "I0614 15:22:21.898109  3510 layer_factory.hpp:77] Creating layer res4a_branch2a_relu\n",
            "I0614 15:22:21.898119  3510 net.cpp:84] Creating Layer res4a_branch2a_relu\n",
            "I0614 15:22:21.898128  3510 net.cpp:406] res4a_branch2a_relu <- res4a_branch2a\n",
            "I0614 15:22:21.898135  3510 net.cpp:367] res4a_branch2a_relu -> res4a_branch2a (in-place)\n",
            "I0614 15:22:21.898756  3510 net.cpp:122] Setting up res4a_branch2a_relu\n",
            "I0614 15:22:21.898777  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.898785  3510 net.cpp:137] Memory required for data: 356048896\n",
            "I0614 15:22:21.898793  3510 layer_factory.hpp:77] Creating layer res4a_branch2b\n",
            "I0614 15:22:21.898805  3510 net.cpp:84] Creating Layer res4a_branch2b\n",
            "I0614 15:22:21.898813  3510 net.cpp:406] res4a_branch2b <- res4a_branch2a\n",
            "I0614 15:22:21.898834  3510 net.cpp:380] res4a_branch2b -> res4a_branch2b\n",
            "I0614 15:22:21.908964  3510 net.cpp:122] Setting up res4a_branch2b\n",
            "I0614 15:22:21.908999  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.909009  3510 net.cpp:137] Memory required for data: 356450304\n",
            "I0614 15:22:21.909021  3510 layer_factory.hpp:77] Creating layer bn4a_branch2b\n",
            "I0614 15:22:21.909034  3510 net.cpp:84] Creating Layer bn4a_branch2b\n",
            "I0614 15:22:21.909040  3510 net.cpp:406] bn4a_branch2b <- res4a_branch2b\n",
            "I0614 15:22:21.909049  3510 net.cpp:367] bn4a_branch2b -> res4a_branch2b (in-place)\n",
            "I0614 15:22:21.909157  3510 net.cpp:122] Setting up bn4a_branch2b\n",
            "I0614 15:22:21.909169  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.909173  3510 net.cpp:137] Memory required for data: 356851712\n",
            "I0614 15:22:21.909183  3510 layer_factory.hpp:77] Creating layer scale4a_branch2b\n",
            "I0614 15:22:21.909193  3510 net.cpp:84] Creating Layer scale4a_branch2b\n",
            "I0614 15:22:21.909200  3510 net.cpp:406] scale4a_branch2b <- res4a_branch2b\n",
            "I0614 15:22:21.909209  3510 net.cpp:367] scale4a_branch2b -> res4a_branch2b (in-place)\n",
            "I0614 15:22:21.909246  3510 layer_factory.hpp:77] Creating layer scale4a_branch2b\n",
            "I0614 15:22:21.909307  3510 net.cpp:122] Setting up scale4a_branch2b\n",
            "I0614 15:22:21.909320  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.909327  3510 net.cpp:137] Memory required for data: 357253120\n",
            "I0614 15:22:21.909338  3510 layer_factory.hpp:77] Creating layer res4a_branch2b_relu\n",
            "I0614 15:22:21.909351  3510 net.cpp:84] Creating Layer res4a_branch2b_relu\n",
            "I0614 15:22:21.909358  3510 net.cpp:406] res4a_branch2b_relu <- res4a_branch2b\n",
            "I0614 15:22:21.909366  3510 net.cpp:367] res4a_branch2b_relu -> res4a_branch2b (in-place)\n",
            "I0614 15:22:21.909873  3510 net.cpp:122] Setting up res4a_branch2b_relu\n",
            "I0614 15:22:21.909895  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.909900  3510 net.cpp:137] Memory required for data: 357654528\n",
            "I0614 15:22:21.909905  3510 layer_factory.hpp:77] Creating layer res4a_branch2c\n",
            "I0614 15:22:21.909920  3510 net.cpp:84] Creating Layer res4a_branch2c\n",
            "I0614 15:22:21.909940  3510 net.cpp:406] res4a_branch2c <- res4a_branch2b\n",
            "I0614 15:22:21.909948  3510 net.cpp:380] res4a_branch2c -> res4a_branch2c\n",
            "I0614 15:22:21.912825  3510 net.cpp:122] Setting up res4a_branch2c\n",
            "I0614 15:22:21.912848  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.912853  3510 net.cpp:137] Memory required for data: 359260160\n",
            "I0614 15:22:21.912861  3510 layer_factory.hpp:77] Creating layer bn4a_branch2c\n",
            "I0614 15:22:21.912875  3510 net.cpp:84] Creating Layer bn4a_branch2c\n",
            "I0614 15:22:21.912881  3510 net.cpp:406] bn4a_branch2c <- res4a_branch2c\n",
            "I0614 15:22:21.912890  3510 net.cpp:367] bn4a_branch2c -> res4a_branch2c (in-place)\n",
            "I0614 15:22:21.913018  3510 net.cpp:122] Setting up bn4a_branch2c\n",
            "I0614 15:22:21.913028  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.913033  3510 net.cpp:137] Memory required for data: 360865792\n",
            "I0614 15:22:21.913041  3510 layer_factory.hpp:77] Creating layer scale4a_branch2c\n",
            "I0614 15:22:21.913053  3510 net.cpp:84] Creating Layer scale4a_branch2c\n",
            "I0614 15:22:21.913060  3510 net.cpp:406] scale4a_branch2c <- res4a_branch2c\n",
            "I0614 15:22:21.913069  3510 net.cpp:367] scale4a_branch2c -> res4a_branch2c (in-place)\n",
            "I0614 15:22:21.913102  3510 layer_factory.hpp:77] Creating layer scale4a_branch2c\n",
            "I0614 15:22:21.913169  3510 net.cpp:122] Setting up scale4a_branch2c\n",
            "I0614 15:22:21.913180  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.913185  3510 net.cpp:137] Memory required for data: 362471424\n",
            "I0614 15:22:21.913195  3510 layer_factory.hpp:77] Creating layer res4a\n",
            "I0614 15:22:21.913204  3510 net.cpp:84] Creating Layer res4a\n",
            "I0614 15:22:21.913211  3510 net.cpp:406] res4a <- res4a_branch1\n",
            "I0614 15:22:21.913219  3510 net.cpp:406] res4a <- res4a_branch2c\n",
            "I0614 15:22:21.913228  3510 net.cpp:380] res4a -> res4a\n",
            "I0614 15:22:21.913245  3510 net.cpp:122] Setting up res4a\n",
            "I0614 15:22:21.913254  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.913261  3510 net.cpp:137] Memory required for data: 364077056\n",
            "I0614 15:22:21.913269  3510 layer_factory.hpp:77] Creating layer res4a_relu\n",
            "I0614 15:22:21.913276  3510 net.cpp:84] Creating Layer res4a_relu\n",
            "I0614 15:22:21.913283  3510 net.cpp:406] res4a_relu <- res4a\n",
            "I0614 15:22:21.913291  3510 net.cpp:367] res4a_relu -> res4a (in-place)\n",
            "I0614 15:22:21.913800  3510 net.cpp:122] Setting up res4a_relu\n",
            "I0614 15:22:21.913820  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.913825  3510 net.cpp:137] Memory required for data: 365682688\n",
            "I0614 15:22:21.913830  3510 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split\n",
            "I0614 15:22:21.913841  3510 net.cpp:84] Creating Layer res4a_res4a_relu_0_split\n",
            "I0614 15:22:21.913849  3510 net.cpp:406] res4a_res4a_relu_0_split <- res4a\n",
            "I0614 15:22:21.913859  3510 net.cpp:380] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0\n",
            "I0614 15:22:21.913870  3510 net.cpp:380] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1\n",
            "I0614 15:22:21.913906  3510 net.cpp:122] Setting up res4a_res4a_relu_0_split\n",
            "I0614 15:22:21.913936  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.913946  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.913954  3510 net.cpp:137] Memory required for data: 368893952\n",
            "I0614 15:22:21.913960  3510 layer_factory.hpp:77] Creating layer res4b_branch2a\n",
            "I0614 15:22:21.913983  3510 net.cpp:84] Creating Layer res4b_branch2a\n",
            "I0614 15:22:21.913991  3510 net.cpp:406] res4b_branch2a <- res4a_res4a_relu_0_split_0\n",
            "I0614 15:22:21.914000  3510 net.cpp:380] res4b_branch2a -> res4b_branch2a\n",
            "I0614 15:22:21.917063  3510 net.cpp:122] Setting up res4b_branch2a\n",
            "I0614 15:22:21.917089  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.917104  3510 net.cpp:137] Memory required for data: 369295360\n",
            "I0614 15:22:21.917116  3510 layer_factory.hpp:77] Creating layer bn4b_branch2a\n",
            "I0614 15:22:21.917127  3510 net.cpp:84] Creating Layer bn4b_branch2a\n",
            "I0614 15:22:21.917135  3510 net.cpp:406] bn4b_branch2a <- res4b_branch2a\n",
            "I0614 15:22:21.917142  3510 net.cpp:367] bn4b_branch2a -> res4b_branch2a (in-place)\n",
            "I0614 15:22:21.917270  3510 net.cpp:122] Setting up bn4b_branch2a\n",
            "I0614 15:22:21.917282  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.917286  3510 net.cpp:137] Memory required for data: 369696768\n",
            "I0614 15:22:21.917295  3510 layer_factory.hpp:77] Creating layer scale4b_branch2a\n",
            "I0614 15:22:21.917304  3510 net.cpp:84] Creating Layer scale4b_branch2a\n",
            "I0614 15:22:21.917310  3510 net.cpp:406] scale4b_branch2a <- res4b_branch2a\n",
            "I0614 15:22:21.917317  3510 net.cpp:367] scale4b_branch2a -> res4b_branch2a (in-place)\n",
            "I0614 15:22:21.917346  3510 layer_factory.hpp:77] Creating layer scale4b_branch2a\n",
            "I0614 15:22:21.917430  3510 net.cpp:122] Setting up scale4b_branch2a\n",
            "I0614 15:22:21.917443  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.917446  3510 net.cpp:137] Memory required for data: 370098176\n",
            "I0614 15:22:21.917454  3510 layer_factory.hpp:77] Creating layer res4b_branch2a_relu\n",
            "I0614 15:22:21.917464  3510 net.cpp:84] Creating Layer res4b_branch2a_relu\n",
            "I0614 15:22:21.917470  3510 net.cpp:406] res4b_branch2a_relu <- res4b_branch2a\n",
            "I0614 15:22:21.917486  3510 net.cpp:367] res4b_branch2a_relu -> res4b_branch2a (in-place)\n",
            "I0614 15:22:21.917981  3510 net.cpp:122] Setting up res4b_branch2a_relu\n",
            "I0614 15:22:21.918000  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.918005  3510 net.cpp:137] Memory required for data: 370499584\n",
            "I0614 15:22:21.918010  3510 layer_factory.hpp:77] Creating layer res4b_branch2b\n",
            "I0614 15:22:21.918020  3510 net.cpp:84] Creating Layer res4b_branch2b\n",
            "I0614 15:22:21.918030  3510 net.cpp:406] res4b_branch2b <- res4b_branch2a\n",
            "I0614 15:22:21.918037  3510 net.cpp:380] res4b_branch2b -> res4b_branch2b\n",
            "I0614 15:22:21.921309  3510 net.cpp:122] Setting up res4b_branch2b\n",
            "I0614 15:22:21.921331  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.921339  3510 net.cpp:137] Memory required for data: 370900992\n",
            "I0614 15:22:21.921350  3510 layer_factory.hpp:77] Creating layer bn4b_branch2b\n",
            "I0614 15:22:21.921360  3510 net.cpp:84] Creating Layer bn4b_branch2b\n",
            "I0614 15:22:21.921368  3510 net.cpp:406] bn4b_branch2b <- res4b_branch2b\n",
            "I0614 15:22:21.921377  3510 net.cpp:367] bn4b_branch2b -> res4b_branch2b (in-place)\n",
            "I0614 15:22:21.921494  3510 net.cpp:122] Setting up bn4b_branch2b\n",
            "I0614 15:22:21.921509  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.921515  3510 net.cpp:137] Memory required for data: 371302400\n",
            "I0614 15:22:21.921527  3510 layer_factory.hpp:77] Creating layer scale4b_branch2b\n",
            "I0614 15:22:21.921537  3510 net.cpp:84] Creating Layer scale4b_branch2b\n",
            "I0614 15:22:21.921546  3510 net.cpp:406] scale4b_branch2b <- res4b_branch2b\n",
            "I0614 15:22:21.921553  3510 net.cpp:367] scale4b_branch2b -> res4b_branch2b (in-place)\n",
            "I0614 15:22:21.921583  3510 layer_factory.hpp:77] Creating layer scale4b_branch2b\n",
            "I0614 15:22:21.921658  3510 net.cpp:122] Setting up scale4b_branch2b\n",
            "I0614 15:22:21.921670  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.921674  3510 net.cpp:137] Memory required for data: 371703808\n",
            "I0614 15:22:21.921682  3510 layer_factory.hpp:77] Creating layer res4b_branch2b_relu\n",
            "I0614 15:22:21.921691  3510 net.cpp:84] Creating Layer res4b_branch2b_relu\n",
            "I0614 15:22:21.921698  3510 net.cpp:406] res4b_branch2b_relu <- res4b_branch2b\n",
            "I0614 15:22:21.921705  3510 net.cpp:367] res4b_branch2b_relu -> res4b_branch2b (in-place)\n",
            "I0614 15:22:21.922053  3510 net.cpp:122] Setting up res4b_branch2b_relu\n",
            "I0614 15:22:21.922070  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.922075  3510 net.cpp:137] Memory required for data: 372105216\n",
            "I0614 15:22:21.922080  3510 layer_factory.hpp:77] Creating layer res4b_branch2c\n",
            "I0614 15:22:21.922089  3510 net.cpp:84] Creating Layer res4b_branch2c\n",
            "I0614 15:22:21.922096  3510 net.cpp:406] res4b_branch2c <- res4b_branch2b\n",
            "I0614 15:22:21.922107  3510 net.cpp:380] res4b_branch2c -> res4b_branch2c\n",
            "I0614 15:22:21.926499  3510 net.cpp:122] Setting up res4b_branch2c\n",
            "I0614 15:22:21.926568  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.926573  3510 net.cpp:137] Memory required for data: 373710848\n",
            "I0614 15:22:21.926582  3510 layer_factory.hpp:77] Creating layer bn4b_branch2c\n",
            "I0614 15:22:21.926604  3510 net.cpp:84] Creating Layer bn4b_branch2c\n",
            "I0614 15:22:21.926609  3510 net.cpp:406] bn4b_branch2c <- res4b_branch2c\n",
            "I0614 15:22:21.926625  3510 net.cpp:367] bn4b_branch2c -> res4b_branch2c (in-place)\n",
            "I0614 15:22:21.926745  3510 net.cpp:122] Setting up bn4b_branch2c\n",
            "I0614 15:22:21.926753  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.926756  3510 net.cpp:137] Memory required for data: 375316480\n",
            "I0614 15:22:21.926764  3510 layer_factory.hpp:77] Creating layer scale4b_branch2c\n",
            "I0614 15:22:21.926771  3510 net.cpp:84] Creating Layer scale4b_branch2c\n",
            "I0614 15:22:21.984856  3510 net.cpp:406] scale4b_branch2c <- res4b_branch2c\n",
            "I0614 15:22:21.984876  3510 net.cpp:367] scale4b_branch2c -> res4b_branch2c (in-place)\n",
            "I0614 15:22:21.984946  3510 layer_factory.hpp:77] Creating layer scale4b_branch2c\n",
            "I0614 15:22:21.985044  3510 net.cpp:122] Setting up scale4b_branch2c\n",
            "I0614 15:22:21.985059  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.985065  3510 net.cpp:137] Memory required for data: 376922112\n",
            "I0614 15:22:21.985076  3510 layer_factory.hpp:77] Creating layer res4b\n",
            "I0614 15:22:21.985086  3510 net.cpp:84] Creating Layer res4b\n",
            "I0614 15:22:21.985103  3510 net.cpp:406] res4b <- res4a_res4a_relu_0_split_1\n",
            "I0614 15:22:21.985111  3510 net.cpp:406] res4b <- res4b_branch2c\n",
            "I0614 15:22:21.985119  3510 net.cpp:380] res4b -> res4b\n",
            "I0614 15:22:21.985143  3510 net.cpp:122] Setting up res4b\n",
            "I0614 15:22:21.985153  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.985160  3510 net.cpp:137] Memory required for data: 378527744\n",
            "I0614 15:22:21.985167  3510 layer_factory.hpp:77] Creating layer res4b_relu\n",
            "I0614 15:22:21.985175  3510 net.cpp:84] Creating Layer res4b_relu\n",
            "I0614 15:22:21.985183  3510 net.cpp:406] res4b_relu <- res4b\n",
            "I0614 15:22:21.985190  3510 net.cpp:367] res4b_relu -> res4b (in-place)\n",
            "I0614 15:22:21.985703  3510 net.cpp:122] Setting up res4b_relu\n",
            "I0614 15:22:21.985729  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.985738  3510 net.cpp:137] Memory required for data: 380133376\n",
            "I0614 15:22:21.985745  3510 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split\n",
            "I0614 15:22:21.985756  3510 net.cpp:84] Creating Layer res4b_res4b_relu_0_split\n",
            "I0614 15:22:21.985764  3510 net.cpp:406] res4b_res4b_relu_0_split <- res4b\n",
            "I0614 15:22:21.985774  3510 net.cpp:380] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0\n",
            "I0614 15:22:21.985785  3510 net.cpp:380] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1\n",
            "I0614 15:22:21.985827  3510 net.cpp:122] Setting up res4b_res4b_relu_0_split\n",
            "I0614 15:22:21.985838  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.985846  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.985853  3510 net.cpp:137] Memory required for data: 383344640\n",
            "I0614 15:22:21.985860  3510 layer_factory.hpp:77] Creating layer res4c_branch2a\n",
            "I0614 15:22:21.985870  3510 net.cpp:84] Creating Layer res4c_branch2a\n",
            "I0614 15:22:21.985877  3510 net.cpp:406] res4c_branch2a <- res4b_res4b_relu_0_split_0\n",
            "I0614 15:22:21.985885  3510 net.cpp:380] res4c_branch2a -> res4c_branch2a\n",
            "I0614 15:22:21.988322  3510 net.cpp:122] Setting up res4c_branch2a\n",
            "I0614 15:22:21.988346  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.988353  3510 net.cpp:137] Memory required for data: 383746048\n",
            "I0614 15:22:21.988360  3510 layer_factory.hpp:77] Creating layer bn4c_branch2a\n",
            "I0614 15:22:21.988377  3510 net.cpp:84] Creating Layer bn4c_branch2a\n",
            "I0614 15:22:21.988385  3510 net.cpp:406] bn4c_branch2a <- res4c_branch2a\n",
            "I0614 15:22:21.988392  3510 net.cpp:367] bn4c_branch2a -> res4c_branch2a (in-place)\n",
            "I0614 15:22:21.988507  3510 net.cpp:122] Setting up bn4c_branch2a\n",
            "I0614 15:22:21.988517  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.988523  3510 net.cpp:137] Memory required for data: 384147456\n",
            "I0614 15:22:21.988538  3510 layer_factory.hpp:77] Creating layer scale4c_branch2a\n",
            "I0614 15:22:21.988548  3510 net.cpp:84] Creating Layer scale4c_branch2a\n",
            "I0614 15:22:21.988556  3510 net.cpp:406] scale4c_branch2a <- res4c_branch2a\n",
            "I0614 15:22:21.988565  3510 net.cpp:367] scale4c_branch2a -> res4c_branch2a (in-place)\n",
            "I0614 15:22:21.988595  3510 layer_factory.hpp:77] Creating layer scale4c_branch2a\n",
            "I0614 15:22:21.988665  3510 net.cpp:122] Setting up scale4c_branch2a\n",
            "I0614 15:22:21.988677  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.988682  3510 net.cpp:137] Memory required for data: 384548864\n",
            "I0614 15:22:21.988688  3510 layer_factory.hpp:77] Creating layer res4c_branch2a_relu\n",
            "I0614 15:22:21.988695  3510 net.cpp:84] Creating Layer res4c_branch2a_relu\n",
            "I0614 15:22:21.988704  3510 net.cpp:406] res4c_branch2a_relu <- res4c_branch2a\n",
            "I0614 15:22:21.988713  3510 net.cpp:367] res4c_branch2a_relu -> res4c_branch2a (in-place)\n",
            "I0614 15:22:21.989208  3510 net.cpp:122] Setting up res4c_branch2a_relu\n",
            "I0614 15:22:21.989238  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.989243  3510 net.cpp:137] Memory required for data: 384950272\n",
            "I0614 15:22:21.989248  3510 layer_factory.hpp:77] Creating layer res4c_branch2b\n",
            "I0614 15:22:21.989262  3510 net.cpp:84] Creating Layer res4c_branch2b\n",
            "I0614 15:22:21.989272  3510 net.cpp:406] res4c_branch2b <- res4c_branch2a\n",
            "I0614 15:22:21.989281  3510 net.cpp:380] res4c_branch2b -> res4c_branch2b\n",
            "I0614 15:22:21.992404  3510 net.cpp:122] Setting up res4c_branch2b\n",
            "I0614 15:22:21.992425  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.992430  3510 net.cpp:137] Memory required for data: 385351680\n",
            "I0614 15:22:21.992439  3510 layer_factory.hpp:77] Creating layer bn4c_branch2b\n",
            "I0614 15:22:21.992446  3510 net.cpp:84] Creating Layer bn4c_branch2b\n",
            "I0614 15:22:21.992453  3510 net.cpp:406] bn4c_branch2b <- res4c_branch2b\n",
            "I0614 15:22:21.992462  3510 net.cpp:367] bn4c_branch2b -> res4c_branch2b (in-place)\n",
            "I0614 15:22:21.992575  3510 net.cpp:122] Setting up bn4c_branch2b\n",
            "I0614 15:22:21.992594  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.992609  3510 net.cpp:137] Memory required for data: 385753088\n",
            "I0614 15:22:21.992619  3510 layer_factory.hpp:77] Creating layer scale4c_branch2b\n",
            "I0614 15:22:21.992628  3510 net.cpp:84] Creating Layer scale4c_branch2b\n",
            "I0614 15:22:21.992635  3510 net.cpp:406] scale4c_branch2b <- res4c_branch2b\n",
            "I0614 15:22:21.992642  3510 net.cpp:367] scale4c_branch2b -> res4c_branch2b (in-place)\n",
            "I0614 15:22:21.992671  3510 layer_factory.hpp:77] Creating layer scale4c_branch2b\n",
            "I0614 15:22:21.992739  3510 net.cpp:122] Setting up scale4c_branch2b\n",
            "I0614 15:22:21.992749  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.992754  3510 net.cpp:137] Memory required for data: 386154496\n",
            "I0614 15:22:21.992761  3510 layer_factory.hpp:77] Creating layer res4c_branch2b_relu\n",
            "I0614 15:22:21.992770  3510 net.cpp:84] Creating Layer res4c_branch2b_relu\n",
            "I0614 15:22:21.992777  3510 net.cpp:406] res4c_branch2b_relu <- res4c_branch2b\n",
            "I0614 15:22:21.992784  3510 net.cpp:367] res4c_branch2b_relu -> res4c_branch2b (in-place)\n",
            "I0614 15:22:21.993301  3510 net.cpp:122] Setting up res4c_branch2b_relu\n",
            "I0614 15:22:21.993322  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:21.993327  3510 net.cpp:137] Memory required for data: 386555904\n",
            "I0614 15:22:21.993333  3510 layer_factory.hpp:77] Creating layer res4c_branch2c\n",
            "I0614 15:22:21.993352  3510 net.cpp:84] Creating Layer res4c_branch2c\n",
            "I0614 15:22:21.993360  3510 net.cpp:406] res4c_branch2c <- res4c_branch2b\n",
            "I0614 15:22:21.993371  3510 net.cpp:380] res4c_branch2c -> res4c_branch2c\n",
            "I0614 15:22:21.997799  3510 net.cpp:122] Setting up res4c_branch2c\n",
            "I0614 15:22:21.997822  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.997828  3510 net.cpp:137] Memory required for data: 388161536\n",
            "I0614 15:22:21.997838  3510 layer_factory.hpp:77] Creating layer bn4c_branch2c\n",
            "I0614 15:22:21.997848  3510 net.cpp:84] Creating Layer bn4c_branch2c\n",
            "I0614 15:22:21.997856  3510 net.cpp:406] bn4c_branch2c <- res4c_branch2c\n",
            "I0614 15:22:21.997865  3510 net.cpp:367] bn4c_branch2c -> res4c_branch2c (in-place)\n",
            "I0614 15:22:21.997993  3510 net.cpp:122] Setting up bn4c_branch2c\n",
            "I0614 15:22:21.998006  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.998010  3510 net.cpp:137] Memory required for data: 389767168\n",
            "I0614 15:22:21.998023  3510 layer_factory.hpp:77] Creating layer scale4c_branch2c\n",
            "I0614 15:22:21.998041  3510 net.cpp:84] Creating Layer scale4c_branch2c\n",
            "I0614 15:22:21.998049  3510 net.cpp:406] scale4c_branch2c <- res4c_branch2c\n",
            "I0614 15:22:21.998057  3510 net.cpp:367] scale4c_branch2c -> res4c_branch2c (in-place)\n",
            "I0614 15:22:21.998085  3510 layer_factory.hpp:77] Creating layer scale4c_branch2c\n",
            "I0614 15:22:21.998152  3510 net.cpp:122] Setting up scale4c_branch2c\n",
            "I0614 15:22:21.998160  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.998165  3510 net.cpp:137] Memory required for data: 391372800\n",
            "I0614 15:22:21.998175  3510 layer_factory.hpp:77] Creating layer res4c\n",
            "I0614 15:22:21.998184  3510 net.cpp:84] Creating Layer res4c\n",
            "I0614 15:22:21.998191  3510 net.cpp:406] res4c <- res4b_res4b_relu_0_split_1\n",
            "I0614 15:22:21.998199  3510 net.cpp:406] res4c <- res4c_branch2c\n",
            "I0614 15:22:21.998207  3510 net.cpp:380] res4c -> res4c\n",
            "I0614 15:22:21.998224  3510 net.cpp:122] Setting up res4c\n",
            "I0614 15:22:21.998234  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.998240  3510 net.cpp:137] Memory required for data: 392978432\n",
            "I0614 15:22:21.998247  3510 layer_factory.hpp:77] Creating layer res4c_relu\n",
            "I0614 15:22:21.998255  3510 net.cpp:84] Creating Layer res4c_relu\n",
            "I0614 15:22:21.998262  3510 net.cpp:406] res4c_relu <- res4c\n",
            "I0614 15:22:21.998270  3510 net.cpp:367] res4c_relu -> res4c (in-place)\n",
            "I0614 15:22:21.998781  3510 net.cpp:122] Setting up res4c_relu\n",
            "I0614 15:22:21.998801  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.998806  3510 net.cpp:137] Memory required for data: 394584064\n",
            "I0614 15:22:21.998814  3510 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split\n",
            "I0614 15:22:21.998823  3510 net.cpp:84] Creating Layer res4c_res4c_relu_0_split\n",
            "I0614 15:22:21.998832  3510 net.cpp:406] res4c_res4c_relu_0_split <- res4c\n",
            "I0614 15:22:21.998842  3510 net.cpp:380] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0\n",
            "I0614 15:22:21.998852  3510 net.cpp:380] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1\n",
            "I0614 15:22:21.998896  3510 net.cpp:122] Setting up res4c_res4c_relu_0_split\n",
            "I0614 15:22:21.998905  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.998911  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:21.998919  3510 net.cpp:137] Memory required for data: 397795328\n",
            "I0614 15:22:21.998934  3510 layer_factory.hpp:77] Creating layer res4d_branch2a\n",
            "I0614 15:22:21.998947  3510 net.cpp:84] Creating Layer res4d_branch2a\n",
            "I0614 15:22:21.998955  3510 net.cpp:406] res4d_branch2a <- res4c_res4c_relu_0_split_0\n",
            "I0614 15:22:21.998965  3510 net.cpp:380] res4d_branch2a -> res4d_branch2a\n",
            "I0614 15:22:22.000769  3510 net.cpp:122] Setting up res4d_branch2a\n",
            "I0614 15:22:22.000806  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.000815  3510 net.cpp:137] Memory required for data: 398196736\n",
            "I0614 15:22:22.000828  3510 layer_factory.hpp:77] Creating layer bn4d_branch2a\n",
            "I0614 15:22:22.000838  3510 net.cpp:84] Creating Layer bn4d_branch2a\n",
            "I0614 15:22:22.000846  3510 net.cpp:406] bn4d_branch2a <- res4d_branch2a\n",
            "I0614 15:22:22.000855  3510 net.cpp:367] bn4d_branch2a -> res4d_branch2a (in-place)\n",
            "I0614 15:22:22.001009  3510 net.cpp:122] Setting up bn4d_branch2a\n",
            "I0614 15:22:22.001024  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.001030  3510 net.cpp:137] Memory required for data: 398598144\n",
            "I0614 15:22:22.001042  3510 layer_factory.hpp:77] Creating layer scale4d_branch2a\n",
            "I0614 15:22:22.001060  3510 net.cpp:84] Creating Layer scale4d_branch2a\n",
            "I0614 15:22:22.001068  3510 net.cpp:406] scale4d_branch2a <- res4d_branch2a\n",
            "I0614 15:22:22.001076  3510 net.cpp:367] scale4d_branch2a -> res4d_branch2a (in-place)\n",
            "I0614 15:22:22.001103  3510 layer_factory.hpp:77] Creating layer scale4d_branch2a\n",
            "I0614 15:22:22.001160  3510 net.cpp:122] Setting up scale4d_branch2a\n",
            "I0614 15:22:22.001171  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.001175  3510 net.cpp:137] Memory required for data: 398999552\n",
            "I0614 15:22:22.001185  3510 layer_factory.hpp:77] Creating layer res4d_branch2a_relu\n",
            "I0614 15:22:22.001202  3510 net.cpp:84] Creating Layer res4d_branch2a_relu\n",
            "I0614 15:22:22.001210  3510 net.cpp:406] res4d_branch2a_relu <- res4d_branch2a\n",
            "I0614 15:22:22.001219  3510 net.cpp:367] res4d_branch2a_relu -> res4d_branch2a (in-place)\n",
            "I0614 15:22:22.001721  3510 net.cpp:122] Setting up res4d_branch2a_relu\n",
            "I0614 15:22:22.001741  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.001746  3510 net.cpp:137] Memory required for data: 399400960\n",
            "I0614 15:22:22.001751  3510 layer_factory.hpp:77] Creating layer res4d_branch2b\n",
            "I0614 15:22:22.001761  3510 net.cpp:84] Creating Layer res4d_branch2b\n",
            "I0614 15:22:22.001770  3510 net.cpp:406] res4d_branch2b <- res4d_branch2a\n",
            "I0614 15:22:22.001777  3510 net.cpp:380] res4d_branch2b -> res4d_branch2b\n",
            "I0614 15:22:22.007232  3510 net.cpp:122] Setting up res4d_branch2b\n",
            "I0614 15:22:22.007252  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.007257  3510 net.cpp:137] Memory required for data: 399802368\n",
            "I0614 15:22:22.007266  3510 layer_factory.hpp:77] Creating layer bn4d_branch2b\n",
            "I0614 15:22:22.007273  3510 net.cpp:84] Creating Layer bn4d_branch2b\n",
            "I0614 15:22:22.007278  3510 net.cpp:406] bn4d_branch2b <- res4d_branch2b\n",
            "I0614 15:22:22.007285  3510 net.cpp:367] bn4d_branch2b -> res4d_branch2b (in-place)\n",
            "I0614 15:22:22.007426  3510 net.cpp:122] Setting up bn4d_branch2b\n",
            "I0614 15:22:22.007433  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.007437  3510 net.cpp:137] Memory required for data: 400203776\n",
            "I0614 15:22:22.007447  3510 layer_factory.hpp:77] Creating layer scale4d_branch2b\n",
            "I0614 15:22:22.007453  3510 net.cpp:84] Creating Layer scale4d_branch2b\n",
            "I0614 15:22:22.007457  3510 net.cpp:406] scale4d_branch2b <- res4d_branch2b\n",
            "I0614 15:22:22.007463  3510 net.cpp:367] scale4d_branch2b -> res4d_branch2b (in-place)\n",
            "I0614 15:22:22.007486  3510 layer_factory.hpp:77] Creating layer scale4d_branch2b\n",
            "I0614 15:22:22.007542  3510 net.cpp:122] Setting up scale4d_branch2b\n",
            "I0614 15:22:22.007550  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.007555  3510 net.cpp:137] Memory required for data: 400605184\n",
            "I0614 15:22:22.007561  3510 layer_factory.hpp:77] Creating layer res4d_branch2b_relu\n",
            "I0614 15:22:22.007567  3510 net.cpp:84] Creating Layer res4d_branch2b_relu\n",
            "I0614 15:22:22.007572  3510 net.cpp:406] res4d_branch2b_relu <- res4d_branch2b\n",
            "I0614 15:22:22.007577  3510 net.cpp:367] res4d_branch2b_relu -> res4d_branch2b (in-place)\n",
            "I0614 15:22:22.008016  3510 net.cpp:122] Setting up res4d_branch2b_relu\n",
            "I0614 15:22:22.008038  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.008046  3510 net.cpp:137] Memory required for data: 401006592\n",
            "I0614 15:22:22.008054  3510 layer_factory.hpp:77] Creating layer res4d_branch2c\n",
            "I0614 15:22:22.008065  3510 net.cpp:84] Creating Layer res4d_branch2c\n",
            "I0614 15:22:22.008074  3510 net.cpp:406] res4d_branch2c <- res4d_branch2b\n",
            "I0614 15:22:22.008082  3510 net.cpp:380] res4d_branch2c -> res4d_branch2c\n",
            "I0614 15:22:22.011797  3510 net.cpp:122] Setting up res4d_branch2c\n",
            "I0614 15:22:22.011822  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.011831  3510 net.cpp:137] Memory required for data: 402612224\n",
            "I0614 15:22:22.011842  3510 layer_factory.hpp:77] Creating layer bn4d_branch2c\n",
            "I0614 15:22:22.011864  3510 net.cpp:84] Creating Layer bn4d_branch2c\n",
            "I0614 15:22:22.011876  3510 net.cpp:406] bn4d_branch2c <- res4d_branch2c\n",
            "I0614 15:22:22.011886  3510 net.cpp:367] bn4d_branch2c -> res4d_branch2c (in-place)\n",
            "I0614 15:22:22.012050  3510 net.cpp:122] Setting up bn4d_branch2c\n",
            "I0614 15:22:22.012070  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.012074  3510 net.cpp:137] Memory required for data: 404217856\n",
            "I0614 15:22:22.012082  3510 layer_factory.hpp:77] Creating layer scale4d_branch2c\n",
            "I0614 15:22:22.012089  3510 net.cpp:84] Creating Layer scale4d_branch2c\n",
            "I0614 15:22:22.012094  3510 net.cpp:406] scale4d_branch2c <- res4d_branch2c\n",
            "I0614 15:22:22.012099  3510 net.cpp:367] scale4d_branch2c -> res4d_branch2c (in-place)\n",
            "I0614 15:22:22.012122  3510 layer_factory.hpp:77] Creating layer scale4d_branch2c\n",
            "I0614 15:22:22.012205  3510 net.cpp:122] Setting up scale4d_branch2c\n",
            "I0614 15:22:22.012212  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.012220  3510 net.cpp:137] Memory required for data: 405823488\n",
            "I0614 15:22:22.012230  3510 layer_factory.hpp:77] Creating layer res4d\n",
            "I0614 15:22:22.012239  3510 net.cpp:84] Creating Layer res4d\n",
            "I0614 15:22:22.012248  3510 net.cpp:406] res4d <- res4c_res4c_relu_0_split_1\n",
            "I0614 15:22:22.012253  3510 net.cpp:406] res4d <- res4d_branch2c\n",
            "I0614 15:22:22.012264  3510 net.cpp:380] res4d -> res4d\n",
            "I0614 15:22:22.012284  3510 net.cpp:122] Setting up res4d\n",
            "I0614 15:22:22.012293  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.012300  3510 net.cpp:137] Memory required for data: 407429120\n",
            "I0614 15:22:22.012307  3510 layer_factory.hpp:77] Creating layer res4d_relu\n",
            "I0614 15:22:22.012316  3510 net.cpp:84] Creating Layer res4d_relu\n",
            "I0614 15:22:22.012321  3510 net.cpp:406] res4d_relu <- res4d\n",
            "I0614 15:22:22.012329  3510 net.cpp:367] res4d_relu -> res4d (in-place)\n",
            "I0614 15:22:22.012972  3510 net.cpp:122] Setting up res4d_relu\n",
            "I0614 15:22:22.012995  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.013001  3510 net.cpp:137] Memory required for data: 409034752\n",
            "I0614 15:22:22.013010  3510 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split\n",
            "I0614 15:22:22.013022  3510 net.cpp:84] Creating Layer res4d_res4d_relu_0_split\n",
            "I0614 15:22:22.013031  3510 net.cpp:406] res4d_res4d_relu_0_split <- res4d\n",
            "I0614 15:22:22.013054  3510 net.cpp:380] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0\n",
            "I0614 15:22:22.013067  3510 net.cpp:380] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1\n",
            "I0614 15:22:22.013109  3510 net.cpp:122] Setting up res4d_res4d_relu_0_split\n",
            "I0614 15:22:22.013120  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.013126  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.013134  3510 net.cpp:137] Memory required for data: 412246016\n",
            "I0614 15:22:22.013142  3510 layer_factory.hpp:77] Creating layer res4e_branch2a\n",
            "I0614 15:22:22.013154  3510 net.cpp:84] Creating Layer res4e_branch2a\n",
            "I0614 15:22:22.013162  3510 net.cpp:406] res4e_branch2a <- res4d_res4d_relu_0_split_0\n",
            "I0614 15:22:22.013172  3510 net.cpp:380] res4e_branch2a -> res4e_branch2a\n",
            "I0614 15:22:22.015036  3510 net.cpp:122] Setting up res4e_branch2a\n",
            "I0614 15:22:22.015058  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.015062  3510 net.cpp:137] Memory required for data: 412647424\n",
            "I0614 15:22:22.015074  3510 layer_factory.hpp:77] Creating layer bn4e_branch2a\n",
            "I0614 15:22:22.015084  3510 net.cpp:84] Creating Layer bn4e_branch2a\n",
            "I0614 15:22:22.015094  3510 net.cpp:406] bn4e_branch2a <- res4e_branch2a\n",
            "I0614 15:22:22.015105  3510 net.cpp:367] bn4e_branch2a -> res4e_branch2a (in-place)\n",
            "I0614 15:22:22.015231  3510 net.cpp:122] Setting up bn4e_branch2a\n",
            "I0614 15:22:22.015242  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.015247  3510 net.cpp:137] Memory required for data: 413048832\n",
            "I0614 15:22:22.015259  3510 layer_factory.hpp:77] Creating layer scale4e_branch2a\n",
            "I0614 15:22:22.015269  3510 net.cpp:84] Creating Layer scale4e_branch2a\n",
            "I0614 15:22:22.015277  3510 net.cpp:406] scale4e_branch2a <- res4e_branch2a\n",
            "I0614 15:22:22.015286  3510 net.cpp:367] scale4e_branch2a -> res4e_branch2a (in-place)\n",
            "I0614 15:22:22.015314  3510 layer_factory.hpp:77] Creating layer scale4e_branch2a\n",
            "I0614 15:22:22.015390  3510 net.cpp:122] Setting up scale4e_branch2a\n",
            "I0614 15:22:22.087807  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.087826  3510 net.cpp:137] Memory required for data: 413450240\n",
            "I0614 15:22:22.087843  3510 layer_factory.hpp:77] Creating layer res4e_branch2a_relu\n",
            "I0614 15:22:22.087855  3510 net.cpp:84] Creating Layer res4e_branch2a_relu\n",
            "I0614 15:22:22.087875  3510 net.cpp:406] res4e_branch2a_relu <- res4e_branch2a\n",
            "I0614 15:22:22.087888  3510 net.cpp:367] res4e_branch2a_relu -> res4e_branch2a (in-place)\n",
            "I0614 15:22:22.088714  3510 net.cpp:122] Setting up res4e_branch2a_relu\n",
            "I0614 15:22:22.088748  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.088755  3510 net.cpp:137] Memory required for data: 413851648\n",
            "I0614 15:22:22.088764  3510 layer_factory.hpp:77] Creating layer res4e_branch2b\n",
            "I0614 15:22:22.088775  3510 net.cpp:84] Creating Layer res4e_branch2b\n",
            "I0614 15:22:22.088784  3510 net.cpp:406] res4e_branch2b <- res4e_branch2a\n",
            "I0614 15:22:22.088794  3510 net.cpp:380] res4e_branch2b -> res4e_branch2b\n",
            "I0614 15:22:22.095263  3510 net.cpp:122] Setting up res4e_branch2b\n",
            "I0614 15:22:22.095317  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.095326  3510 net.cpp:137] Memory required for data: 414253056\n",
            "I0614 15:22:22.095338  3510 layer_factory.hpp:77] Creating layer bn4e_branch2b\n",
            "I0614 15:22:22.095350  3510 net.cpp:84] Creating Layer bn4e_branch2b\n",
            "I0614 15:22:22.095358  3510 net.cpp:406] bn4e_branch2b <- res4e_branch2b\n",
            "I0614 15:22:22.095368  3510 net.cpp:367] bn4e_branch2b -> res4e_branch2b (in-place)\n",
            "I0614 15:22:22.095520  3510 net.cpp:122] Setting up bn4e_branch2b\n",
            "I0614 15:22:22.095531  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.095539  3510 net.cpp:137] Memory required for data: 414654464\n",
            "I0614 15:22:22.095551  3510 layer_factory.hpp:77] Creating layer scale4e_branch2b\n",
            "I0614 15:22:22.095561  3510 net.cpp:84] Creating Layer scale4e_branch2b\n",
            "I0614 15:22:22.095569  3510 net.cpp:406] scale4e_branch2b <- res4e_branch2b\n",
            "I0614 15:22:22.095587  3510 net.cpp:367] scale4e_branch2b -> res4e_branch2b (in-place)\n",
            "I0614 15:22:22.095618  3510 layer_factory.hpp:77] Creating layer scale4e_branch2b\n",
            "I0614 15:22:22.095700  3510 net.cpp:122] Setting up scale4e_branch2b\n",
            "I0614 15:22:22.095710  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.095716  3510 net.cpp:137] Memory required for data: 415055872\n",
            "I0614 15:22:22.095727  3510 layer_factory.hpp:77] Creating layer res4e_branch2b_relu\n",
            "I0614 15:22:22.095736  3510 net.cpp:84] Creating Layer res4e_branch2b_relu\n",
            "I0614 15:22:22.095743  3510 net.cpp:406] res4e_branch2b_relu <- res4e_branch2b\n",
            "I0614 15:22:22.095752  3510 net.cpp:367] res4e_branch2b_relu -> res4e_branch2b (in-place)\n",
            "I0614 15:22:22.096390  3510 net.cpp:122] Setting up res4e_branch2b_relu\n",
            "I0614 15:22:22.096413  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.096421  3510 net.cpp:137] Memory required for data: 415457280\n",
            "I0614 15:22:22.096431  3510 layer_factory.hpp:77] Creating layer res4e_branch2c\n",
            "I0614 15:22:22.096441  3510 net.cpp:84] Creating Layer res4e_branch2c\n",
            "I0614 15:22:22.096451  3510 net.cpp:406] res4e_branch2c <- res4e_branch2b\n",
            "I0614 15:22:22.096460  3510 net.cpp:380] res4e_branch2c -> res4e_branch2c\n",
            "I0614 15:22:22.100754  3510 net.cpp:122] Setting up res4e_branch2c\n",
            "I0614 15:22:22.100780  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.100785  3510 net.cpp:137] Memory required for data: 417062912\n",
            "I0614 15:22:22.100805  3510 layer_factory.hpp:77] Creating layer bn4e_branch2c\n",
            "I0614 15:22:22.100814  3510 net.cpp:84] Creating Layer bn4e_branch2c\n",
            "I0614 15:22:22.100823  3510 net.cpp:406] bn4e_branch2c <- res4e_branch2c\n",
            "I0614 15:22:22.100831  3510 net.cpp:367] bn4e_branch2c -> res4e_branch2c (in-place)\n",
            "I0614 15:22:22.100972  3510 net.cpp:122] Setting up bn4e_branch2c\n",
            "I0614 15:22:22.100984  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.100989  3510 net.cpp:137] Memory required for data: 418668544\n",
            "I0614 15:22:22.101001  3510 layer_factory.hpp:77] Creating layer scale4e_branch2c\n",
            "I0614 15:22:22.101011  3510 net.cpp:84] Creating Layer scale4e_branch2c\n",
            "I0614 15:22:22.101018  3510 net.cpp:406] scale4e_branch2c <- res4e_branch2c\n",
            "I0614 15:22:22.101027  3510 net.cpp:367] scale4e_branch2c -> res4e_branch2c (in-place)\n",
            "I0614 15:22:22.101055  3510 layer_factory.hpp:77] Creating layer scale4e_branch2c\n",
            "I0614 15:22:22.101135  3510 net.cpp:122] Setting up scale4e_branch2c\n",
            "I0614 15:22:22.101143  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.101148  3510 net.cpp:137] Memory required for data: 420274176\n",
            "I0614 15:22:22.101158  3510 layer_factory.hpp:77] Creating layer res4e\n",
            "I0614 15:22:22.101167  3510 net.cpp:84] Creating Layer res4e\n",
            "I0614 15:22:22.101176  3510 net.cpp:406] res4e <- res4d_res4d_relu_0_split_1\n",
            "I0614 15:22:22.101182  3510 net.cpp:406] res4e <- res4e_branch2c\n",
            "I0614 15:22:22.101191  3510 net.cpp:380] res4e -> res4e\n",
            "I0614 15:22:22.101210  3510 net.cpp:122] Setting up res4e\n",
            "I0614 15:22:22.101219  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.101227  3510 net.cpp:137] Memory required for data: 421879808\n",
            "I0614 15:22:22.101233  3510 layer_factory.hpp:77] Creating layer res4e_relu\n",
            "I0614 15:22:22.101241  3510 net.cpp:84] Creating Layer res4e_relu\n",
            "I0614 15:22:22.101248  3510 net.cpp:406] res4e_relu <- res4e\n",
            "I0614 15:22:22.101255  3510 net.cpp:367] res4e_relu -> res4e (in-place)\n",
            "I0614 15:22:22.101758  3510 net.cpp:122] Setting up res4e_relu\n",
            "I0614 15:22:22.101781  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.101786  3510 net.cpp:137] Memory required for data: 423485440\n",
            "I0614 15:22:22.101791  3510 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split\n",
            "I0614 15:22:22.101800  3510 net.cpp:84] Creating Layer res4e_res4e_relu_0_split\n",
            "I0614 15:22:22.101809  3510 net.cpp:406] res4e_res4e_relu_0_split <- res4e\n",
            "I0614 15:22:22.101816  3510 net.cpp:380] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0\n",
            "I0614 15:22:22.101827  3510 net.cpp:380] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1\n",
            "I0614 15:22:22.101861  3510 net.cpp:122] Setting up res4e_res4e_relu_0_split\n",
            "I0614 15:22:22.101883  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.101892  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.101899  3510 net.cpp:137] Memory required for data: 426696704\n",
            "I0614 15:22:22.101907  3510 layer_factory.hpp:77] Creating layer res4f_branch2a\n",
            "I0614 15:22:22.101917  3510 net.cpp:84] Creating Layer res4f_branch2a\n",
            "I0614 15:22:22.101924  3510 net.cpp:406] res4f_branch2a <- res4e_res4e_relu_0_split_0\n",
            "I0614 15:22:22.101939  3510 net.cpp:380] res4f_branch2a -> res4f_branch2a\n",
            "I0614 15:22:22.107093  3510 net.cpp:122] Setting up res4f_branch2a\n",
            "I0614 15:22:22.107167  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.107300  3510 net.cpp:137] Memory required for data: 427098112\n",
            "I0614 15:22:22.107331  3510 layer_factory.hpp:77] Creating layer bn4f_branch2a\n",
            "I0614 15:22:22.107343  3510 net.cpp:84] Creating Layer bn4f_branch2a\n",
            "I0614 15:22:22.107352  3510 net.cpp:406] bn4f_branch2a <- res4f_branch2a\n",
            "I0614 15:22:22.107362  3510 net.cpp:367] bn4f_branch2a -> res4f_branch2a (in-place)\n",
            "I0614 15:22:22.107524  3510 net.cpp:122] Setting up bn4f_branch2a\n",
            "I0614 15:22:22.107537  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.107542  3510 net.cpp:137] Memory required for data: 427499520\n",
            "I0614 15:22:22.107553  3510 layer_factory.hpp:77] Creating layer scale4f_branch2a\n",
            "I0614 15:22:22.107563  3510 net.cpp:84] Creating Layer scale4f_branch2a\n",
            "I0614 15:22:22.107571  3510 net.cpp:406] scale4f_branch2a <- res4f_branch2a\n",
            "I0614 15:22:22.107579  3510 net.cpp:367] scale4f_branch2a -> res4f_branch2a (in-place)\n",
            "I0614 15:22:22.107609  3510 layer_factory.hpp:77] Creating layer scale4f_branch2a\n",
            "I0614 15:22:22.107673  3510 net.cpp:122] Setting up scale4f_branch2a\n",
            "I0614 15:22:22.107683  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.107688  3510 net.cpp:137] Memory required for data: 427900928\n",
            "I0614 15:22:22.107697  3510 layer_factory.hpp:77] Creating layer res4f_branch2a_relu\n",
            "I0614 15:22:22.107707  3510 net.cpp:84] Creating Layer res4f_branch2a_relu\n",
            "I0614 15:22:22.107714  3510 net.cpp:406] res4f_branch2a_relu <- res4f_branch2a\n",
            "I0614 15:22:22.107722  3510 net.cpp:367] res4f_branch2a_relu -> res4f_branch2a (in-place)\n",
            "I0614 15:22:22.108147  3510 net.cpp:122] Setting up res4f_branch2a_relu\n",
            "I0614 15:22:22.108168  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.108173  3510 net.cpp:137] Memory required for data: 428302336\n",
            "I0614 15:22:22.108178  3510 layer_factory.hpp:77] Creating layer res4f_branch2b\n",
            "I0614 15:22:22.108187  3510 net.cpp:84] Creating Layer res4f_branch2b\n",
            "I0614 15:22:22.108197  3510 net.cpp:406] res4f_branch2b <- res4f_branch2a\n",
            "I0614 15:22:22.108206  3510 net.cpp:380] res4f_branch2b -> res4f_branch2b\n",
            "I0614 15:22:22.111414  3510 net.cpp:122] Setting up res4f_branch2b\n",
            "I0614 15:22:22.111438  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.111443  3510 net.cpp:137] Memory required for data: 428703744\n",
            "I0614 15:22:22.111450  3510 layer_factory.hpp:77] Creating layer bn4f_branch2b\n",
            "I0614 15:22:22.111459  3510 net.cpp:84] Creating Layer bn4f_branch2b\n",
            "I0614 15:22:22.111464  3510 net.cpp:406] bn4f_branch2b <- res4f_branch2b\n",
            "I0614 15:22:22.111471  3510 net.cpp:367] bn4f_branch2b -> res4f_branch2b (in-place)\n",
            "I0614 15:22:22.111586  3510 net.cpp:122] Setting up bn4f_branch2b\n",
            "I0614 15:22:22.111598  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.111603  3510 net.cpp:137] Memory required for data: 429105152\n",
            "I0614 15:22:22.111611  3510 layer_factory.hpp:77] Creating layer scale4f_branch2b\n",
            "I0614 15:22:22.111620  3510 net.cpp:84] Creating Layer scale4f_branch2b\n",
            "I0614 15:22:22.111626  3510 net.cpp:406] scale4f_branch2b <- res4f_branch2b\n",
            "I0614 15:22:22.111632  3510 net.cpp:367] scale4f_branch2b -> res4f_branch2b (in-place)\n",
            "I0614 15:22:22.111661  3510 layer_factory.hpp:77] Creating layer scale4f_branch2b\n",
            "I0614 15:22:22.111733  3510 net.cpp:122] Setting up scale4f_branch2b\n",
            "I0614 15:22:22.111743  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.111748  3510 net.cpp:137] Memory required for data: 429506560\n",
            "I0614 15:22:22.111755  3510 layer_factory.hpp:77] Creating layer res4f_branch2b_relu\n",
            "I0614 15:22:22.111763  3510 net.cpp:84] Creating Layer res4f_branch2b_relu\n",
            "I0614 15:22:22.111768  3510 net.cpp:406] res4f_branch2b_relu <- res4f_branch2b\n",
            "I0614 15:22:22.111785  3510 net.cpp:367] res4f_branch2b_relu -> res4f_branch2b (in-place)\n",
            "I0614 15:22:22.112329  3510 net.cpp:122] Setting up res4f_branch2b_relu\n",
            "I0614 15:22:22.112351  3510 net.cpp:129] Top shape: 2 256 14 14 (100352)\n",
            "I0614 15:22:22.112357  3510 net.cpp:137] Memory required for data: 429907968\n",
            "I0614 15:22:22.112362  3510 layer_factory.hpp:77] Creating layer res4f_branch2c\n",
            "I0614 15:22:22.112380  3510 net.cpp:84] Creating Layer res4f_branch2c\n",
            "I0614 15:22:22.112391  3510 net.cpp:406] res4f_branch2c <- res4f_branch2b\n",
            "I0614 15:22:22.112399  3510 net.cpp:380] res4f_branch2c -> res4f_branch2c\n",
            "I0614 15:22:22.115258  3510 net.cpp:122] Setting up res4f_branch2c\n",
            "I0614 15:22:22.115290  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.115296  3510 net.cpp:137] Memory required for data: 431513600\n",
            "I0614 15:22:22.115304  3510 layer_factory.hpp:77] Creating layer bn4f_branch2c\n",
            "I0614 15:22:22.115319  3510 net.cpp:84] Creating Layer bn4f_branch2c\n",
            "I0614 15:22:22.115326  3510 net.cpp:406] bn4f_branch2c <- res4f_branch2c\n",
            "I0614 15:22:22.115335  3510 net.cpp:367] bn4f_branch2c -> res4f_branch2c (in-place)\n",
            "I0614 15:22:22.115447  3510 net.cpp:122] Setting up bn4f_branch2c\n",
            "I0614 15:22:22.115458  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.115463  3510 net.cpp:137] Memory required for data: 433119232\n",
            "I0614 15:22:22.115481  3510 layer_factory.hpp:77] Creating layer scale4f_branch2c\n",
            "I0614 15:22:22.115491  3510 net.cpp:84] Creating Layer scale4f_branch2c\n",
            "I0614 15:22:22.115499  3510 net.cpp:406] scale4f_branch2c <- res4f_branch2c\n",
            "I0614 15:22:22.115507  3510 net.cpp:367] scale4f_branch2c -> res4f_branch2c (in-place)\n",
            "I0614 15:22:22.115536  3510 layer_factory.hpp:77] Creating layer scale4f_branch2c\n",
            "I0614 15:22:22.115597  3510 net.cpp:122] Setting up scale4f_branch2c\n",
            "I0614 15:22:22.115608  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.115612  3510 net.cpp:137] Memory required for data: 434724864\n",
            "I0614 15:22:22.115622  3510 layer_factory.hpp:77] Creating layer res4f\n",
            "I0614 15:22:22.115633  3510 net.cpp:84] Creating Layer res4f\n",
            "I0614 15:22:22.115639  3510 net.cpp:406] res4f <- res4e_res4e_relu_0_split_1\n",
            "I0614 15:22:22.115648  3510 net.cpp:406] res4f <- res4f_branch2c\n",
            "I0614 15:22:22.115655  3510 net.cpp:380] res4f -> res4f\n",
            "I0614 15:22:22.115674  3510 net.cpp:122] Setting up res4f\n",
            "I0614 15:22:22.115684  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.115690  3510 net.cpp:137] Memory required for data: 436330496\n",
            "I0614 15:22:22.115697  3510 layer_factory.hpp:77] Creating layer res4f_relu\n",
            "I0614 15:22:22.115705  3510 net.cpp:84] Creating Layer res4f_relu\n",
            "I0614 15:22:22.115712  3510 net.cpp:406] res4f_relu <- res4f\n",
            "I0614 15:22:22.115720  3510 net.cpp:367] res4f_relu -> res4f (in-place)\n",
            "I0614 15:22:22.116312  3510 net.cpp:122] Setting up res4f_relu\n",
            "I0614 15:22:22.116331  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.116336  3510 net.cpp:137] Memory required for data: 437936128\n",
            "I0614 15:22:22.116341  3510 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split\n",
            "I0614 15:22:22.116349  3510 net.cpp:84] Creating Layer res4f_res4f_relu_0_split\n",
            "I0614 15:22:22.116353  3510 net.cpp:406] res4f_res4f_relu_0_split <- res4f\n",
            "I0614 15:22:22.116360  3510 net.cpp:380] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0\n",
            "I0614 15:22:22.116367  3510 net.cpp:380] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1\n",
            "I0614 15:22:22.116411  3510 net.cpp:122] Setting up res4f_res4f_relu_0_split\n",
            "I0614 15:22:22.116417  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.116422  3510 net.cpp:129] Top shape: 2 1024 14 14 (401408)\n",
            "I0614 15:22:22.116427  3510 net.cpp:137] Memory required for data: 441147392\n",
            "I0614 15:22:22.116431  3510 layer_factory.hpp:77] Creating layer res5a_branch1\n",
            "I0614 15:22:22.116438  3510 net.cpp:84] Creating Layer res5a_branch1\n",
            "I0614 15:22:22.116443  3510 net.cpp:406] res5a_branch1 <- res4f_res4f_relu_0_split_0\n",
            "I0614 15:22:22.116449  3510 net.cpp:380] res5a_branch1 -> res5a_branch1\n",
            "I0614 15:22:22.126267  3510 net.cpp:122] Setting up res5a_branch1\n",
            "I0614 15:22:22.126291  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.126296  3510 net.cpp:137] Memory required for data: 441950208\n",
            "I0614 15:22:22.126307  3510 layer_factory.hpp:77] Creating layer bn5a_branch1\n",
            "I0614 15:22:22.126317  3510 net.cpp:84] Creating Layer bn5a_branch1\n",
            "I0614 15:22:22.126322  3510 net.cpp:406] bn5a_branch1 <- res5a_branch1\n",
            "I0614 15:22:22.126332  3510 net.cpp:367] bn5a_branch1 -> res5a_branch1 (in-place)\n",
            "I0614 15:22:22.126451  3510 net.cpp:122] Setting up bn5a_branch1\n",
            "I0614 15:22:22.126462  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.126466  3510 net.cpp:137] Memory required for data: 442753024\n",
            "I0614 15:22:22.126477  3510 layer_factory.hpp:77] Creating layer scale5a_branch1\n",
            "I0614 15:22:22.126487  3510 net.cpp:84] Creating Layer scale5a_branch1\n",
            "I0614 15:22:22.126494  3510 net.cpp:406] scale5a_branch1 <- res5a_branch1\n",
            "I0614 15:22:22.126502  3510 net.cpp:367] scale5a_branch1 -> res5a_branch1 (in-place)\n",
            "I0614 15:22:22.126533  3510 layer_factory.hpp:77] Creating layer scale5a_branch1\n",
            "I0614 15:22:22.126611  3510 net.cpp:122] Setting up scale5a_branch1\n",
            "I0614 15:22:22.126621  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.126626  3510 net.cpp:137] Memory required for data: 443555840\n",
            "I0614 15:22:22.126633  3510 layer_factory.hpp:77] Creating layer res5a_branch2a\n",
            "I0614 15:22:22.126643  3510 net.cpp:84] Creating Layer res5a_branch2a\n",
            "I0614 15:22:22.126652  3510 net.cpp:406] res5a_branch2a <- res4f_res4f_relu_0_split_1\n",
            "I0614 15:22:22.126659  3510 net.cpp:380] res5a_branch2a -> res5a_branch2a\n",
            "I0614 15:22:22.129521  3510 net.cpp:122] Setting up res5a_branch2a\n",
            "I0614 15:22:22.129546  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.129551  3510 net.cpp:137] Memory required for data: 443756544\n",
            "I0614 15:22:22.129559  3510 layer_factory.hpp:77] Creating layer bn5a_branch2a\n",
            "I0614 15:22:22.129567  3510 net.cpp:84] Creating Layer bn5a_branch2a\n",
            "I0614 15:22:22.129576  3510 net.cpp:406] bn5a_branch2a <- res5a_branch2a\n",
            "I0614 15:22:22.129585  3510 net.cpp:367] bn5a_branch2a -> res5a_branch2a (in-place)\n",
            "I0614 15:22:22.129706  3510 net.cpp:122] Setting up bn5a_branch2a\n",
            "I0614 15:22:22.129716  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.129720  3510 net.cpp:137] Memory required for data: 443957248\n",
            "I0614 15:22:22.129729  3510 layer_factory.hpp:77] Creating layer scale5a_branch2a\n",
            "I0614 15:22:22.129739  3510 net.cpp:84] Creating Layer scale5a_branch2a\n",
            "I0614 15:22:22.129746  3510 net.cpp:406] scale5a_branch2a <- res5a_branch2a\n",
            "I0614 15:22:22.129755  3510 net.cpp:367] scale5a_branch2a -> res5a_branch2a (in-place)\n",
            "I0614 15:22:22.129783  3510 layer_factory.hpp:77] Creating layer scale5a_branch2a\n",
            "I0614 15:22:22.129863  3510 net.cpp:122] Setting up scale5a_branch2a\n",
            "I0614 15:22:22.129873  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.129878  3510 net.cpp:137] Memory required for data: 444157952\n",
            "I0614 15:22:22.129887  3510 layer_factory.hpp:77] Creating layer res5a_branch2a_relu\n",
            "I0614 15:22:22.129896  3510 net.cpp:84] Creating Layer res5a_branch2a_relu\n",
            "I0614 15:22:22.129904  3510 net.cpp:406] res5a_branch2a_relu <- res5a_branch2a\n",
            "I0614 15:22:22.129912  3510 net.cpp:367] res5a_branch2a_relu -> res5a_branch2a (in-place)\n",
            "I0614 15:22:22.130278  3510 net.cpp:122] Setting up res5a_branch2a_relu\n",
            "I0614 15:22:22.130297  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.130302  3510 net.cpp:137] Memory required for data: 444358656\n",
            "I0614 15:22:22.130307  3510 layer_factory.hpp:77] Creating layer res5a_branch2b\n",
            "I0614 15:22:22.130316  3510 net.cpp:84] Creating Layer res5a_branch2b\n",
            "I0614 15:22:22.130324  3510 net.cpp:406] res5a_branch2b <- res5a_branch2a\n",
            "I0614 15:22:22.130333  3510 net.cpp:380] res5a_branch2b -> res5a_branch2b\n",
            "I0614 15:22:22.136806  3510 net.cpp:122] Setting up res5a_branch2b\n",
            "I0614 15:22:22.186898  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.186914  3510 net.cpp:137] Memory required for data: 444559360\n",
            "I0614 15:22:22.186941  3510 layer_factory.hpp:77] Creating layer bn5a_branch2b\n",
            "I0614 15:22:22.186954  3510 net.cpp:84] Creating Layer bn5a_branch2b\n",
            "I0614 15:22:22.186964  3510 net.cpp:406] bn5a_branch2b <- res5a_branch2b\n",
            "I0614 15:22:22.186973  3510 net.cpp:367] bn5a_branch2b -> res5a_branch2b (in-place)\n",
            "I0614 15:22:22.187211  3510 net.cpp:122] Setting up bn5a_branch2b\n",
            "I0614 15:22:22.187235  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.187242  3510 net.cpp:137] Memory required for data: 444760064\n",
            "I0614 15:22:22.187256  3510 layer_factory.hpp:77] Creating layer scale5a_branch2b\n",
            "I0614 15:22:22.187269  3510 net.cpp:84] Creating Layer scale5a_branch2b\n",
            "I0614 15:22:22.187278  3510 net.cpp:406] scale5a_branch2b <- res5a_branch2b\n",
            "I0614 15:22:22.187296  3510 net.cpp:367] scale5a_branch2b -> res5a_branch2b (in-place)\n",
            "I0614 15:22:22.187343  3510 layer_factory.hpp:77] Creating layer scale5a_branch2b\n",
            "I0614 15:22:22.187436  3510 net.cpp:122] Setting up scale5a_branch2b\n",
            "I0614 15:22:22.187453  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.187459  3510 net.cpp:137] Memory required for data: 444960768\n",
            "I0614 15:22:22.187471  3510 layer_factory.hpp:77] Creating layer res5a_branch2b_relu\n",
            "I0614 15:22:22.187481  3510 net.cpp:84] Creating Layer res5a_branch2b_relu\n",
            "I0614 15:22:22.187489  3510 net.cpp:406] res5a_branch2b_relu <- res5a_branch2b\n",
            "I0614 15:22:22.187497  3510 net.cpp:367] res5a_branch2b_relu -> res5a_branch2b (in-place)\n",
            "I0614 15:22:22.189836  3510 net.cpp:122] Setting up res5a_branch2b_relu\n",
            "I0614 15:22:22.189864  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.189870  3510 net.cpp:137] Memory required for data: 445161472\n",
            "I0614 15:22:22.189875  3510 layer_factory.hpp:77] Creating layer res5a_branch2c\n",
            "I0614 15:22:22.189885  3510 net.cpp:84] Creating Layer res5a_branch2c\n",
            "I0614 15:22:22.189893  3510 net.cpp:406] res5a_branch2c <- res5a_branch2b\n",
            "I0614 15:22:22.189910  3510 net.cpp:380] res5a_branch2c -> res5a_branch2c\n",
            "I0614 15:22:22.193764  3510 net.cpp:122] Setting up res5a_branch2c\n",
            "I0614 15:22:22.193791  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.193796  3510 net.cpp:137] Memory required for data: 445964288\n",
            "I0614 15:22:22.193805  3510 layer_factory.hpp:77] Creating layer bn5a_branch2c\n",
            "I0614 15:22:22.193815  3510 net.cpp:84] Creating Layer bn5a_branch2c\n",
            "I0614 15:22:22.193825  3510 net.cpp:406] bn5a_branch2c <- res5a_branch2c\n",
            "I0614 15:22:22.193838  3510 net.cpp:367] bn5a_branch2c -> res5a_branch2c (in-place)\n",
            "I0614 15:22:22.193979  3510 net.cpp:122] Setting up bn5a_branch2c\n",
            "I0614 15:22:22.193990  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.193995  3510 net.cpp:137] Memory required for data: 446767104\n",
            "I0614 15:22:22.194005  3510 layer_factory.hpp:77] Creating layer scale5a_branch2c\n",
            "I0614 15:22:22.194015  3510 net.cpp:84] Creating Layer scale5a_branch2c\n",
            "I0614 15:22:22.194022  3510 net.cpp:406] scale5a_branch2c <- res5a_branch2c\n",
            "I0614 15:22:22.194028  3510 net.cpp:367] scale5a_branch2c -> res5a_branch2c (in-place)\n",
            "I0614 15:22:22.194061  3510 layer_factory.hpp:77] Creating layer scale5a_branch2c\n",
            "I0614 15:22:22.194139  3510 net.cpp:122] Setting up scale5a_branch2c\n",
            "I0614 15:22:22.194149  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.194154  3510 net.cpp:137] Memory required for data: 447569920\n",
            "I0614 15:22:22.194160  3510 layer_factory.hpp:77] Creating layer res5a\n",
            "I0614 15:22:22.194170  3510 net.cpp:84] Creating Layer res5a\n",
            "I0614 15:22:22.194177  3510 net.cpp:406] res5a <- res5a_branch1\n",
            "I0614 15:22:22.194185  3510 net.cpp:406] res5a <- res5a_branch2c\n",
            "I0614 15:22:22.194190  3510 net.cpp:380] res5a -> res5a\n",
            "I0614 15:22:22.194209  3510 net.cpp:122] Setting up res5a\n",
            "I0614 15:22:22.194219  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.194226  3510 net.cpp:137] Memory required for data: 448372736\n",
            "I0614 15:22:22.194231  3510 layer_factory.hpp:77] Creating layer res5a_relu\n",
            "I0614 15:22:22.194238  3510 net.cpp:84] Creating Layer res5a_relu\n",
            "I0614 15:22:22.194245  3510 net.cpp:406] res5a_relu <- res5a\n",
            "I0614 15:22:22.194252  3510 net.cpp:367] res5a_relu -> res5a (in-place)\n",
            "I0614 15:22:22.194792  3510 net.cpp:122] Setting up res5a_relu\n",
            "I0614 15:22:22.194816  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.194821  3510 net.cpp:137] Memory required for data: 449175552\n",
            "I0614 15:22:22.194826  3510 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split\n",
            "I0614 15:22:22.194834  3510 net.cpp:84] Creating Layer res5a_res5a_relu_0_split\n",
            "I0614 15:22:22.194857  3510 net.cpp:406] res5a_res5a_relu_0_split <- res5a\n",
            "I0614 15:22:22.194869  3510 net.cpp:380] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0\n",
            "I0614 15:22:22.194893  3510 net.cpp:380] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1\n",
            "I0614 15:22:22.194939  3510 net.cpp:122] Setting up res5a_res5a_relu_0_split\n",
            "I0614 15:22:22.194949  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.194955  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.194959  3510 net.cpp:137] Memory required for data: 450781184\n",
            "I0614 15:22:22.194964  3510 layer_factory.hpp:77] Creating layer res5b_branch2a\n",
            "I0614 15:22:22.194974  3510 net.cpp:84] Creating Layer res5b_branch2a\n",
            "I0614 15:22:22.194981  3510 net.cpp:406] res5b_branch2a <- res5a_res5a_relu_0_split_0\n",
            "I0614 15:22:22.194988  3510 net.cpp:380] res5b_branch2a -> res5b_branch2a\n",
            "I0614 15:22:22.198918  3510 net.cpp:122] Setting up res5b_branch2a\n",
            "I0614 15:22:22.198953  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.198958  3510 net.cpp:137] Memory required for data: 450981888\n",
            "I0614 15:22:22.198966  3510 layer_factory.hpp:77] Creating layer bn5b_branch2a\n",
            "I0614 15:22:22.198976  3510 net.cpp:84] Creating Layer bn5b_branch2a\n",
            "I0614 15:22:22.198984  3510 net.cpp:406] bn5b_branch2a <- res5b_branch2a\n",
            "I0614 15:22:22.198992  3510 net.cpp:367] bn5b_branch2a -> res5b_branch2a (in-place)\n",
            "I0614 15:22:22.199110  3510 net.cpp:122] Setting up bn5b_branch2a\n",
            "I0614 15:22:22.199120  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.199129  3510 net.cpp:137] Memory required for data: 451182592\n",
            "I0614 15:22:22.199141  3510 layer_factory.hpp:77] Creating layer scale5b_branch2a\n",
            "I0614 15:22:22.199162  3510 net.cpp:84] Creating Layer scale5b_branch2a\n",
            "I0614 15:22:22.199169  3510 net.cpp:406] scale5b_branch2a <- res5b_branch2a\n",
            "I0614 15:22:22.199182  3510 net.cpp:367] scale5b_branch2a -> res5b_branch2a (in-place)\n",
            "I0614 15:22:22.199223  3510 layer_factory.hpp:77] Creating layer scale5b_branch2a\n",
            "I0614 15:22:22.199296  3510 net.cpp:122] Setting up scale5b_branch2a\n",
            "I0614 15:22:22.199306  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.199311  3510 net.cpp:137] Memory required for data: 451383296\n",
            "I0614 15:22:22.199319  3510 layer_factory.hpp:77] Creating layer res5b_branch2a_relu\n",
            "I0614 15:22:22.199329  3510 net.cpp:84] Creating Layer res5b_branch2a_relu\n",
            "I0614 15:22:22.199337  3510 net.cpp:406] res5b_branch2a_relu <- res5b_branch2a\n",
            "I0614 15:22:22.199343  3510 net.cpp:367] res5b_branch2a_relu -> res5b_branch2a (in-place)\n",
            "I0614 15:22:22.199831  3510 net.cpp:122] Setting up res5b_branch2a_relu\n",
            "I0614 15:22:22.199854  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.199859  3510 net.cpp:137] Memory required for data: 451584000\n",
            "I0614 15:22:22.199864  3510 layer_factory.hpp:77] Creating layer res5b_branch2b\n",
            "I0614 15:22:22.199873  3510 net.cpp:84] Creating Layer res5b_branch2b\n",
            "I0614 15:22:22.199885  3510 net.cpp:406] res5b_branch2b <- res5b_branch2a\n",
            "I0614 15:22:22.199893  3510 net.cpp:380] res5b_branch2b -> res5b_branch2b\n",
            "I0614 15:22:22.209810  3510 net.cpp:122] Setting up res5b_branch2b\n",
            "I0614 15:22:22.209848  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.209853  3510 net.cpp:137] Memory required for data: 451784704\n",
            "I0614 15:22:22.209861  3510 layer_factory.hpp:77] Creating layer bn5b_branch2b\n",
            "I0614 15:22:22.209887  3510 net.cpp:84] Creating Layer bn5b_branch2b\n",
            "I0614 15:22:22.209897  3510 net.cpp:406] bn5b_branch2b <- res5b_branch2b\n",
            "I0614 15:22:22.209906  3510 net.cpp:367] bn5b_branch2b -> res5b_branch2b (in-place)\n",
            "I0614 15:22:22.210054  3510 net.cpp:122] Setting up bn5b_branch2b\n",
            "I0614 15:22:22.210067  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.210070  3510 net.cpp:137] Memory required for data: 451985408\n",
            "I0614 15:22:22.210078  3510 layer_factory.hpp:77] Creating layer scale5b_branch2b\n",
            "I0614 15:22:22.210085  3510 net.cpp:84] Creating Layer scale5b_branch2b\n",
            "I0614 15:22:22.210089  3510 net.cpp:406] scale5b_branch2b <- res5b_branch2b\n",
            "I0614 15:22:22.210095  3510 net.cpp:367] scale5b_branch2b -> res5b_branch2b (in-place)\n",
            "I0614 15:22:22.210121  3510 layer_factory.hpp:77] Creating layer scale5b_branch2b\n",
            "I0614 15:22:22.210183  3510 net.cpp:122] Setting up scale5b_branch2b\n",
            "I0614 15:22:22.210201  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.210204  3510 net.cpp:137] Memory required for data: 452186112\n",
            "I0614 15:22:22.210211  3510 layer_factory.hpp:77] Creating layer res5b_branch2b_relu\n",
            "I0614 15:22:22.210216  3510 net.cpp:84] Creating Layer res5b_branch2b_relu\n",
            "I0614 15:22:22.210220  3510 net.cpp:406] res5b_branch2b_relu <- res5b_branch2b\n",
            "I0614 15:22:22.210225  3510 net.cpp:367] res5b_branch2b_relu -> res5b_branch2b (in-place)\n",
            "I0614 15:22:22.210747  3510 net.cpp:122] Setting up res5b_branch2b_relu\n",
            "I0614 15:22:22.210772  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.210777  3510 net.cpp:137] Memory required for data: 452386816\n",
            "I0614 15:22:22.210781  3510 layer_factory.hpp:77] Creating layer res5b_branch2c\n",
            "I0614 15:22:22.210791  3510 net.cpp:84] Creating Layer res5b_branch2c\n",
            "I0614 15:22:22.210798  3510 net.cpp:406] res5b_branch2c <- res5b_branch2b\n",
            "I0614 15:22:22.210806  3510 net.cpp:380] res5b_branch2c -> res5b_branch2c\n",
            "I0614 15:22:22.214946  3510 net.cpp:122] Setting up res5b_branch2c\n",
            "I0614 15:22:22.214972  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.214982  3510 net.cpp:137] Memory required for data: 453189632\n",
            "I0614 15:22:22.214993  3510 layer_factory.hpp:77] Creating layer bn5b_branch2c\n",
            "I0614 15:22:22.215003  3510 net.cpp:84] Creating Layer bn5b_branch2c\n",
            "I0614 15:22:22.215010  3510 net.cpp:406] bn5b_branch2c <- res5b_branch2c\n",
            "I0614 15:22:22.215019  3510 net.cpp:367] bn5b_branch2c -> res5b_branch2c (in-place)\n",
            "I0614 15:22:22.215150  3510 net.cpp:122] Setting up bn5b_branch2c\n",
            "I0614 15:22:22.215160  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.215165  3510 net.cpp:137] Memory required for data: 453992448\n",
            "I0614 15:22:22.215174  3510 layer_factory.hpp:77] Creating layer scale5b_branch2c\n",
            "I0614 15:22:22.215184  3510 net.cpp:84] Creating Layer scale5b_branch2c\n",
            "I0614 15:22:22.215191  3510 net.cpp:406] scale5b_branch2c <- res5b_branch2c\n",
            "I0614 15:22:22.215199  3510 net.cpp:367] scale5b_branch2c -> res5b_branch2c (in-place)\n",
            "I0614 15:22:22.215231  3510 layer_factory.hpp:77] Creating layer scale5b_branch2c\n",
            "I0614 15:22:22.215306  3510 net.cpp:122] Setting up scale5b_branch2c\n",
            "I0614 15:22:22.215315  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.215320  3510 net.cpp:137] Memory required for data: 454795264\n",
            "I0614 15:22:22.215330  3510 layer_factory.hpp:77] Creating layer res5b\n",
            "I0614 15:22:22.215339  3510 net.cpp:84] Creating Layer res5b\n",
            "I0614 15:22:22.215348  3510 net.cpp:406] res5b <- res5a_res5a_relu_0_split_1\n",
            "I0614 15:22:22.215355  3510 net.cpp:406] res5b <- res5b_branch2c\n",
            "I0614 15:22:22.215363  3510 net.cpp:380] res5b -> res5b\n",
            "I0614 15:22:22.215382  3510 net.cpp:122] Setting up res5b\n",
            "I0614 15:22:22.215391  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.215399  3510 net.cpp:137] Memory required for data: 455598080\n",
            "I0614 15:22:22.215405  3510 layer_factory.hpp:77] Creating layer res5b_relu\n",
            "I0614 15:22:22.215415  3510 net.cpp:84] Creating Layer res5b_relu\n",
            "I0614 15:22:22.215421  3510 net.cpp:406] res5b_relu <- res5b\n",
            "I0614 15:22:22.215436  3510 net.cpp:367] res5b_relu -> res5b (in-place)\n",
            "I0614 15:22:22.215777  3510 net.cpp:122] Setting up res5b_relu\n",
            "I0614 15:22:22.215797  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.215802  3510 net.cpp:137] Memory required for data: 456400896\n",
            "I0614 15:22:22.215807  3510 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split\n",
            "I0614 15:22:22.215816  3510 net.cpp:84] Creating Layer res5b_res5b_relu_0_split\n",
            "I0614 15:22:22.215823  3510 net.cpp:406] res5b_res5b_relu_0_split <- res5b\n",
            "I0614 15:22:22.215831  3510 net.cpp:380] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0\n",
            "I0614 15:22:22.215842  3510 net.cpp:380] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1\n",
            "I0614 15:22:22.215898  3510 net.cpp:122] Setting up res5b_res5b_relu_0_split\n",
            "I0614 15:22:22.215909  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.215914  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.215921  3510 net.cpp:137] Memory required for data: 458006528\n",
            "I0614 15:22:22.215937  3510 layer_factory.hpp:77] Creating layer res5c_branch2a\n",
            "I0614 15:22:22.215946  3510 net.cpp:84] Creating Layer res5c_branch2a\n",
            "I0614 15:22:22.215951  3510 net.cpp:406] res5c_branch2a <- res5b_res5b_relu_0_split_0\n",
            "I0614 15:22:22.215958  3510 net.cpp:380] res5c_branch2a -> res5c_branch2a\n",
            "I0614 15:22:22.220064  3510 net.cpp:122] Setting up res5c_branch2a\n",
            "I0614 15:22:22.220085  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.220090  3510 net.cpp:137] Memory required for data: 458207232\n",
            "I0614 15:22:22.220101  3510 layer_factory.hpp:77] Creating layer bn5c_branch2a\n",
            "I0614 15:22:22.220111  3510 net.cpp:84] Creating Layer bn5c_branch2a\n",
            "I0614 15:22:22.220119  3510 net.cpp:406] bn5c_branch2a <- res5c_branch2a\n",
            "I0614 15:22:22.220132  3510 net.cpp:367] bn5c_branch2a -> res5c_branch2a (in-place)\n",
            "I0614 15:22:22.220250  3510 net.cpp:122] Setting up bn5c_branch2a\n",
            "I0614 15:22:22.220260  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.220265  3510 net.cpp:137] Memory required for data: 458407936\n",
            "I0614 15:22:22.220278  3510 layer_factory.hpp:77] Creating layer scale5c_branch2a\n",
            "I0614 15:22:22.220288  3510 net.cpp:84] Creating Layer scale5c_branch2a\n",
            "I0614 15:22:22.220294  3510 net.cpp:406] scale5c_branch2a <- res5c_branch2a\n",
            "I0614 15:22:22.220302  3510 net.cpp:367] scale5c_branch2a -> res5c_branch2a (in-place)\n",
            "I0614 15:22:22.220332  3510 layer_factory.hpp:77] Creating layer scale5c_branch2a\n",
            "I0614 15:22:22.220417  3510 net.cpp:122] Setting up scale5c_branch2a\n",
            "I0614 15:22:22.220427  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.220432  3510 net.cpp:137] Memory required for data: 458608640\n",
            "I0614 15:22:22.220443  3510 layer_factory.hpp:77] Creating layer res5c_branch2a_relu\n",
            "I0614 15:22:22.220451  3510 net.cpp:84] Creating Layer res5c_branch2a_relu\n",
            "I0614 15:22:22.220458  3510 net.cpp:406] res5c_branch2a_relu <- res5c_branch2a\n",
            "I0614 15:22:22.220466  3510 net.cpp:367] res5c_branch2a_relu -> res5c_branch2a (in-place)\n",
            "I0614 15:22:22.220969  3510 net.cpp:122] Setting up res5c_branch2a_relu\n",
            "I0614 15:22:22.220989  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.220994  3510 net.cpp:137] Memory required for data: 458809344\n",
            "I0614 15:22:22.221002  3510 layer_factory.hpp:77] Creating layer res5c_branch2b\n",
            "I0614 15:22:22.221021  3510 net.cpp:84] Creating Layer res5c_branch2b\n",
            "I0614 15:22:22.221030  3510 net.cpp:406] res5c_branch2b <- res5c_branch2a\n",
            "I0614 15:22:22.221037  3510 net.cpp:380] res5c_branch2b -> res5c_branch2b\n",
            "I0614 15:22:22.229300  3510 net.cpp:122] Setting up res5c_branch2b\n",
            "I0614 15:22:22.229323  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.229328  3510 net.cpp:137] Memory required for data: 459010048\n",
            "I0614 15:22:22.229338  3510 layer_factory.hpp:77] Creating layer bn5c_branch2b\n",
            "I0614 15:22:22.229346  3510 net.cpp:84] Creating Layer bn5c_branch2b\n",
            "I0614 15:22:22.229352  3510 net.cpp:406] bn5c_branch2b <- res5c_branch2b\n",
            "I0614 15:22:22.229367  3510 net.cpp:367] bn5c_branch2b -> res5c_branch2b (in-place)\n",
            "I0614 15:22:22.229480  3510 net.cpp:122] Setting up bn5c_branch2b\n",
            "I0614 15:22:22.229491  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.229496  3510 net.cpp:137] Memory required for data: 459210752\n",
            "I0614 15:22:22.229506  3510 layer_factory.hpp:77] Creating layer scale5c_branch2b\n",
            "I0614 15:22:22.229514  3510 net.cpp:84] Creating Layer scale5c_branch2b\n",
            "I0614 15:22:22.229522  3510 net.cpp:406] scale5c_branch2b <- res5c_branch2b\n",
            "I0614 15:22:22.229529  3510 net.cpp:367] scale5c_branch2b -> res5c_branch2b (in-place)\n",
            "I0614 15:22:22.229559  3510 layer_factory.hpp:77] Creating layer scale5c_branch2b\n",
            "I0614 15:22:22.229645  3510 net.cpp:122] Setting up scale5c_branch2b\n",
            "I0614 15:22:22.229655  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.229660  3510 net.cpp:137] Memory required for data: 459411456\n",
            "I0614 15:22:22.229667  3510 layer_factory.hpp:77] Creating layer res5c_branch2b_relu\n",
            "I0614 15:22:22.229686  3510 net.cpp:84] Creating Layer res5c_branch2b_relu\n",
            "I0614 15:22:22.229694  3510 net.cpp:406] res5c_branch2b_relu <- res5c_branch2b\n",
            "I0614 15:22:22.229701  3510 net.cpp:367] res5c_branch2b_relu -> res5c_branch2b (in-place)\n",
            "I0614 15:22:22.230207  3510 net.cpp:122] Setting up res5c_branch2b_relu\n",
            "I0614 15:22:22.230228  3510 net.cpp:129] Top shape: 2 512 7 7 (50176)\n",
            "I0614 15:22:22.230232  3510 net.cpp:137] Memory required for data: 459612160\n",
            "I0614 15:22:22.230238  3510 layer_factory.hpp:77] Creating layer res5c_branch2c\n",
            "I0614 15:22:22.230247  3510 net.cpp:84] Creating Layer res5c_branch2c\n",
            "I0614 15:22:22.230252  3510 net.cpp:406] res5c_branch2c <- res5c_branch2b\n",
            "I0614 15:22:22.230260  3510 net.cpp:380] res5c_branch2c -> res5c_branch2c\n",
            "I0614 15:22:22.235286  3510 net.cpp:122] Setting up res5c_branch2c\n",
            "I0614 15:22:22.235321  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.235330  3510 net.cpp:137] Memory required for data: 460414976\n",
            "I0614 15:22:22.235342  3510 layer_factory.hpp:77] Creating layer bn5c_branch2c\n",
            "I0614 15:22:22.235352  3510 net.cpp:84] Creating Layer bn5c_branch2c\n",
            "I0614 15:22:22.235361  3510 net.cpp:406] bn5c_branch2c <- res5c_branch2c\n",
            "I0614 15:22:22.235368  3510 net.cpp:367] bn5c_branch2c -> res5c_branch2c (in-place)\n",
            "I0614 15:22:22.235486  3510 net.cpp:122] Setting up bn5c_branch2c\n",
            "I0614 15:22:22.235496  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.235503  3510 net.cpp:137] Memory required for data: 461217792\n",
            "I0614 15:22:22.235515  3510 layer_factory.hpp:77] Creating layer scale5c_branch2c\n",
            "I0614 15:22:22.235524  3510 net.cpp:84] Creating Layer scale5c_branch2c\n",
            "I0614 15:22:22.235532  3510 net.cpp:406] scale5c_branch2c <- res5c_branch2c\n",
            "I0614 15:22:22.235540  3510 net.cpp:367] scale5c_branch2c -> res5c_branch2c (in-place)\n",
            "I0614 15:22:22.235581  3510 layer_factory.hpp:77] Creating layer scale5c_branch2c\n",
            "I0614 15:22:22.235656  3510 net.cpp:122] Setting up scale5c_branch2c\n",
            "I0614 15:22:22.235666  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.235673  3510 net.cpp:137] Memory required for data: 462020608\n",
            "I0614 15:22:22.235680  3510 layer_factory.hpp:77] Creating layer res5c\n",
            "I0614 15:22:22.235689  3510 net.cpp:84] Creating Layer res5c\n",
            "I0614 15:22:22.235698  3510 net.cpp:406] res5c <- res5b_res5b_relu_0_split_1\n",
            "I0614 15:22:22.235707  3510 net.cpp:406] res5c <- res5c_branch2c\n",
            "I0614 15:22:22.235715  3510 net.cpp:380] res5c -> res5c\n",
            "I0614 15:22:22.235734  3510 net.cpp:122] Setting up res5c\n",
            "I0614 15:22:22.235744  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.235751  3510 net.cpp:137] Memory required for data: 462823424\n",
            "I0614 15:22:22.235759  3510 layer_factory.hpp:77] Creating layer res5c_relu\n",
            "I0614 15:22:22.235767  3510 net.cpp:84] Creating Layer res5c_relu\n",
            "I0614 15:22:22.287920  3510 net.cpp:406] res5c_relu <- res5c\n",
            "I0614 15:22:22.287948  3510 net.cpp:367] res5c_relu -> res5c (in-place)\n",
            "I0614 15:22:22.289815  3510 net.cpp:122] Setting up res5c_relu\n",
            "I0614 15:22:22.289844  3510 net.cpp:129] Top shape: 2 2048 7 7 (200704)\n",
            "I0614 15:22:22.289851  3510 net.cpp:137] Memory required for data: 463626240\n",
            "I0614 15:22:22.289858  3510 layer_factory.hpp:77] Creating layer pool5\n",
            "I0614 15:22:22.289870  3510 net.cpp:84] Creating Layer pool5\n",
            "I0614 15:22:22.289877  3510 net.cpp:406] pool5 <- res5c\n",
            "I0614 15:22:22.289887  3510 net.cpp:380] pool5 -> pool5\n",
            "I0614 15:22:22.290966  3510 net.cpp:122] Setting up pool5\n",
            "I0614 15:22:22.291007  3510 net.cpp:129] Top shape: 2 2048 1 1 (4096)\n",
            "I0614 15:22:22.291015  3510 net.cpp:137] Memory required for data: 463642624\n",
            "I0614 15:22:22.291024  3510 layer_factory.hpp:77] Creating layer fc\n",
            "I0614 15:22:22.291035  3510 net.cpp:84] Creating Layer fc\n",
            "I0614 15:22:22.291043  3510 net.cpp:406] fc <- pool5\n",
            "I0614 15:22:22.291051  3510 net.cpp:380] fc -> fc\n",
            "I0614 15:22:22.292346  3510 net.cpp:122] Setting up fc\n",
            "I0614 15:22:22.292367  3510 net.cpp:129] Top shape: 2 40 (80)\n",
            "I0614 15:22:22.292376  3510 net.cpp:137] Memory required for data: 463642944\n",
            "I0614 15:22:22.292387  3510 layer_factory.hpp:77] Creating layer pred\n",
            "I0614 15:22:22.292397  3510 net.cpp:84] Creating Layer pred\n",
            "I0614 15:22:22.292405  3510 net.cpp:406] pred <- fc\n",
            "I0614 15:22:22.292423  3510 net.cpp:380] pred -> pred\n",
            "I0614 15:22:22.292943  3510 net.cpp:122] Setting up pred\n",
            "I0614 15:22:22.292966  3510 net.cpp:129] Top shape: 2 40 (80)\n",
            "I0614 15:22:22.292973  3510 net.cpp:137] Memory required for data: 463643264\n",
            "I0614 15:22:22.292981  3510 net.cpp:200] pred does not need backward computation.\n",
            "I0614 15:22:22.292995  3510 net.cpp:200] fc does not need backward computation.\n",
            "I0614 15:22:22.293002  3510 net.cpp:200] pool5 does not need backward computation.\n",
            "I0614 15:22:22.293009  3510 net.cpp:200] res5c_relu does not need backward computation.\n",
            "I0614 15:22:22.293016  3510 net.cpp:200] res5c does not need backward computation.\n",
            "I0614 15:22:22.293023  3510 net.cpp:200] scale5c_branch2c does not need backward computation.\n",
            "I0614 15:22:22.293030  3510 net.cpp:200] bn5c_branch2c does not need backward computation.\n",
            "I0614 15:22:22.293037  3510 net.cpp:200] res5c_branch2c does not need backward computation.\n",
            "I0614 15:22:22.293045  3510 net.cpp:200] res5c_branch2b_relu does not need backward computation.\n",
            "I0614 15:22:22.293052  3510 net.cpp:200] scale5c_branch2b does not need backward computation.\n",
            "I0614 15:22:22.293059  3510 net.cpp:200] bn5c_branch2b does not need backward computation.\n",
            "I0614 15:22:22.293066  3510 net.cpp:200] res5c_branch2b does not need backward computation.\n",
            "I0614 15:22:22.293072  3510 net.cpp:200] res5c_branch2a_relu does not need backward computation.\n",
            "I0614 15:22:22.293079  3510 net.cpp:200] scale5c_branch2a does not need backward computation.\n",
            "I0614 15:22:22.293089  3510 net.cpp:200] bn5c_branch2a does not need backward computation.\n",
            "I0614 15:22:22.293095  3510 net.cpp:200] res5c_branch2a does not need backward computation.\n",
            "I0614 15:22:22.293102  3510 net.cpp:200] res5b_res5b_relu_0_split does not need backward computation.\n",
            "I0614 15:22:22.293109  3510 net.cpp:200] res5b_relu does not need backward computation.\n",
            "I0614 15:22:22.293116  3510 net.cpp:200] res5b does not need backward computation.\n",
            "I0614 15:22:22.293126  3510 net.cpp:200] scale5b_branch2c does not need backward computation.\n",
            "I0614 15:22:22.293134  3510 net.cpp:200] bn5b_branch2c does not need backward computation.\n",
            "I0614 15:22:22.293140  3510 net.cpp:200] res5b_branch2c does not need backward computation.\n",
            "I0614 15:22:22.293148  3510 net.cpp:200] res5b_branch2b_relu does not need backward computation.\n",
            "I0614 15:22:22.293154  3510 net.cpp:200] scale5b_branch2b does not need backward computation.\n",
            "I0614 15:22:22.293160  3510 net.cpp:200] bn5b_branch2b does not need backward computation.\n",
            "I0614 15:22:22.293166  3510 net.cpp:200] res5b_branch2b does not need backward computation.\n",
            "I0614 15:22:22.293174  3510 net.cpp:200] res5b_branch2a_relu does not need backward computation.\n",
            "I0614 15:22:22.293181  3510 net.cpp:200] scale5b_branch2a does not need backward computation.\n",
            "I0614 15:22:22.293188  3510 net.cpp:200] bn5b_branch2a does not need backward computation.\n",
            "I0614 15:22:22.293196  3510 net.cpp:200] res5b_branch2a does not need backward computation.\n",
            "I0614 15:22:22.293205  3510 net.cpp:200] res5a_res5a_relu_0_split does not need backward computation.\n",
            "I0614 15:22:22.293213  3510 net.cpp:200] res5a_relu does not need backward computation.\n",
            "I0614 15:22:22.293220  3510 net.cpp:200] res5a does not need backward computation.\n",
            "I0614 15:22:22.293227  3510 net.cpp:200] scale5a_branch2c does not need backward computation.\n",
            "I0614 15:22:22.293253  3510 net.cpp:200] bn5a_branch2c does not need backward computation.\n",
            "I0614 15:22:22.293260  3510 net.cpp:200] res5a_branch2c does not need backward computation.\n",
            "I0614 15:22:22.293268  3510 net.cpp:200] res5a_branch2b_relu does not need backward computation.\n",
            "I0614 15:22:22.293277  3510 net.cpp:200] scale5a_branch2b does not need backward computation.\n",
            "I0614 15:22:22.293283  3510 net.cpp:200] bn5a_branch2b does not need backward computation.\n",
            "I0614 15:22:22.293290  3510 net.cpp:200] res5a_branch2b does not need backward computation.\n",
            "I0614 15:22:22.293296  3510 net.cpp:200] res5a_branch2a_relu does not need backward computation.\n",
            "I0614 15:22:22.293303  3510 net.cpp:200] scale5a_branch2a does not need backward computation.\n",
            "I0614 15:22:22.293309  3510 net.cpp:200] bn5a_branch2a does not need backward computation.\n",
            "I0614 15:22:22.293326  3510 net.cpp:200] res5a_branch2a does not need backward computation.\n",
            "I0614 15:22:22.294193  3510 net.cpp:200] scale5a_branch1 does not need backward computation.\n",
            "I0614 15:22:22.294210  3510 net.cpp:200] bn5a_branch1 does not need backward computation.\n",
            "I0614 15:22:22.294219  3510 net.cpp:200] res5a_branch1 does not need backward computation.\n",
            "I0614 15:22:22.294225  3510 net.cpp:200] res4f_res4f_relu_0_split does not need backward computation.\n",
            "I0614 15:22:22.294234  3510 net.cpp:200] res4f_relu does not need backward computation.\n",
            "I0614 15:22:22.294252  3510 net.cpp:200] res4f does not need backward computation.\n",
            "I0614 15:22:22.294261  3510 net.cpp:200] scale4f_branch2c does not need backward computation.\n",
            "I0614 15:22:22.294268  3510 net.cpp:200] bn4f_branch2c does not need backward computation.\n",
            "I0614 15:22:22.294276  3510 net.cpp:200] res4f_branch2c does not need backward computation.\n",
            "I0614 15:22:22.294283  3510 net.cpp:200] res4f_branch2b_relu does not need backward computation.\n",
            "I0614 15:22:22.294291  3510 net.cpp:200] scale4f_branch2b does not need backward computation.\n",
            "I0614 15:22:22.294298  3510 net.cpp:200] bn4f_branch2b does not need backward computation.\n",
            "I0614 15:22:22.294306  3510 net.cpp:200] res4f_branch2b does not need backward computation.\n",
            "I0614 15:22:22.294323  3510 net.cpp:200] res4f_branch2a_relu does not need backward computation.\n",
            "I0614 15:22:22.294330  3510 net.cpp:200] scale4f_branch2a does not need backward computation.\n",
            "I0614 15:22:22.294338  3510 net.cpp:200] bn4f_branch2a does not need backward computation.\n",
            "I0614 15:22:22.294345  3510 net.cpp:200] res4f_branch2a does not need backward computation.\n",
            "I0614 15:22:22.294353  3510 net.cpp:200] res4e_res4e_relu_0_split does not need backward computation.\n",
            "I0614 15:22:22.294360  3510 net.cpp:200] res4e_relu does not need backward computation.\n",
            "I0614 15:22:22.294368  3510 net.cpp:200] res4e does not need backward computation.\n",
            "I0614 15:22:22.294376  3510 net.cpp:200] scale4e_branch2c does not need backward computation.\n",
            "I0614 15:22:22.294384  3510 net.cpp:200] bn4e_branch2c does not need backward computation.\n",
            "I0614 15:22:22.294399  3510 net.cpp:200] res4e_branch2c does not need backward computation.\n",
            "I0614 15:22:22.294407  3510 net.cpp:200] res4e_branch2b_relu does not need backward computation.\n",
            "I0614 15:22:22.294415  3510 net.cpp:200] scale4e_branch2b does not need backward computation.\n",
            "I0614 15:22:22.294422  3510 net.cpp:200] bn4e_branch2b does not need backward computation.\n",
            "I0614 15:22:22.294430  3510 net.cpp:200] res4e_branch2b does not need backward computation.\n",
            "I0614 15:22:22.294437  3510 net.cpp:200] res4e_branch2a_relu does not need backward computation.\n",
            "I0614 15:22:22.294445  3510 net.cpp:200] scale4e_branch2a does not need backward computation.\n",
            "I0614 15:22:22.294450  3510 net.cpp:200] bn4e_branch2a does not need backward computation.\n",
            "I0614 15:22:22.294458  3510 net.cpp:200] res4e_branch2a does not need backward computation.\n",
            "I0614 15:22:22.294466  3510 net.cpp:200] res4d_res4d_relu_0_split does not need backward computation.\n",
            "I0614 15:22:22.294485  3510 net.cpp:200] res4d_relu does not need backward computation.\n",
            "I0614 15:22:22.294493  3510 net.cpp:200] res4d does not need backward computation.\n",
            "I0614 15:22:22.294502  3510 net.cpp:200] scale4d_branch2c does not need backward computation.\n",
            "I0614 15:22:22.294512  3510 net.cpp:200] bn4d_branch2c does not need backward computation.\n",
            "I0614 15:22:22.294519  3510 net.cpp:200] res4d_branch2c does not need backward computation.\n",
            "I0614 15:22:22.294528  3510 net.cpp:200] res4d_branch2b_relu does not need backward computation.\n",
            "I0614 15:22:22.294538  3510 net.cpp:200] scale4d_branch2b does not need backward computation.\n",
            "I0614 15:22:22.294555  3510 net.cpp:200] bn4d_branch2b does not need backward computation.\n",
            "I0614 15:22:22.294562  3510 net.cpp:200] res4d_branch2b does not need backward computation.\n",
            "I0614 15:22:22.294570  3510 net.cpp:200] res4d_branch2a_relu does not need backward computation.\n",
            "I0614 15:22:22.294579  3510 net.cpp:200] scale4d_branch2a does not need backward computation.\n",
            "I0614 15:22:22.294585  3510 net.cpp:200] bn4d_branch2a does not need backward computation.\n",
            "I0614 15:22:22.294593  3510 net.cpp:200] res4d_branch2a does not need backward computation.\n",
            "I0614 15:22:22.294600  3510 net.cpp:200] res4c_res4c_relu_0_split does not need backward computation.\n",
            "I0614 15:22:22.294610  3510 net.cpp:200] res4c_relu does not need backward computation.\n",
            "I0614 15:22:22.294617  3510 net.cpp:200] res4c does not need backward computation.\n",
            "I0614 15:22:22.294641  3510 net.cpp:200] scale4c_branch2c does not need backward computation.\n",
            "I0614 15:22:22.294648  3510 net.cpp:200] bn4c_branch2c does not need backward computation.\n",
            "I0614 15:22:22.294657  3510 net.cpp:200] res4c_branch2c does not need backward computation.\n",
            "I0614 15:22:22.294665  3510 net.cpp:200] res4c_branch2b_relu does not need backward computation.\n",
            "I0614 15:22:22.294674  3510 net.cpp:200] scale4c_branch2b does not need backward computation.\n",
            "I0614 15:22:22.294683  3510 net.cpp:200] bn4c_branch2b does not need backward computation.\n",
            "I0614 15:22:22.294692  3510 net.cpp:200] res4c_branch2b does not need backward computation.\n",
            "I0614 15:22:22.294699  3510 net.cpp:200] res4c_branch2a_relu does not need backward computation.\n",
            "I0614 15:22:22.294706  3510 net.cpp:200] scale4c_branch2a does not need backward computation.\n",
            "I0614 15:22:22.294725  3510 net.cpp:200] bn4c_branch2a does not need backward computation.\n",
            "I0614 15:22:22.294732  3510 net.cpp:200] res4c_branch2a does not need backward computation.\n",
            "I0614 15:22:22.294741  3510 net.cpp:200] res4b_res4b_relu_0_split does not need backward computation.\n",
            "I0614 15:22:22.294749  3510 net.cpp:200] res4b_relu does not need backward computation.\n",
            "I0614 15:22:22.294756  3510 net.cpp:200] res4b does not need backward computation.\n",
            "I0614 15:22:22.294764  3510 net.cpp:200] scale4b_branch2c does not need backward computation.\n",
            "I0614 15:22:22.294771  3510 net.cpp:200] bn4b_branch2c does not need backward computation.\n",
            "I0614 15:22:22.294778  3510 net.cpp:200] res4b_branch2c does not need backward computation.\n",
            "I0614 15:22:22.294796  3510 net.cpp:200] res4b_branch2b_relu does not need backward computation.\n",
            "I0614 15:22:22.294803  3510 net.cpp:200] scale4b_branch2b does not need backward computation.\n",
            "I0614 15:22:22.294812  3510 net.cpp:200] bn4b_branch2b does not need backward computation.\n",
            "I0614 15:22:22.294821  3510 net.cpp:200] res4b_branch2b does not need backward computation.\n",
            "I0614 15:22:22.294827  3510 net.cpp:200] res4b_branch2a_relu does not need backward computation.\n",
            "I0614 15:22:22.294836  3510 net.cpp:200] scale4b_branch2a does not need backward computation.\n",
            "I0614 15:22:22.294843  3510 net.cpp:200] bn4b_branch2a does not need backward computation.\n",
            "I0614 15:22:22.294852  3510 net.cpp:200] res4b_branch2a does not need backward computation.\n",
            "I0614 15:22:22.294862  3510 net.cpp:200] res4a_res4a_relu_0_split does not need backward computation.\n",
            "I0614 15:22:22.294878  3510 net.cpp:200] res4a_relu does not need backward computation.\n",
            "I0614 15:22:22.294885  3510 net.cpp:200] res4a does not need backward computation.\n",
            "I0614 15:22:22.294894  3510 net.cpp:200] scale4a_branch2c does not need backward computation.\n",
            "I0614 15:22:22.294903  3510 net.cpp:200] bn4a_branch2c does not need backward computation.\n",
            "I0614 15:22:22.294911  3510 net.cpp:200] res4a_branch2c does not need backward computation.\n",
            "I0614 15:22:22.294920  3510 net.cpp:200] res4a_branch2b_relu does not need backward computation.\n",
            "I0614 15:22:22.294945  3510 net.cpp:200] scale4a_branch2b does not need backward computation.\n",
            "I0614 15:22:22.294953  3510 net.cpp:200] bn4a_branch2b does not need backward computation.\n",
            "I0614 15:22:22.294961  3510 net.cpp:200] res4a_branch2b does not need backward computation.\n",
            "I0614 15:22:22.294970  3510 net.cpp:200] res4a_branch2a_relu does not need backward computation.\n",
            "I0614 15:22:22.294977  3510 net.cpp:200] scale4a_branch2a does not need backward computation.\n",
            "I0614 15:22:22.294984  3510 net.cpp:200] bn4a_branch2a does not need backward computation.\n",
            "I0614 15:22:22.294992  3510 net.cpp:200] res4a_branch2a does not need backward computation.\n",
            "I0614 15:22:22.295001  3510 net.cpp:200] scale4a_branch1 does not need backward computation.\n",
            "I0614 15:22:22.295008  3510 net.cpp:200] bn4a_branch1 does not need backward computation.\n",
            "I0614 15:22:22.295030  3510 net.cpp:200] res4a_branch1 does not need backward computation.\n",
            "I0614 15:22:22.295039  3510 net.cpp:200] res3d_res3d_relu_0_split does not need backward computation.\n",
            "I0614 15:22:22.295047  3510 net.cpp:200] res3d_relu does not need backward computation.\n",
            "I0614 15:22:22.295053  3510 net.cpp:200] res3d does not need backward computation.\n",
            "I0614 15:22:22.295060  3510 net.cpp:200] scale3d_branch2c does not need backward computation.\n",
            "I0614 15:22:22.295068  3510 net.cpp:200] bn3d_branch2c does not need backward computation.\n",
            "I0614 15:22:22.295075  3510 net.cpp:200] res3d_branch2c does not need backward computation.\n",
            "I0614 15:22:22.295082  3510 net.cpp:200] res3d_branch2b_relu does not need backward computation.\n",
            "I0614 15:22:22.295090  3510 net.cpp:200] scale3d_branch2b does not need backward computation.\n",
            "I0614 15:22:22.295107  3510 net.cpp:200] bn3d_branch2b does not need backward computation.\n",
            "I0614 15:22:22.295114  3510 net.cpp:200] res3d_branch2b does not need backward computation.\n",
            "I0614 15:22:22.295122  3510 net.cpp:200] res3d_branch2a_relu does not need backward computation.\n",
            "I0614 15:22:22.295130  3510 net.cpp:200] scale3d_branch2a does not need backward computation.\n",
            "I0614 15:22:22.295137  3510 net.cpp:200] bn3d_branch2a does not need backward computation.\n",
            "I0614 15:22:22.295145  3510 net.cpp:200] res3d_branch2a does not need backward computation.\n",
            "I0614 15:22:22.295152  3510 net.cpp:200] res3c_res3c_relu_0_split does not need backward computation.\n",
            "I0614 15:22:22.295161  3510 net.cpp:200] res3c_relu does not need backward computation.\n",
            "I0614 15:22:22.295167  3510 net.cpp:200] res3c does not need backward computation.\n",
            "I0614 15:22:22.295184  3510 net.cpp:200] scale3c_branch2c does not need backward computation.\n",
            "I0614 15:22:22.295192  3510 net.cpp:200] bn3c_branch2c does not need backward computation.\n",
            "I0614 15:22:22.295199  3510 net.cpp:200] res3c_branch2c does not need backward computation.\n",
            "I0614 15:22:22.295207  3510 net.cpp:200] res3c_branch2b_relu does not need backward computation.\n",
            "I0614 15:22:22.295214  3510 net.cpp:200] scale3c_branch2b does not need backward computation.\n",
            "I0614 15:22:22.295222  3510 net.cpp:200] bn3c_branch2b does not need backward computation.\n",
            "I0614 15:22:22.295229  3510 net.cpp:200] res3c_branch2b does not need backward computation.\n",
            "I0614 15:22:22.295236  3510 net.cpp:200] res3c_branch2a_relu does not need backward computation.\n",
            "I0614 15:22:22.295244  3510 net.cpp:200] scale3c_branch2a does not need backward computation.\n",
            "I0614 15:22:22.295260  3510 net.cpp:200] bn3c_branch2a does not need backward computation.\n",
            "I0614 15:22:22.295267  3510 net.cpp:200] res3c_branch2a does not need backward computation.\n",
            "I0614 15:22:22.295275  3510 net.cpp:200] res3b_res3b_relu_0_split does not need backward computation.\n",
            "I0614 15:22:22.297122  3510 net.cpp:200] res3b_relu does not need backward computation.\n",
            "I0614 15:22:22.297137  3510 net.cpp:200] res3b does not need backward computation.\n",
            "I0614 15:22:22.297147  3510 net.cpp:200] scale3b_branch2c does not need backward computation.\n",
            "I0614 15:22:22.297155  3510 net.cpp:200] bn3b_branch2c does not need backward computation.\n",
            "I0614 15:22:22.297163  3510 net.cpp:200] res3b_branch2c does not need backward computation.\n",
            "I0614 15:22:22.297181  3510 net.cpp:200] res3b_branch2b_relu does not need backward computation.\n",
            "I0614 15:22:22.297189  3510 net.cpp:200] scale3b_branch2b does not need backward computation.\n",
            "I0614 15:22:22.297196  3510 net.cpp:200] bn3b_branch2b does not need backward computation.\n",
            "I0614 15:22:22.297204  3510 net.cpp:200] res3b_branch2b does not need backward computation.\n",
            "I0614 15:22:22.297211  3510 net.cpp:200] res3b_branch2a_relu does not need backward computation.\n",
            "I0614 15:22:22.297219  3510 net.cpp:200] scale3b_branch2a does not need backward computation.\n",
            "I0614 15:22:22.297226  3510 net.cpp:200] bn3b_branch2a does not need backward computation.\n",
            "I0614 15:22:22.297233  3510 net.cpp:200] res3b_branch2a does not need backward computation.\n",
            "I0614 15:22:22.297241  3510 net.cpp:200] res3a_res3a_relu_0_split does not need backward computation.\n",
            "I0614 15:22:22.297250  3510 net.cpp:200] res3a_relu does not need backward computation.\n",
            "I0614 15:22:22.297256  3510 net.cpp:200] res3a does not need backward computation.\n",
            "I0614 15:22:22.297264  3510 net.cpp:200] scale3a_branch2c does not need backward computation.\n",
            "I0614 15:22:22.297281  3510 net.cpp:200] bn3a_branch2c does not need backward computation.\n",
            "I0614 15:22:22.297288  3510 net.cpp:200] res3a_branch2c does not need backward computation.\n",
            "I0614 15:22:22.297294  3510 net.cpp:200] res3a_branch2b_relu does not need backward computation.\n",
            "I0614 15:22:22.297303  3510 net.cpp:200] scale3a_branch2b does not need backward computation.\n",
            "I0614 15:22:22.297310  3510 net.cpp:200] bn3a_branch2b does not need backward computation.\n",
            "I0614 15:22:22.297318  3510 net.cpp:200] res3a_branch2b does not need backward computation.\n",
            "I0614 15:22:22.297327  3510 net.cpp:200] res3a_branch2a_relu does not need backward computation.\n",
            "I0614 15:22:22.297333  3510 net.cpp:200] scale3a_branch2a does not need backward computation.\n",
            "I0614 15:22:22.297340  3510 net.cpp:200] bn3a_branch2a does not need backward computation.\n",
            "I0614 15:22:22.297348  3510 net.cpp:200] res3a_branch2a does not need backward computation.\n",
            "I0614 15:22:22.297355  3510 net.cpp:200] scale3a_branch1 does not need backward computation.\n",
            "I0614 15:22:22.297363  3510 net.cpp:200] bn3a_branch1 does not need backward computation.\n",
            "I0614 15:22:22.297370  3510 net.cpp:200] res3a_branch1 does not need backward computation.\n",
            "I0614 15:22:22.297379  3510 net.cpp:200] res2c_res2c_relu_0_split does not need backward computation.\n",
            "I0614 15:22:22.297385  3510 net.cpp:200] res2c_relu does not need backward computation.\n",
            "I0614 15:22:22.297394  3510 net.cpp:200] res2c does not need backward computation.\n",
            "I0614 15:22:22.297420  3510 net.cpp:200] scale2c_branch2c does not need backward computation.\n",
            "I0614 15:22:22.297427  3510 net.cpp:200] bn2c_branch2c does not need backward computation.\n",
            "I0614 15:22:22.297435  3510 net.cpp:200] res2c_branch2c does not need backward computation.\n",
            "I0614 15:22:22.297442  3510 net.cpp:200] res2c_branch2b_relu does not need backward computation.\n",
            "I0614 15:22:22.297451  3510 net.cpp:200] scale2c_branch2b does not need backward computation.\n",
            "I0614 15:22:22.297457  3510 net.cpp:200] bn2c_branch2b does not need backward computation.\n",
            "I0614 15:22:22.297466  3510 net.cpp:200] res2c_branch2b does not need backward computation.\n",
            "I0614 15:22:22.297473  3510 net.cpp:200] res2c_branch2a_relu does not need backward computation.\n",
            "I0614 15:22:22.297480  3510 net.cpp:200] scale2c_branch2a does not need backward computation.\n",
            "I0614 15:22:22.297488  3510 net.cpp:200] bn2c_branch2a does not need backward computation.\n",
            "I0614 15:22:22.297495  3510 net.cpp:200] res2c_branch2a does not need backward computation.\n",
            "I0614 15:22:22.297504  3510 net.cpp:200] res2b_res2b_relu_0_split does not need backward computation.\n",
            "I0614 15:22:22.297511  3510 net.cpp:200] res2b_relu does not need backward computation.\n",
            "I0614 15:22:22.297519  3510 net.cpp:200] res2b does not need backward computation.\n",
            "I0614 15:22:22.297528  3510 net.cpp:200] scale2b_branch2c does not need backward computation.\n",
            "I0614 15:22:22.297534  3510 net.cpp:200] bn2b_branch2c does not need backward computation.\n",
            "I0614 15:22:22.297541  3510 net.cpp:200] res2b_branch2c does not need backward computation.\n",
            "I0614 15:22:22.297549  3510 net.cpp:200] res2b_branch2b_relu does not need backward computation.\n",
            "I0614 15:22:22.297556  3510 net.cpp:200] scale2b_branch2b does not need backward computation.\n",
            "I0614 15:22:22.297564  3510 net.cpp:200] bn2b_branch2b does not need backward computation.\n",
            "I0614 15:22:22.297571  3510 net.cpp:200] res2b_branch2b does not need backward computation.\n",
            "I0614 15:22:22.297578  3510 net.cpp:200] res2b_branch2a_relu does not need backward computation.\n",
            "I0614 15:22:22.297586  3510 net.cpp:200] scale2b_branch2a does not need backward computation.\n",
            "I0614 15:22:22.297593  3510 net.cpp:200] bn2b_branch2a does not need backward computation.\n",
            "I0614 15:22:22.297600  3510 net.cpp:200] res2b_branch2a does not need backward computation.\n",
            "I0614 15:22:22.297608  3510 net.cpp:200] res2a_res2a_relu_0_split does not need backward computation.\n",
            "I0614 15:22:22.297616  3510 net.cpp:200] res2a_relu does not need backward computation.\n",
            "I0614 15:22:22.297623  3510 net.cpp:200] res2a does not need backward computation.\n",
            "I0614 15:22:22.297644  3510 net.cpp:200] scale2a_branch2c does not need backward computation.\n",
            "I0614 15:22:22.297652  3510 net.cpp:200] bn2a_branch2c does not need backward computation.\n",
            "I0614 15:22:22.297658  3510 net.cpp:200] res2a_branch2c does not need backward computation.\n",
            "I0614 15:22:22.297667  3510 net.cpp:200] res2a_branch2b_relu does not need backward computation.\n",
            "I0614 15:22:22.297673  3510 net.cpp:200] scale2a_branch2b does not need backward computation.\n",
            "I0614 15:22:22.297680  3510 net.cpp:200] bn2a_branch2b does not need backward computation.\n",
            "I0614 15:22:22.297688  3510 net.cpp:200] res2a_branch2b does not need backward computation.\n",
            "I0614 15:22:22.297695  3510 net.cpp:200] res2a_branch2a_relu does not need backward computation.\n",
            "I0614 15:22:22.297703  3510 net.cpp:200] scale2a_branch2a does not need backward computation.\n",
            "I0614 15:22:22.297710  3510 net.cpp:200] bn2a_branch2a does not need backward computation.\n",
            "I0614 15:22:22.297717  3510 net.cpp:200] res2a_branch2a does not need backward computation.\n",
            "I0614 15:22:22.297725  3510 net.cpp:200] scale2a_branch1 does not need backward computation.\n",
            "I0614 15:22:22.297734  3510 net.cpp:200] bn2a_branch1 does not need backward computation.\n",
            "I0614 15:22:22.297740  3510 net.cpp:200] res2a_branch1 does not need backward computation.\n",
            "I0614 15:22:22.297749  3510 net.cpp:200] pool1_pool1_0_split does not need backward computation.\n",
            "I0614 15:22:22.297756  3510 net.cpp:200] pool1 does not need backward computation.\n",
            "I0614 15:22:22.297765  3510 net.cpp:200] conv1_relu does not need backward computation.\n",
            "I0614 15:22:22.297771  3510 net.cpp:200] scale_conv1 does not need backward computation.\n",
            "I0614 15:22:22.297780  3510 net.cpp:200] bn_conv1 does not need backward computation.\n",
            "I0614 15:22:22.297787  3510 net.cpp:200] conv1 does not need backward computation.\n",
            "I0614 15:22:22.297794  3510 net.cpp:200] input does not need backward computation.\n",
            "I0614 15:22:22.297801  3510 net.cpp:242] This network produces output pred\n",
            "I0614 15:22:22.298045  3510 net.cpp:255] Network initialization done.\n",
            "I0614 15:22:26.335515  3510 net.cpp:744] Ignoring source layer data\n",
            "I0614 15:22:26.352495  3510 net.cpp:744] Ignoring source layer loss\n",
            "Loaded network ./outputs/single_path_resnet_celeba.caffemodel\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wurL10pn39zf"
      },
      "source": [
        "f = open('./result/demo_result.list', 'r')\n",
        "\n",
        "attr_list = []\n",
        "for line in f.readlines():\n",
        "    line = line.strip() \n",
        "    attr = line.split(' ')\n",
        "    attr.pop(0)\n",
        "    attr_list.append(attr)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfUWBWtf6da8",
        "outputId": "4d830252-c5b1-4bec-9f7c-d67b0987f3bc"
      },
      "source": [
        "print(attr_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['0.005692181', '0.4676342', '0.12629458', '0.04546956', '0.011598891', '0.00017513617', '0.63597', '0.73359954', '0.15144116', '0.010101527', '0.00023359331', '0.007813109', '0.015172169', '0.66052794', '0.07459666', '8.363426e-05', '0.00042727374', '0.0025836388', '0.07465582', '0.082473055', '0.58289117', '0.010233769', '0.002269219', '0.0099338265', '0.995716', '0.35317215', '3.268e-06', '0.006301728', '0.9638894', '0.01651572', '0.00010190255', '0.01932922', '0.061005436', '0.021339623', '0.24289933', '0.00014709804', '0.1206886', '0.0075749205', '0.07720883', '0.9331442'], ['0.0071242303', '0.50439143', '0.09684815', '0.0545', '0.012392215', '0.00013804696', '0.62779486', '0.8005358', '0.15958026', '0.009094179', '0.00022126589', '0.007328265', '0.017572336', '0.72602946', '0.10761111', '9.8193035e-05', '0.0004040804', '0.002569601', '0.06145201', '0.10905929', '0.6293794', '0.011012197', '0.0022274717', '0.01113788', '0.99575865', '0.3332584', '2.616715e-06', '0.0055854567', '0.9686651', '0.016642459', '9.729547e-05', '0.025672555', '0.05416343', '0.022735156', '0.24869654', '0.00013139758', '0.106008515', '0.009394864', '0.048005775', '0.90242773'], ['0.01109595', '0.50859314', '0.08627097', '0.05285257', '0.013241296', '0.00010695187', '0.6434449', '0.834986', '0.19805792', '0.0072698873', '0.00022619721', '0.007473801', '0.022544887', '0.73723674', '0.1375872', '0.000117170464', '0.00050169876', '0.0024964157', '0.04255227', '0.13139574', '0.72606486', '0.014279338', '0.0026435733', '0.012480193', '0.9939573', '0.3106331', '2.1345081e-06', '0.005857259', '0.97357607', '0.016750049', '0.000104795254', '0.037708864', '0.054755695', '0.023605535', '0.23215273', '0.00011980771', '0.090667166', '0.011713284', '0.04206162', '0.8915341'], ['0.017716719', '0.5212411', '0.06319992', '0.059953056', '0.01320103', '6.9840724e-05', '0.58610475', '0.8661502', '0.22380319', '0.0056185583', '0.00026970526', '0.007554408', '0.028171059', '0.7996144', '0.24358977', '0.00014251033', '0.0005992141', '0.0027170326', '0.026195113', '0.18671554', '0.810235', '0.009498385', '0.003498964', '0.015673999', '0.99027693', '0.26801264', '1.8885075e-06', '0.0069435355', '0.9780151', '0.01696705', '0.00011593486', '0.050616637', '0.053721555', '0.027006898', '0.21415283', '0.00010831578', '0.06676338', '0.014719171', '0.03624838', '0.8576739'], ['0.0378161', '0.6330036', '0.039268192', '0.110871315', '0.011974275', '4.0362538e-05', '0.54159975', '0.9218105', '0.26654732', '0.0026588489', '0.00022392394', '0.0069930283', '0.05738043', '0.8529199', '0.4550596', '0.00021904311', '0.00061302324', '0.0026046927', '0.012473932', '0.3225658', '0.91999876', '0.005835936', '0.0051557813', '0.027571687', '0.98353946', '0.16976053', '1.3109068e-06', '0.008608768', '0.976195', '0.016863089', '0.00010333062', '0.067891665', '0.057153154', '0.031519804', '0.20194021', '0.000113082366', '0.040262938', '0.016971342', '0.03413984', '0.76471746'], ['0.16484007', '0.5665479', '0.031044502', '0.1429562', '0.013887372', '3.5048768e-05', '0.49737257', '0.92848957', '0.26549155', '0.0011119525', '0.00021939', '0.007347252', '0.15638834', '0.8225659', '0.67708206', '0.0002593979', '0.0009112428', '0.0021201523', '0.0041807014', '0.4589758', '0.98644686', '0.0054423306', '0.006255425', '0.025067635', '0.95908135', '0.13597935', '1.3586979e-06', '0.024221256', '0.9568409', '0.020922853', '0.00017963247', '0.15579024', '0.06401281', '0.032651857', '0.11897352', '0.00017114531', '0.017048273', '0.015247118', '0.043122172', '0.6433878'], ['0.33129478', '0.56051517', '0.028479388', '0.16688928', '0.016680628', '3.8394544e-05', '0.41654855', '0.92345834', '0.24565679', '0.0007473817', '0.00028160197', '0.008507744', '0.29298648', '0.8141786', '0.802702', '0.00036065502', '0.0017106994', '0.0021195442', '0.0027473865', '0.60021317', '0.9945939', '0.0038236463', '0.0076797', '0.026824147', '0.8982372', '0.11589284', '2.137972e-06', '0.04390627', '0.93236697', '0.026187375', '0.00039130388', '0.29987258', '0.06699532', '0.03265506', '0.07047169', '0.0002760609', '0.010728362', '0.01604083', '0.053660348', '0.58793485'], ['0.48080164', '0.47066584', '0.02965736', '0.19253509', '0.01848988', '3.2644646e-05', '0.30860037', '0.91696465', '0.19323856', '0.00059621554', '0.00033585043', '0.009704571', '0.37681022', '0.7844022', '0.86001414', '0.00035376044', '0.0025030822', '0.0023514237', '0.001427195', '0.6148814', '0.9976208', '0.0028012844', '0.009108259', '0.027076732', '0.82548666', '0.101780295', '2.6405542e-06', '0.07655667', '0.9138311', '0.028370652', '0.0006451794', '0.39342213', '0.06946002', '0.029778536', '0.039346863', '0.00035459924', '0.0059285574', '0.014697446', '0.05771932', '0.51665646'], ['0.5594315', '0.46848273', '0.027199648', '0.23131475', '0.02924184', '3.627016e-05', '0.27126658', '0.9126377', '0.17021975', '0.0005456837', '0.000434656', '0.008817025', '0.4408049', '0.8186209', '0.90937626', '0.00041484658', '0.003525863', '0.0029573846', '0.0010945803', '0.71364486', '0.9984627', '0.0056247697', '0.013981126', '0.024240764', '0.73255926', '0.10425871', '3.8133944e-06', '0.10659096', '0.88962555', '0.038736977', '0.001175849', '0.6102195', '0.062422916', '0.0280196', '0.034712773', '0.00048274457', '0.0047214148', '0.015916638', '0.06022376', '0.4202354'], ['0.7083695', '0.48995262', '0.029920008', '0.27669948', '0.04496529', '4.416558e-05', '0.33918172', '0.91669697', '0.15131965', '0.00061330444', '0.00048639748', '0.007934658', '0.48575038', '0.7735585', '0.9103535', '0.00047703524', '0.006862874', '0.0034515022', '0.0009390927', '0.7135892', '0.99898434', '0.0390149', '0.020065155', '0.025410604', '0.5797442', '0.09337535', '5.6055505e-06', '0.123934716', '0.8699641', '0.043679498', '0.0025374987', '0.73523974', '0.05214374', '0.028533066', '0.031714655', '0.0007248379', '0.0045583006', '0.020732842', '0.05998469', '0.39600444'], ['0.75100684', '0.54975784', '0.030859966', '0.31693286', '0.066888966', '5.331556e-05', '0.3789189', '0.92575806', '0.122554906', '0.000778275', '0.0005796485', '0.007241483', '0.53487754', '0.73265916', '0.91015995', '0.0005992525', '0.008475419', '0.004747131', '0.00083076954', '0.75702906', '0.9990797', '0.55660915', '0.020796102', '0.023557607', '0.5622872', '0.08830753', '8.127525e-06', '0.11872765', '0.8483134', '0.065348536', '0.0044755284', '0.8905642', '0.046795636', '0.025375996', '0.03288072', '0.0009446909', '0.0045407536', '0.025762869', '0.06227162', '0.35051477'], ['0.80518115', '0.57119226', '0.034766145', '0.38028157', '0.0944293', '6.0648643e-05', '0.37992242', '0.92348444', '0.10702653', '0.0007689878', '0.00059517147', '0.0065858094', '0.5636613', '0.65537924', '0.8921218', '0.0006808818', '0.009230402', '0.0057059866', '0.0006865935', '0.76726687', '0.99930036', '0.7973461', '0.020150471', '0.025623627', '0.52025867', '0.080553815', '1.1023527e-05', '0.13427731', '0.8029673', '0.07077738', '0.00593817', '0.927186', '0.041766748', '0.022066277', '0.031765755', '0.0011108563', '0.004137158', '0.028222084', '0.065238416', '0.33910936'], ['0.8299146', '0.5688306', '0.03485488', '0.428621', '0.1280505', '6.740274e-05', '0.37473333', '0.92867047', '0.0932392', '0.0007483248', '0.00065844704', '0.005994596', '0.56700695', '0.6443594', '0.90628546', '0.0007429136', '0.01239457', '0.0067735594', '0.0005860163', '0.7973144', '0.99942553', '0.87164485', '0.023954391', '0.030227322', '0.45015103', '0.08087565', '1.3619468e-05', '0.14967614', '0.76370656', '0.07741129', '0.0073072435', '0.9554369', '0.035636526', '0.020516206', '0.031726003', '0.0012713915', '0.0037580207', '0.029189754', '0.07302919', '0.29484108'], ['0.85477674', '0.5618021', '0.034314003', '0.46730465', '0.16058879', '6.639148e-05', '0.36830992', '0.9300401', '0.080378145', '0.0007142731', '0.00072947063', '0.005847103', '0.5482378', '0.617578', '0.9129109', '0.0008709756', '0.01559734', '0.0071638348', '0.0004949906', '0.8336011', '0.9994638', '0.92894745', '0.02632867', '0.03472648', '0.38712683', '0.07703836', '1.5290854e-05', '0.169709', '0.74550366', '0.08326247', '0.009458715', '0.9739021', '0.031205673', '0.019666009', '0.030820694', '0.0012916641', '0.003479454', '0.03182088', '0.07151002', '0.2680712'], ['0.8583329', '0.52786493', '0.031819463', '0.49747917', '0.19209877', '6.729672e-05', '0.3501929', '0.93311703', '0.0720651', '0.00072104123', '0.0008311397', '0.0056640753', '0.5403565', '0.6276346', '0.9242407', '0.0009423292', '0.020394314', '0.008270061', '0.0004099498', '0.8487265', '0.9995138', '0.9495316', '0.032406796', '0.038213413', '0.32360882', '0.07572304', '1.7682305e-05', '0.18148357', '0.7207916', '0.09097555', '0.012806748', '0.98079747', '0.029221695', '0.018665243', '0.02826406', '0.0013937133', '0.0031045992', '0.033597454', '0.07418109', '0.23706067'], ['0.8478284', '0.4900047', '0.028545555', '0.5337941', '0.21891406', '6.603175e-05', '0.31179178', '0.9374633', '0.06177821', '0.0007260984', '0.00088926905', '0.005612469', '0.51810205', '0.6496886', '0.93681', '0.0009145661', '0.021179214', '0.009995423', '0.00036049058', '0.86251664', '0.9995166', '0.96454036', '0.035619095', '0.0417761', '0.31085634', '0.072378926', '2.018217e-05', '0.20169917', '0.70783085', '0.10240105', '0.014819073', '0.9870901', '0.02825677', '0.01800575', '0.026507135', '0.0013901014', '0.0028545992', '0.033494614', '0.07886035', '0.19223872'], ['0.8429484', '0.4707008', '0.024442192', '0.581416', '0.25820914', '6.467635e-05', '0.2892958', '0.945935', '0.051132288', '0.0006894659', '0.00091265247', '0.005324997', '0.49644855', '0.6712836', '0.94712543', '0.001078561', '0.023056464', '0.011500228', '0.00029783096', '0.88204944', '0.99954975', '0.9744129', '0.03978058', '0.04698979', '0.28425658', '0.06679896', '2.1483933e-05', '0.20673089', '0.69977427', '0.11293219', '0.017716506', '0.9918331', '0.027009323', '0.017358758', '0.024214284', '0.001297489', '0.0025914', '0.03620693', '0.0768269', '0.15035513'], ['0.8426205', '0.43359214', '0.022751907', '0.6187012', '0.27847195', '6.7487716e-05', '0.29566824', '0.9545702', '0.045915786', '0.00068842585', '0.00096493546', '0.004892735', '0.48888746', '0.6899175', '0.9558563', '0.001117684', '0.023291536', '0.013022551', '0.00025143469', '0.89790916', '0.99960434', '0.9802935', '0.04517249', '0.054385982', '0.2686308', '0.06266127', '2.172235e-05', '0.21700265', '0.6931438', '0.120210126', '0.01783213', '0.9944044', '0.026010266', '0.016922502', '0.021475883', '0.001265028', '0.0023982995', '0.037831873', '0.077362', '0.1262499'], ['0.8422915', '0.3851695', '0.021473862', '0.65373135', '0.30129445', '7.339056e-05', '0.2987091', '0.95881224', '0.042787425', '0.0007244153', '0.001063854', '0.0046164477', '0.48342544', '0.67532724', '0.9585942', '0.0011633293', '0.024244508', '0.015047222', '0.00021830361', '0.90863323', '0.99964523', '0.9847796', '0.048719373', '0.06034279', '0.2658353', '0.060054787', '2.2787244e-05', '0.23816693', '0.6781337', '0.12556037', '0.018355874', '0.99564826', '0.025620345', '0.016021036', '0.018593572', '0.0013175006', '0.0022476986', '0.03820283', '0.075943924', '0.112641186'], ['0.84452', '0.34728485', '0.021097876', '0.6741737', '0.31888485', '7.937424e-05', '0.2945343', '0.95862746', '0.040246412', '0.00075624924', '0.0011373297', '0.004503249', '0.4639523', '0.6401272', '0.957922', '0.0012342079', '0.02517538', '0.017320387', '0.00019169397', '0.9116292', '0.99968255', '0.98748827', '0.05029293', '0.064324275', '0.25966144', '0.05793099', '2.5281453e-05', '0.26216656', '0.6659914', '0.12969515', '0.0197898', '0.9963644', '0.025014762', '0.015761917', '0.016156292', '0.001354749', '0.002092392', '0.0372547', '0.079743624', '0.103183985'], ['0.8434564', '0.3284868', '0.019980364', '0.69459987', '0.33951408', '8.495945e-05', '0.29493845', '0.95919174', '0.036773935', '0.00077526295', '0.0012800696', '0.0043232497', '0.45205343', '0.6353028', '0.9593285', '0.0013497691', '0.028611042', '0.018911615', '0.00017109644', '0.91815674', '0.9996965', '0.98898786', '0.057400428', '0.07089741', '0.24177703', '0.05520147', '2.6667345e-05', '0.2710832', '0.6469896', '0.1321905', '0.023648653', '0.99685466', '0.02385518', '0.015461459', '0.014846431', '0.0013505507', '0.0020583628', '0.039185587', '0.07899302', '0.0959235'], ['0.84375', '0.3075077', '0.0187073', '0.7089337', '0.3592186', '8.760894e-05', '0.28820187', '0.9618697', '0.032040536', '0.0007923688', '0.0014051262', '0.004221384', '0.4406082', '0.6394913', '0.9618573', '0.0014202388', '0.03444445', '0.020539492', '0.00015794368', '0.92355895', '0.9997096', '0.9896859', '0.06189762', '0.076193124', '0.21804267', '0.05322486', '2.7478553e-05', '0.26876923', '0.6312124', '0.13539436', '0.031263947', '0.9972826', '0.023024827', '0.015186609', '0.01362492', '0.0013292246', '0.0019896785', '0.04021669', '0.07603802', '0.08923412'], ['0.8413222', '0.27829736', '0.016827945', '0.7263166', '0.3839695', '8.276972e-05', '0.27375162', '0.9636147', '0.026719473', '0.0007655913', '0.0014941891', '0.004078729', '0.41712308', '0.64711845', '0.9658992', '0.0014949586', '0.040780816', '0.021899562', '0.00012972913', '0.92951894', '0.99975866', '0.98975945', '0.06478488', '0.08209264', '0.19377685', '0.051476263', '2.7755856e-05', '0.27641177', '0.62187546', '0.13741334', '0.037132874', '0.99773633', '0.021704864', '0.014674464', '0.011535714', '0.0012038422', '0.0017205507', '0.036493324', '0.078468695', '0.07950769'], ['0.84842384', '0.2621333', '0.015301244', '0.7494137', '0.39664388', '8.051205e-05', '0.25797564', '0.9654714', '0.022885596', '0.00075664755', '0.0015263811', '0.0041510463', '0.39911586', '0.64177155', '0.9660124', '0.0016356359', '0.04628954', '0.024112742', '0.00011424073', '0.9293064', '0.99976844', '0.988387', '0.06712588', '0.08914593', '0.174935', '0.04754976', '2.810331e-05', '0.29334816', '0.6355428', '0.14233784', '0.044704564', '0.99777704', '0.021844756', '0.014819528', '0.010522339', '0.0011188444', '0.0016166032', '0.03614454', '0.07568514', '0.07262766'], ['0.8668721', '0.24402948', '0.014495276', '0.767168', '0.40490213', '7.7834164e-05', '0.2387976', '0.96501076', '0.019229824', '0.00078398746', '0.0015978166', '0.0042934725', '0.37245893', '0.60728145', '0.96363854', '0.0019108164', '0.05517918', '0.025771929', '9.925738e-05', '0.92461383', '0.99977934', '0.98782176', '0.066889405', '0.0949647', '0.14734024', '0.04280334', '2.7835802e-05', '0.31952816', '0.64844525', '0.1399001', '0.055715557', '0.99775904', '0.02217672', '0.014927655', '0.009483492', '0.0010332395', '0.0015013254', '0.036047056', '0.068547465', '0.068900436'], ['0.87178254', '0.22814676', '0.013579632', '0.7846913', '0.4136718', '7.922077e-05', '0.22503576', '0.96645415', '0.01593929', '0.0008467556', '0.0016330504', '0.004521396', '0.35372525', '0.604255', '0.9647439', '0.0021021334', '0.06088507', '0.028060205', '8.89003e-05', '0.9226094', '0.9998015', '0.9879943', '0.06657682', '0.09957422', '0.13166708', '0.041658103', '2.9199071e-05', '0.33951044', '0.6475634', '0.14800134', '0.068474986', '0.9978751', '0.023850914', '0.014628631', '0.008620024', '0.0009892024', '0.0013440695', '0.034014657', '0.06855782', '0.064772256'], ['0.87077177', '0.21168557', '0.0126215145', '0.7962315', '0.4278195', '8.215313e-05', '0.21267632', '0.9673016', '0.013745037', '0.00088865764', '0.0017051548', '0.004622868', '0.33647615', '0.6163805', '0.966918', '0.002243521', '0.06721741', '0.032243207', '8.126046e-05', '0.92437834', '0.9998174', '0.98762167', '0.07308674', '0.10678119', '0.12387882', '0.041188452', '3.1443484e-05', '0.35566366', '0.64469063', '0.15739515', '0.07797974', '0.9980006', '0.02437487', '0.014445831', '0.007882886', '0.0009577612', '0.0012406682', '0.03259365', '0.068836614', '0.058449388'], ['0.8733978', '0.19265006', '0.011661624', '0.8035983', '0.45089054', '8.402664e-05', '0.20714211', '0.9677552', '0.011807693', '0.00089984655', '0.0017477444', '0.0045142015', '0.32556593', '0.6233047', '0.96835876', '0.0024634022', '0.07872248', '0.03550954', '7.2090304e-05', '0.9259131', '0.9998362', '0.98737603', '0.07616829', '0.1138457', '0.11061153', '0.04049497', '3.3297525e-05', '0.36893576', '0.6327938', '0.15992612', '0.089183', '0.9981104', '0.022964831', '0.014120201', '0.0071096467', '0.00092965853', '0.0011084384', '0.030880477', '0.06619523', '0.053643413'], ['0.86996216', '0.18336573', '0.011413652', '0.80751795', '0.47907194', '8.520493e-05', '0.20710993', '0.96819365', '0.011159439', '0.00092405104', '0.001896288', '0.004270545', '0.32407975', '0.60675144', '0.96640253', '0.0027514808', '0.08976073', '0.039377645', '6.720477e-05', '0.92458797', '0.9998417', '0.9874052', '0.08204387', '0.12418555', '0.10429485', '0.039052058', '3.6223868e-05', '0.37974703', '0.63514245', '0.15643007', '0.094669506', '0.99807096', '0.021904103', '0.0140456315', '0.006317026', '0.00094985764', '0.0011198121', '0.030548017', '0.06720079', '0.051509243'], ['0.8666043', '0.17230222', '0.010869936', '0.8118342', '0.5017866', '8.510258e-05', '0.21109894', '0.96924293', '0.010256326', '0.0009281142', '0.0020480547', '0.0041093985', '0.31955636', '0.60356796', '0.9653541', '0.0028358905', '0.1050934', '0.04225183', '6.227392e-05', '0.92339826', '0.99984354', '0.9875683', '0.091190174', '0.13275486', '0.09196092', '0.038698964', '3.9333478e-05', '0.380951', '0.64156973', '0.14981735', '0.105661005', '0.99800634', '0.020742342', '0.013583468', '0.0058959816', '0.00096462463', '0.0011077551', '0.02981501', '0.06890455', '0.04879465'], ['0.86766434', '0.16100004', '0.010657232', '0.8144536', '0.51857996', '8.3625746e-05', '0.20590216', '0.96910095', '0.009474101', '0.0009570122', '0.0021207351', '0.0040569343', '0.32135314', '0.5981028', '0.96353674', '0.0028398845', '0.12395091', '0.04648889', '5.698303e-05', '0.92036855', '0.99985355', '0.9874475', '0.1033241', '0.13976946', '0.07635121', '0.038234934', '4.2803003e-05', '0.3948766', '0.64313436', '0.14875923', '0.12794277', '0.9979748', '0.020636786', '0.013421973', '0.00543567', '0.0009522609', '0.0010760506', '0.029294457', '0.068549275', '0.045745216'], ['0.87113243', '0.15241691', '0.0099953385', '0.81944335', '0.5145907', '7.9605285e-05', '0.19799049', '0.9690627', '0.00889227', '0.0009652875', '0.0021467104', '0.004112993', '0.3156797', '0.5882987', '0.96146154', '0.002957913', '0.1389417', '0.0484751', '5.3102805e-05', '0.91790676', '0.99985236', '0.9869362', '0.11175513', '0.14454848', '0.064960234', '0.036076196', '4.2885735e-05', '0.40904972', '0.65582097', '0.14816356', '0.14684708', '0.9978564', '0.021569096', '0.013532149', '0.004995407', '0.00094586285', '0.0010642936', '0.030267745', '0.06292376', '0.04378674'], ['0.86676717', '0.14439368', '0.009295121', '0.8203565', '0.5105204', '7.730306e-05', '0.19212574', '0.96820545', '0.008415553', '0.00096862216', '0.0022566067', '0.004173435', '0.31830746', '0.5962359', '0.959723', '0.0028744582', '0.15695876', '0.0527268', '4.9569164e-05', '0.91236234', '0.9998537', '0.98588234', '0.13227761', '0.15283069', '0.05282914', '0.03455938', '4.4296932e-05', '0.41172826', '0.66983354', '0.1468839', '0.17306893', '0.99756074', '0.022000367', '0.014026995', '0.0046125846', '0.00093027676', '0.0010463954', '0.031347543', '0.0614924', '0.041402526'], ['0.85332465', '0.14034557', '0.00816559', '0.8280879', '0.5003626', '7.671565e-05', '0.18491146', '0.9690898', '0.007776307', '0.0009901448', '0.0023785457', '0.00456308', '0.31102917', '0.6067187', '0.95758903', '0.0028424002', '0.18235639', '0.057543933', '4.7009868e-05', '0.9078407', '0.99984956', '0.98612094', '0.15235184', '0.16208497', '0.0430993', '0.033856984', '4.615653e-05', '0.40806022', '0.6874003', '0.14188927', '0.20173287', '0.9973593', '0.02314206', '0.014814697', '0.0043712575', '0.00092232996', '0.0010258364', '0.032126017', '0.0582288', '0.03771936'], ['0.8450371', '0.13807464', '0.007253968', '0.8352276', '0.49143064', '7.822752e-05', '0.18703553', '0.97082233', '0.007367151', '0.0010258176', '0.0024905207', '0.004810719', '0.30947176', '0.622938', '0.9561517', '0.0030989377', '0.2163882', '0.062048748', '4.4966844e-05', '0.9058578', '0.9998464', '0.98573935', '0.17870957', '0.17132983', '0.03406103', '0.03321288', '4.887692e-05', '0.40171957', '0.70195967', '0.13871802', '0.24431607', '0.99726146', '0.024275936', '0.015512434', '0.0043708', '0.0009175468', '0.0010419027', '0.034183055', '0.056066927', '0.034821257'], ['0.81748164', '0.13322768', '0.006443957', '0.8362925', '0.4963179', '8.411531e-05', '0.18793413', '0.9720453', '0.0070779086', '0.0010141548', '0.0025573773', '0.004774249', '0.30671898', '0.6463649', '0.95436394', '0.0036518006', '0.25629568', '0.06907388', '4.416941e-05', '0.9054018', '0.999848', '0.9854188', '0.21914922', '0.17803344', '0.028397184', '0.033462755', '5.242395e-05', '0.393848', '0.70033693', '0.1375108', '0.26800328', '0.9971026', '0.024506828', '0.015017897', '0.004199339', '0.0009246188', '0.0010536155', '0.035438634', '0.054984916', '0.03159255'], ['0.7961339', '0.12987581', '0.005729411', '0.83899665', '0.49491405', '8.392535e-05', '0.18536183', '0.9734998', '0.006729547', '0.0009845936', '0.0026997488', '0.0048235767', '0.29309464', '0.66624737', '0.9540562', '0.004119319', '0.2877581', '0.07407889', '4.288697e-05', '0.90107006', '0.9998475', '0.98376465', '0.25751445', '0.18142232', '0.024040014', '0.03301507', '5.377801e-05', '0.3827167', '0.70073307', '0.1314386', '0.2958188', '0.9967446', '0.024543341', '0.014847516', '0.0041103447', '0.00091196754', '0.0010208633', '0.03597854', '0.05304955', '0.028606068'], ['0.766678', '0.12746921', '0.005238886', '0.83994675', '0.5135143', '8.963161e-05', '0.18457106', '0.9749689', '0.006741724', '0.0010215293', '0.0030003698', '0.0048627625', '0.28868544', '0.6867925', '0.9526199', '0.0047244527', '0.31971142', '0.08327952', '4.552182e-05', '0.89856094', '0.9998355', '0.982239', '0.30406561', '0.19386846', '0.021018453', '0.033358805', '5.8690744e-05', '0.36502934', '0.7061914', '0.13144392', '0.3163134', '0.99638855', '0.023674171', '0.015193807', '0.0042322995', '0.00091699354', '0.0010545871', '0.03802266', '0.051061496', '0.026346928'], ['0.71681744', '0.12031092', '0.0045549637', '0.8421749', '0.52688205', '9.401508e-05', '0.17380175', '0.97626317', '0.0060119536', '0.0010503824', '0.0030276524', '0.0049211755', '0.2752486', '0.7196676', '0.9532373', '0.005340147', '0.36509097', '0.095288254', '4.5547316e-05', '0.8991688', '0.9998362', '0.98021865', '0.3465378', '0.1950801', '0.017477509', '0.035266373', '6.2961306e-05', '0.35223067', '0.6994992', '0.13704371', '0.3394916', '0.9962782', '0.023024464', '0.0150421', '0.0039521474', '0.0008949307', '0.0010245659', '0.037514146', '0.04915261', '0.02230716'], ['0.6631889', '0.11310832', '0.0039707874', '0.84345734', '0.5413706', '0.00010016216', '0.16520315', '0.9774836', '0.0052248077', '0.0010709211', '0.002913', '0.004918663', '0.2654669', '0.76208454', '0.95492816', '0.0054750917', '0.43080917', '0.104509026', '4.298632e-05', '0.8965057', '0.99985576', '0.9778985', '0.38657492', '0.19841775', '0.013406847', '0.03731015', '6.7345434e-05', '0.33050382', '0.68519074', '0.14199707', '0.39408338', '0.99618393', '0.02186106', '0.015148498', '0.003500707', '0.00084811426', '0.0009419334', '0.03496217', '0.048091605', '0.018950978'], ['0.6323793', '0.10597922', '0.0035593673', '0.8488135', '0.55601907', '0.000104612365', '0.1572882', '0.9785081', '0.0045681894', '0.0010589764', '0.0028533353', '0.004964012', '0.24823415', '0.79225326', '0.9557183', '0.0055643106', '0.47525257', '0.11601283', '3.989049e-05', '0.89215505', '0.9998711', '0.97437966', '0.42395115', '0.20309204', '0.010746526', '0.038032442', '7.3580784e-05', '0.31778413', '0.67316604', '0.14499474', '0.44146582', '0.99584645', '0.020696986', '0.015470603', '0.0032619569', '0.00081338605', '0.000865246', '0.033070706', '0.04566893', '0.016511373'], ['0.5930928', '0.09542337', '0.00311158', '0.85236204', '0.5631419', '0.00010355572', '0.14505157', '0.97915983', '0.004151544', '0.0010466382', '0.002912274', '0.004878874', '0.23248851', '0.80498785', '0.9527559', '0.005786689', '0.50816715', '0.13453637', '3.7113918e-05', '0.8795468', '0.9998788', '0.96854496', '0.45205754', '0.20683512', '0.009377966', '0.037435006', '7.8844925e-05', '0.3138464', '0.6812904', '0.1429208', '0.476241', '0.99495745', '0.0199459', '0.015944773', '0.0030055263', '0.00077721843', '0.000807149', '0.031283516', '0.043393698', '0.014084844'], ['0.53872347', '0.088191174', '0.002654747', '0.8582338', '0.56801164', '0.000106143816', '0.1301173', '0.97958636', '0.0036318316', '0.0010854995', '0.0029776338', '0.004992122', '0.22137277', '0.8101083', '0.94712853', '0.006138443', '0.54662704', '0.16036049', '3.492613e-05', '0.86318713', '0.9998755', '0.9607637', '0.49343848', '0.21726793', '0.007940908', '0.03488891', '8.546633e-05', '0.31631917', '0.6920899', '0.14305165', '0.51814324', '0.99370295', '0.020237675', '0.016010525', '0.0026985558', '0.00077093486', '0.00077488425', '0.030379113', '0.04122734', '0.0115400255'], ['0.478855', '0.077623725', '0.0021819368', '0.86756325', '0.5770583', '0.000106346684', '0.11475525', '0.97967184', '0.0030122674', '0.0010782836', '0.0029282765', '0.004971314', '0.21012759', '0.81876755', '0.9425715', '0.0068852506', '0.5800553', '0.18559504', '3.0630028e-05', '0.85061085', '0.9998827', '0.95613086', '0.5214603', '0.2295364', '0.0066517624', '0.03357377', '9.033537e-05', '0.31494963', '0.6933779', '0.1425547', '0.5625603', '0.99272346', '0.02006726', '0.01578801', '0.0022870933', '0.0007464702', '0.00067310286', '0.027768368', '0.039657302', '0.009210939'], ['0.43264198', '0.06708141', '0.0017712244', '0.87509775', '0.59272915', '0.000101980884', '0.100554615', '0.9804975', '0.002348417', '0.0010506946', '0.0028131388', '0.004768923', '0.18979695', '0.8321576', '0.941555', '0.007559907', '0.59231687', '0.208668', '2.6505142e-05', '0.8397114', '0.9998898', '0.9459338', '0.51622105', '0.23634474', '0.005937283', '0.032787323', '8.97234e-05', '0.3155083', '0.69526684', '0.14115395', '0.5885572', '0.99138707', '0.019570261', '0.01522131', '0.0020288639', '0.00068948645', '0.0005707869', '0.024910912', '0.038093273', '0.0072665648'], ['0.3886538', '0.05999814', '0.0014798776', '0.8771484', '0.59094715', '9.950443e-05', '0.09517445', '0.98089933', '0.001970648', '0.0010583203', '0.0027098572', '0.00468133', '0.17225724', '0.8420742', '0.9441893', '0.008470378', '0.6011457', '0.22577813', '2.400492e-05', '0.8265823', '0.99989325', '0.9381676', '0.50870514', '0.24617851', '0.0058416594', '0.03140595', '8.978933e-05', '0.31683975', '0.69233936', '0.14169425', '0.5815672', '0.9901006', '0.019698678', '0.015290009', '0.001761849', '0.00065456104', '0.0005172951', '0.023235884', '0.037436403', '0.0063666925'], ['0.36347362', '0.058521353', '0.0013246445', '0.8836905', '0.60329986', '0.00010524645', '0.08690265', '0.9806821', '0.0019113221', '0.0009764134', '0.0025630747', '0.004615737', '0.15327555', '0.848055', '0.94155484', '0.010323582', '0.60817045', '0.24363992', '2.2233124e-05', '0.82691044', '0.99989676', '0.9237951', '0.54495573', '0.2651794', '0.0054439893', '0.029573482', '9.1627175e-05', '0.3247803', '0.6829894', '0.14823987', '0.56174505', '0.9888295', '0.018942352', '0.015528231', '0.0016574403', '0.0006149566', '0.0004908365', '0.023546547', '0.03724793', '0.005757479'], ['0.30603445', '0.043331083', '0.0010781039', '0.8889264', '0.61991966', '0.00011983322', '0.07609183', '0.98069656', '0.0015409351', '0.0009150458', '0.0024787518', '0.003964005', '0.11029108', '0.8691315', '0.9413186', '0.017148169', '0.61692905', '0.2746663', '1.9210765e-05', '0.8189792', '0.9999115', '0.90233004', '0.58175254', '0.2867373', '0.0050968905', '0.029063957', '9.104253e-05', '0.31690145', '0.6461665', '0.15742317', '0.5178311', '0.9859116', '0.017046321', '0.014836153', '0.0014620997', '0.00061614637', '0.00042158042', '0.022577042', '0.037068486', '0.0045323814'], ['0.23566946', '0.021065263', '0.0010954901', '0.8558256', '0.6207037', '0.00016424124', '0.082645446', '0.9682914', '0.0013348061', '0.0007630071', '0.0022601455', '0.0030923951', '0.050651204', '0.8471892', '0.91991216', '0.11749231', '0.5838925', '0.3066441', '1.7007387e-05', '0.81661224', '0.9999248', '0.870396', '0.57227755', '0.22577327', '0.0058725937', '0.03361602', '9.401362e-05', '0.3426506', '0.53682154', '0.14261729', '0.41196162', '0.9810494', '0.017642472', '0.011181423', '0.0015019588', '0.00072623754', '0.00034739188', '0.019438393', '0.03986045', '0.0045682695'], ['0.17183226', '0.005477567', '0.0008497562', '0.7448875', '0.53036886', '0.00017166355', '0.07597859', '0.96305096', '0.001111265', '0.000873432', '0.0023749783', '0.003134866', '0.016413493', '0.85500044', '0.91446245', '0.5598042', '0.54306567', '0.29250252', '1.1848933e-05', '0.7630217', '0.9999447', '0.80970687', '0.4999826', '0.14409225', '0.0061320504', '0.035382222', '7.1978415e-05', '0.2688172', '0.44423252', '0.10545546', '0.33240318', '0.96798635', '0.019091405', '0.0096887', '0.0013419725', '0.0006900595', '0.00026479756', '0.016553072', '0.0349685', '0.0040688226'], ['0.14727981', '0.0029772061', '0.00072767655', '0.7198023', '0.5510357', '0.00017469174', '0.06624511', '0.9598464', '0.0008488825', '0.0010522571', '0.002338682', '0.0028627557', '0.009012063', '0.8662866', '0.9109866', '0.624021', '0.56149185', '0.30464667', '1.0116793e-05', '0.7210993', '0.9999543', '0.77509475', '0.4913266', '0.1456576', '0.005249895', '0.035505235', '7.120845e-05', '0.2460801', '0.43356124', '0.09855279', '0.35143262', '0.9583386', '0.017123409', '0.008339595', '0.0012394635', '0.0006399527', '0.00021771721', '0.014760996', '0.03210103', '0.0038969682'], ['0.12266289', '0.0022493263', '0.0006005568', '0.70783794', '0.5692382', '0.00017430948', '0.06034377', '0.9560882', '0.0007806367', '0.0010360398', '0.0023670984', '0.0025807824', '0.006379215', '0.8751347', '0.90798664', '0.7186073', '0.56731796', '0.30885193', '8.510385e-06', '0.6767048', '0.99996114', '0.75111604', '0.51062214', '0.14432824', '0.0044425237', '0.03268134', '6.623147e-05', '0.21535751', '0.43143183', '0.0852021', '0.34284103', '0.9457553', '0.015305385', '0.007639341', '0.0012169075', '0.0005861629', '0.00017544965', '0.013994187', '0.031476695', '0.0034436914'], ['0.11902789', '0.0016375616', '0.000656095', '0.69097424', '0.5996355', '0.00019055771', '0.054860145', '0.9510945', '0.00075572263', '0.0012635506', '0.0023204628', '0.00242282', '0.0034591542', '0.8748038', '0.89682245', '0.82939035', '0.6162518', '0.3050353', '7.597804e-06', '0.64313245', '0.9999653', '0.7263611', '0.5262754', '0.17871284', '0.00396204', '0.030736726', '5.901261e-05', '0.20299852', '0.43189615', '0.073142715', '0.30886784', '0.9377448', '0.014081859', '0.0070303883', '0.0012346231', '0.00047566823', '0.00015511966', '0.014672002', '0.030115899', '0.0038407124'], ['0.11203083', '0.0012199599', '0.00061388203', '0.6696811', '0.6133072', '0.00019913909', '0.050577775', '0.947877', '0.00068452896', '0.0015044255', '0.0023195758', '0.0023777382', '0.0024994756', '0.8849882', '0.89194834', '0.8965777', '0.64976764', '0.3026994', '6.909034e-06', '0.6314304', '0.9999689', '0.6966002', '0.5240115', '0.1781651', '0.0031859449', '0.031816233', '5.371889e-05', '0.18349335', '0.4221894', '0.065759316', '0.3355416', '0.93525875', '0.012867181', '0.0065816077', '0.0012307274', '0.00042971683', '0.00013763513', '0.014688902', '0.02833762', '0.003545687'], ['0.100698255', '0.0009231729', '0.00055459316', '0.6608983', '0.6094439', '0.00019013601', '0.043459482', '0.9421573', '0.0005632954', '0.0016887835', '0.002510413', '0.002381897', '0.0021432359', '0.879079', '0.87799585', '0.8732685', '0.66003746', '0.31672835', '5.260434e-06', '0.5671234', '0.9999763', '0.65646195', '0.5389124', '0.16801849', '0.0027884953', '0.029034633', '4.9358216e-05', '0.18163532', '0.41500318', '0.055317823', '0.37436825', '0.9125079', '0.012817889', '0.0060083745', '0.0009501881', '0.00039893473', '0.00010592719', '0.012740372', '0.026141414', '0.0030719372'], ['0.09165484', '0.00077588914', '0.00055733416', '0.6480168', '0.6044376', '0.000192268', '0.03796248', '0.9345144', '0.00049920724', '0.0020654947', '0.002628016', '0.002387656', '0.0018532212', '0.86953473', '0.8593092', '0.83894217', '0.6771622', '0.32876986', '4.516169e-06', '0.5018171', '0.9999794', '0.61788034', '0.5553381', '0.15543404', '0.002527502', '0.026517592', '4.885038e-05', '0.19211009', '0.42405474', '0.050005123', '0.40504903', '0.88484955', '0.012708088', '0.005980532', '0.00077203184', '0.00037672068', '9.5198615e-05', '0.012525838', '0.02325831', '0.002979035'], ['0.077166125', '0.00064764754', '0.00054478773', '0.6197974', '0.5994203', '0.00019398877', '0.034856085', '0.9234656', '0.00040804548', '0.0025199186', '0.0028343422', '0.0023241905', '0.0014206201', '0.8596755', '0.8316293', '0.8605007', '0.68682206', '0.35054332', '4.04558e-06', '0.42832118', '0.99998164', '0.590745', '0.56330377', '0.13764963', '0.002368039', '0.02655338', '4.9921833e-05', '0.19573042', '0.45386404', '0.043777615', '0.4315962', '0.8526041', '0.01220158', '0.005799576', '0.00064083154', '0.0003456297', '8.762098e-05', '0.01232303', '0.021956831', '0.0027653477'], ['0.0658206', '0.0005189683', '0.0005284009', '0.58987844', '0.59641266', '0.00020321683', '0.031227026', '0.90511316', '0.00034162425', '0.0030026378', '0.003164935', '0.0023292883', '0.0009946227', '0.8402915', '0.80693287', '0.88602424', '0.67143184', '0.36634144', '3.435603e-06', '0.3655393', '0.99998283', '0.5338997', '0.5618994', '0.119732976', '0.002391273', '0.025401734', '5.0188522e-05', '0.19867547', '0.4616574', '0.03682102', '0.43443632', '0.80625355', '0.011186069', '0.0054329336', '0.0005386058', '0.00031626358', '7.8276804e-05', '0.011916805', '0.020703686', '0.002616231'], ['0.058587313', '0.0004283007', '0.00051824097', '0.57102084', '0.5860902', '0.00022480656', '0.02834406', '0.88617444', '0.00031233692', '0.003412463', '0.0034791497', '0.0024438445', '0.00079528766', '0.82916975', '0.7805003', '0.90226126', '0.6546', '0.3722172', '3.357934e-06', '0.32794636', '0.9999826', '0.49063212', '0.5455973', '0.10930751', '0.0024988125', '0.025064442', '5.059105e-05', '0.19558814', '0.4618433', '0.031970553', '0.43449283', '0.76432866', '0.01116216', '0.00521651', '0.0004935451', '0.00029498854', '7.431143e-05', '0.011376505', '0.019316765', '0.002598886'], ['0.054592296', '0.00039282476', '0.0005040548', '0.55930424', '0.5609788', '0.00024019124', '0.026458254', '0.8650342', '0.00031068263', '0.0037282351', '0.0040091793', '0.0024159502', '0.0007033938', '0.81492436', '0.75682944', '0.9028345', '0.63346946', '0.3847055', '3.2246915e-06', '0.28773683', '0.99998266', '0.43362892', '0.56594867', '0.103538334', '0.00252163', '0.023732401', '4.9741073e-05', '0.19965622', '0.4734739', '0.0292143', '0.4251503', '0.70735514', '0.011512289', '0.0049227914', '0.00046659456', '0.00027698156', '7.08759e-05', '0.011683833', '0.018855099', '0.0025444266'], ['0.054158863', '0.00038886393', '0.00049011013', '0.56217325', '0.55617476', '0.0002533032', '0.025353394', '0.84227324', '0.00030645455', '0.003980181', '0.004424394', '0.0023385568', '0.0006225037', '0.80386364', '0.7439192', '0.89942044', '0.6056875', '0.38753796', '2.9519456e-06', '0.25972724', '0.9999832', '0.397784', '0.58953786', '0.10114459', '0.002510842', '0.022642927', '4.9202776e-05', '0.20766824', '0.48474687', '0.02798268', '0.42923814', '0.65027696', '0.0116516845', '0.004669132', '0.0004648879', '0.00026179687', '6.617473e-05', '0.012071073', '0.019035727', '0.0026085696']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Wtv4rOv6s1E"
      },
      "source": [
        "temp = np.array(attr_list,dtype=float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "8_dACfN24mtI",
        "outputId": "a7a8e254-b958-4cd0-e8c2-bc06f9e99c1d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.xlabel('alpha')\n",
        "plt.ylabel('young')\n",
        "plt.scatter(alpha_list,temp[:,-1])\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "4kLOL-Yv4uQP",
        "outputId": "0ff85539-0d84-4bdd-e55d-e05194317d9e"
      },
      "source": [
        "plt.xlabel('alpha')\n",
        "plt.ylabel('glass')\n",
        "plt.scatter(alpha_list,temp[:,15])\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXMklEQVR4nO3df5Bd5X3f8feXZW3Wkm05haiWkIHMYGES7CjaQqjSZjfGkeLWoGCwsSkdNyUqk8h2xrZSVDq4wU1Romlap8atqeNpMsXeAaOoGkeu3Fba0LqBSLIgMgJlFGoCSxuDjTAyG7OIb/+4d+Wr1d3d++vsvXfP+zWj4Z7nPOfu95HY87nnPOeeE5mJJKm8zup2AZKk7jIIJKnkDAJJKjmDQJJKziCQpJI7u9sFNOvcc8/NCy+8sKVtv//977NkyZLOFtQljqX3LJZxgGPpVe2M5eDBg89l5nn11vVdEFx44YUcOHCgpW3Hx8cZGRnpbEFd4lh6z2IZBziWXtXOWCLiydnWeWpIkkrOIJCkkjMIJKnkDAJJKjmDQJJKru+uGpKkxWLnoQm27znKM8cnWbFsiC3rVwOc0bZxzcpC6zAIJKkLdh6aYOuOw0xOnQRg4vgkW+57BAKmTuaptq07DnPgye+y7/FnuWHVi9y2bW/Hw8EgkKQZ6n1S7/Sn8u17jp4KgWlTr575WIDJqZPc8+BfkgCrfhgOQMdqco5AkmpMf1KfOD5J8sMd785DEx39Oc8cn2y478x4mJw6yfY9RztWi0cEklSj3if16R1vq5/A6x1hrFg2xEQTYTBTM0EyH48IJKnGbDvYVne8sx1hjF5yHkODA6f1HTwrGByI09pOX/qhFcuGWqqnHoNAkmrMtoNtdcc72xHGvsef5c5rL2PlsiECWLlsiO3Xv4Pt173jtLYbf/otZwTG0ODAqSuMOsFTQ5JUY8v61addzQOVHe/oJeexbtvepieQ5zrC2LhmZd33mNk2fMGPVOcEXmRlAZPXBoEk1Zjewdae0x+95DzuPzhx2qWejV65M9tcQDNHGNOBMT4+zodvHGl4u0YZBJI0w8xP6uu27W15Anm2I4xOntppl3MEkjSPZiaQdx6aYN22vVx06x+xbttegDPmAu689rLCvy3cDI8IJGkejZ7eqfdt4a07DnPntZfx9Vt/bkFqbYVHBJI0jy3rVzd05c5c30HoZR4RSNI86k0g17typ9PfQVgoBoEkNaDepZ4zvzG87HWDPP/S1BnbdvLLX0UwCCSpBfXmA6a/GTx991DovSuE6jEIJJVaq3cane3uocuGBlny2rMX9HkC7TIIJJXWbFf5wPxfFJvtvP8Lk1M8/Mmf72yhBfOqIUml1c5VPp2+J1E3GQSSSqudq3wavaS0HxgEkkqrnU/1G9es7PlvDDfKOQJJpdXufYBmu3tovzEIJJVWo18UW+wKDYKI2AB8GhgAPp+Z22asfwvw+8Cyap9bM3N3kTVJUq3F8qm+HYXNEUTEAHAX8AvApcAHIuLSGd3+OXBvZq4BbgA+W1Q9kqT6ipwsvhw4lplPZObLwBhwzYw+Cbyh+vqNwDMF1iNJqiMyc/5erbxxxHXAhsy8ubp8E3BFZm6u6fNm4GvAm4AlwFWZebDOe20CNgEsX7587djYWEs1nThxgqVLl7a0ba9xLL1nsYwDHEuvamcso6OjBzNzuO7KzCzkD3AdlXmB6eWbgM/M6PMx4OPV11cCR4Cz5nrftWvXZqv27dvX8ra9xrH0nsUyjkzH0qvaGQtwIGfZrxZ5amgCWFWzfH61rdY/Bu4FyMw/Ac4Bzi2wJknSDEUGwX7g4oi4KCJeQ2UyeNeMPn8JvBMgIt5GJQieLbAmSdIMhQVBZr4CbAb2AI9RuTro0Yi4IyKurnb7OPDLEfEI8CXgQ9VDGEnSAin0ewRZ+U7A7hltt9e8PgKsK7IGSdLcvNeQJJWcQSBJJWcQSFLJGQSSVHIGgSSVnEEgSSVnEEhSyRkEklRyBoEklZyPqpRUGjsPTZT+sZT1GASSSmHnoYnTHlQ/cXySrTsOA5Q+DDw1JKkUtu85eioEpk1OnWT7nqNdqqh3GASSSuGZ45NNtZeJQSCpFFYsG2qqvUwMAkmlsGX9aoYGB05rGxocYMv61V2qqHc4WSypFKYnhL1q6EwGgaTS2LhmpTv+Ojw1JEklZxBIUskZBJJUcgaBJJWcQSBJJWcQSFLJGQSSVHIGgSSVnEEgSSVnEEhSyRkEklRyBoEklZxBIGlR2nlognXb9nJ44gXWbdvLzkMT3S6pZ3n3UUmLzmnPJ17l84nn4xGBpEXH5xM3xyCQtOj4fOLmGASSFh2fT9ycQoMgIjZExNGIOBYRt87S530RcSQiHo2ILxZZj6Ry8PnEzSlssjgiBoC7gHcBTwP7I2JXZh6p6XMxsBVYl5nPR8SPFlWPpPKofT4xvMhKn088pyKvGrocOJaZTwBExBhwDXCkps8vA3dl5vMAmfntAuuRVCLTzyceHx/nwzeOdLucnlbkqaGVwFM1y09X22q9FXhrRHw9Ih6MiA0F1iNJqiMys5g3jrgO2JCZN1eXbwKuyMzNNX2+AkwB7wPOBx4ALsvM4zPeaxOwCWD58uVrx8bGWqrpxIkTLF26tKVte41j6T2LZRzgWHpVO2MZHR09mJnD9dYVeWpoAlhVs3x+ta3W08BDmTkF/J+I+HPgYmB/bafMvBu4G2B4eDhHRkZaKmh8fJxWt+01jqX3LJZxgGPpVUWNpchTQ/uBiyPiooh4DXADsGtGn53ACEBEnEvlVNETBdYkSZqhsCDIzFeAzcAe4DHg3sx8NCLuiIirq932AN+JiCPAPmBLZn6nqJokSWcq9F5Dmbkb2D2j7faa1wl8rPpHktQF3nROUt/beWiC7XuO8szxSVb4nYGmGQSS+tppdxrFO422wnsNSepr3mm0fQaBpL7mnUbbZxBI6mveabR9BoGkvuadRtvnZLGkvlZ7p1GvGmqNQSCp703faVSt8dSQJJWcQSBJJWcQSFLJGQSSVHIGgSSVnEEgSSVnEEhSyRkEklRyBoEklVxDQRARSyLirOrrt0bE1RExWGxpkqSF0OgRwQPAORGxEvgacBPwn4oqSpK0cBoNgsjMl4Brgc9m5vXAjxdXliRpoTQcBBFxJXAj8EfVtoE5+kuS+kSjQfBrwFbgDzPz0Yj4MWBfcWVJkhZKQ7ehzsw/Bv4YoDpp/FxmfqTIwiRJC6PRq4a+GBFviIglwDeBIxGxpdjSJEkLodFTQ5dm5veAjcBXgYuoXDkkSepzjQbBYPV7AxuBXZk5BWRxZUmSFkqjQfA54FvAEuCBiLgA+F5RRUmSFk6jk8W/C/xuTdOTETFaTEmSpIXU8MPrI+LvUfkS2Tk1zXd0vCJJ0oJq9Kqh/wC8H/gwEMD1wAUF1iVJWiCNzhH87cz8h8DzmfkbwJXAW4srS5K0UBoNgsnqf1+KiBXAFPDmYkqSJC2kRucIvhIRy4DtwDeoXDr6+cKqkiQtmEavGvpU9eX9EfEV4JzMfKG4siRJC2XOIIiIa+dYR2bu6HxJkqSFNN8RwXtmLE9/mziqr+cMgojYAHyayi2rP5+Z22bp917gy8DfyswD8xUtSeqcOYMgM/8RQER8nMqOP6ZXAS9ExE9m5sP1to2IAeAu4F3A08D+iNiVmUdm9Hs98FHgoXYGIklqTaNXDa0FbqFypdAK4J8AG4D/GBG/Pss2lwPHMvOJzHwZGAOuqdPvU8BvAX/dTOGSpM6IzPnvHRcRDwDvzswT1eWlVJ5UtgE4mJmX1tnmOmBDZt5cXb4JuCIzN9f0+Sngtsx8b0SMA5+od2ooIjYBmwCWL1++dmxsrOmBApw4cYKlS5e2tG2vcSy9Z7GMAxxLr2pnLKOjowczc7jeukYvH/1R4Ac1y1PA8sycjIgfzLLNnKoPuPkd4EPz9c3Mu4G7AYaHh3NkZKSVH8n4+DitbttrHEvvWSzjAMfSq4oaS6NBcA/wUET8l+rye4AvVh9Uc2SWbSaAVTXL51fbpr0e+AlgPCIA/iawKyKudsJYkhZOw98jiIivAuuqTbfU7KxvnGWz/cDFEXERlQC4AfhgzXu+AJw7vTzXqSFJUnEavvtodQfd8E46M1+JiM3AHiqXj36h+uD7O4ADmbmr6WolSR3XcBC0IjN3A7tntN0+S9+RImuRJNXX6OWjkqRFyiCQpJIzCCSp5AwCSSo5g0CSSs4gkKSSMwgkqeQMAkkqOYNAkkrOIJCkkjMIJKnkDAJJKjmDQJJKziCQpJIzCCSp5AwCSSo5g0CSSs4gkKSSMwgkqeQMAkkqOYNAkkrOIJCkkjMIJKnkDAJJKjmDQJJKziCQpJIzCCSp5AwCSSo5g0CSSs4gkKSSMwgkqeQMAkkqOYNAkkrOIJCkkjMIJKnkCg2CiNgQEUcj4lhE3Fpn/cci4khE/FlE/I+IuKDIeiRJZyosCCJiALgL+AXgUuADEXHpjG6HgOHMfDvwZeC3i6pHklRfkUcElwPHMvOJzHwZGAOuqe2Qmfsy86Xq4oPA+QXWI0mqIzKzmDeOuA7YkJk3V5dvAq7IzM2z9P8M8P8y81/WWbcJ2ASwfPnytWNjYy3VdOLECZYuXdrStr3GsfSexTIOcCy9qp2xjI6OHszM4Xrrzm6rqg6JiH8ADAM/W299Zt4N3A0wPDycIyMjLf2c8fFxWt221ziW3rNYxgGOpVcVNZYig2ACWFWzfH617TQRcRVwG/CzmfmDAuuRJNVR5BzBfuDiiLgoIl4D3ADsqu0QEWuAzwFXZ+a3C6xFkjSLwoIgM18BNgN7gMeAezPz0Yi4IyKurnbbDiwF7ouIhyNi1yxvJ0kqSKFzBJm5G9g9o+32mtdXFfnzJUnz85vFklRyBoEklZxBIEklZxBIUskZBJJUcgaBJJWcQSBJJWcQSFLJGQSSVHI9cfdRSWrUzkMTbN9zlGeOT7Ji2RBb1q9m45qV3S6rrxkEkvrGzkMTbN1xmMmpkwBMHJ9k647DAIZBGzw1JKlvbN9z9FQITJucOsn2PUe7VNHiYBBI6hvPHJ9sql2NMQgk9Y0Vy4aaaldjDAJJfWPL+tUMDQ6c1jY0OMCW9au7VNHi4GSxpL4xPSHsVUOdZRBI6isb16x0x99hnhqSpJIzCCSp5AwCSSo5g0CSSs4gkKSSMwgkqeQMAkkqOYNAkkrOIJCkkjMIJKnkDAJJKjmDQJJKziCQpJIzCCSp5LwNtaSetfPQhM8eWAAGgaSetPPQBFt3HD71sPqJ45Ns3XEYwDDoMINAUkfU+/QO9Z8m1kjfl15+5VQITJucOsn2PUcNgg4zCLSoNbpz6kTbDate5LZte5va2fVqW+1YGtl29JLzuP/gxGmf3rfc9wgETJ3MU21bdxzmwJPfbajvbJ6ZY51aE5lZ3JtHbAA+DQwAn8/MbTPWvxb4A2At8B3g/Zn5rbnec3h4OA8cONBUHdO/kDesepGxp17f1C9Gr/5CtzKWTrd16u+mqLHM3DkBDJ4Vp+1wOtn28cte4V8fPpuhwQHeu3blgv7sosbS6LYBNLonGYjgZBv7nZXLhvj6rT/XcP/x8XFGRkZa/nm9pJ2xRMTBzByuu66oIIiIAeDPgXcBTwP7gQ9k5pGaPr8CvD0zb4mIG4BfzMz3z/W+zQZB7XnGZv/n7uVf6GbH0um2Tv7dFDWWZnZOnTA9Dmh/Z9dttWPpJUODA9x57WVNnRoyCCrmCoIi/6UvB45l5hPVIsaAa4AjNX2uAf5F9fWXgc9ERGQH02n7nqNnnGecevXMt6/XNjl1ki899NQZv9CNbr+Y2/rh76abu+F+DoGiNROSy4YGWfLas71qqGBFHhFcB2zIzJuryzcBV2Tm5po+36z2ebq6/BfVPs/NeK9NwCaA5cuXrx0bG2u4jsMTL5x6vXwI/mqRnF50LL2ndhxBkF2NovZ04t8kqByl1e5jzorgTa8b5PmXpni1pn22vivfNMSyocG26jhx4gRLly5t6z16RTtjGR0d7coRQcdk5t3A3VA5NdTModFt2/aemnhq5XC3Vw/xe+HQvVN/N0WOZebpIecImhtLs6cK9z3+bEfnljrx6d9TQ/Mrck8yAayqWT6/2lavz9MRcTbwRiqTxh2zZf3q065Fhu6cB19sbf3wd9PMzqkTbfAiK2t2YMMX/EjPXWTQylga3Xa2nXa99o1rVs7aroVX5Kmhs6lMFr+Tyg5/P/DBzHy0ps+vApfVTBZfm5nvm+t9vWrIq4Y6sXMqgp88e5NjqZhrspjMLOwP8G4qYfAXwG3VtjuAq6uvzwHuA44Bfwr82HzvuXbt2mzVvn37Wt621ziW3rNYxpHpWHpVO2MBDuQs+9VCTzJn5m5g94y222te/zVwfZE1SJLm5t1HJankDAJJKjmDQJJKziCQpJIr9KZzRYiIZ4EnW9z8XOC5eXv1B8fSexbLOMCx9Kp2xnJBZp5Xb0XfBUE7IuJAznYdbZ9xLL1nsYwDHEuvKmosnhqSpJIzCCSp5MoWBHd3u4AOciy9Z7GMAxxLrypkLKWaI5AknalsRwSSpBkMAkkqudIFQUR8KiL+LCIejoivRcSKbtfUqojYHhGPV8fzhxGxrNs1tSIiro+IRyPi1Yjoy8v8ImJDRByNiGMRcWu362lVRHwhIr5dfXpg34qIVRGxLyKOVP/f+mi3a2pVRJwTEX8aEY9Ux/IbHf8ZZZsjiIg3ZOb3qq8/Alyambd0uayWRMTPA3sz85WI+C2AzPynXS6raRHxNuBV4HPAJzKzuQdOdFlEDFC53fq7gKepPHvjA5l5ZM4Ne1BE/F3gBPAHmfkT3a6nVRHxZuDNmfmNiHg9cBDY2Kf/JgEsycwTETEI/C/go5n5YKd+RumOCKZDoGoJ3X3GeVsy82uZ+Up18UEqT4HrO5n5WGYe7XYdbbgcOJaZT2Tmy8AYcE2Xa2pJZj4AfLfbdbQrM/9vZn6j+vpF4DGgLx9/Vn2cwInq4mD1T0f3W6ULAoCI+M2IeAq4Ebh9vv594peAr3a7iJJaCTxVs/w0fbrTWYwi4kJgDfBQdytpXUQMRMTDwLeB/5aZHR3LogyCiPjvEfHNOn+uAcjM2zJzFXAPsLm71c5tvrFU+9wGvEJlPD2pkXFInRYRS4H7gV+bcTagr2Tmycz8SSpH/ZdHREdP2xX6hLJuycyrGux6D5UnqH2ywHLaMt9YIuJDwN8H3pk9POHTxL9JP5oAVtUsn19tUxdVz6ffD9yTmTu6XU8nZObxiNgHbAA6NqG/KI8I5hIRF9csXgM83q1a2hURG4Bfp/IM6Je6XU+J7QcujoiLIuI1wA3Ari7XVGrVCdbfAx7LzN/pdj3tiIjzpq8IjIghKhcldHS/Vcarhu4HVlO5SuVJ4JbM7MtPbxFxDHgt8J1q04P9eAVURPwi8O+A84DjwMOZub67VTUnIt4N/FtgAPhCZv5ml0tqSUR8CRihcrvjvwI+mZm/19WiWhARPwP8T+Awld91gH9WfY56X4mItwO/T+X/rbOAezPzjo7+jLIFgSTpdKU7NSRJOp1BIEklZxBIUskZBJJUcgaBJJWcQSA1ISK+FRHntttH6iUGgSSVnEEgzSIidkbEweo94DfNWHdh9VkQ90TEYxHx5Yh4XU2XD0fENyLicERcUt3m8oj4k4g4FBH/OyJWL+iApFkYBNLsfikz1wLDwEci4m/MWL8a+Gxmvg34HvArNeuey8yfAv498Ilq2+PA38nMNVTuevuvCq1eapBBIM3uIxHxCJVnPawCLp6x/qnM/Hr19X8GfqZm3fRNzg4CF1ZfvxG4r/r0r38D/HgRRUvNMgikOiJiBLgKuDIz3wEcAs6Z0W3m/Vlql39Q/e9JfniX308B+6pP/npPnfeTusIgkOp7I/B8Zr5UPcf/03X6vCUirqy+/iCVRwjO957TNzj8UEeqlDrAIJDq+6/A2RHxGLCNyumhmY4Cv1rt8yYq8wFz+W3gzog4xCJ9Foj6k3cflVpQffzhV/r5Ae/SNI8IJKnkPCKQpJLziECSSs4gkKSSMwgkqeQMAkkqOYNAkkru/wPh+FjxIYad6QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "DzyXEsEx7cQg",
        "outputId": "1cd6cc2f-77f5-4751-a73b-0a58dea8ac92"
      },
      "source": [
        "plt.xlabel('alpha')\n",
        "plt.ylabel('male')\n",
        "plt.scatter(alpha_list,temp[:,20])\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "1Idyz7Ky7eQV",
        "outputId": "f3cf61ad-df93-4a88-a15b-ce50933b1c2b"
      },
      "source": [
        "plt.xlabel('alpha')\n",
        "plt.ylabel('smile')\n",
        "plt.scatter(alpha_list,temp[:,31])\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "48CGPmEEDSWI",
        "outputId": "8abf1a37-1af7-4747-b5d5-d6cbe6eb1562"
      },
      "source": [
        "plt.xlabel('alpha')\n",
        "plt.ylabel('young')\n",
        "plt.scatter(alpha_list[:31],temp[:31,-1])\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXPklEQVR4nO3df5BdZ3nY8e9j2caq5Vg2AoFlgeyOouLG7ShSDFTJdAUOEkxqu8QhTlyHn/EfVCYzgFJ5nHE6ZhoETtt/apJ6aGbSKY1iXKOKICIb5G2mFIMtFlAsW7FioHgNNibIsUDFlvz0j3sWrlb37p57d8+9597z/czc0T3nvvfu8+7R7rPvj/O+kZlIkprrjGEHIEkaLhOBJDWciUCSGs5EIEkNZyKQpIY7c9gB9GrFihW5Zs2avt77wx/+kHPPPXdxAxoS61I/41IPsC51tZC6HDhw4JnMfFmn10YuEaxZs4aHHnqor/dOTk4yMTGxuAENiXWpn3GpB1iXulpIXSLiW91es2tIkhrORCBJDWcikKSGMxFIUsOZCCSp4RqRCHZPTbNp534OTj/Lpp372T01PeyQJKk2Rm76aK92T01z8z0HOf7CSVgN00ePc/M9BwG4Zv2qIUcnScM39i2C2/cdbiWBNsdfOMnt+w4PKSJJqpexTwRPHj3e03lJapqxTwQXLV/a03lJapqxTwTbt6xj6VlLTjm39KwlbN+ybkgRSVK9jP1g8cyAcGtM4DlWLV/K9i3rHCiWpMLYJwJoJYNr1q9icnKSm66f6Fpu99Q0t+87zJNHj3ORCUNSQzQiEZRxyjRTnGYqqTnGfoygLKeZSmoqWwSFXqeZ2o0kaVzYIij0Ms10phtp+uhxkp92I7l0haRRZCIo9DLN1G4kSePErqFC+zTT+bp7vFtZ0jgxEbSZmWY6n4uWL2W6wy9971aWNIrsGuqDdytLGie2CPrQSzeSJNWdiaBPZbuRnGYqqe5MBBXybmVJo8Axggo5zVTSKDARVMhpppJGgYmgQm6KI2kUmAgq5DRTSaPAweIKOc1U0igwEVSs7DRTSRoWu4YkqeFMBJLUcCYCSWo4E4EkNZyJQJIartJEEBFbI+JwRByJiB0dXn9VRNwfEVMR8fWIeEuV8UiSTldZIoiIJcAdwJuBy4DfiIjLZhX7PeCuzFwPXAd8rKp4JEmdVdkiuAI4kpmPZ+bzwC7g6lllEviZ4vn5wJMVxiNJ6iAys5oPjrgW2JqZ7ymObwBem5nb2sq8ErgXuAA4F7gyMw90+KwbgRsBVq5cuWHXrl19xXTs2DGWLVvW13vrxrrUz7jUA6xLXS2kLps3bz6QmRs7vpiZlTyAa4GPtx3fAPynWWXeD3ygeP564BBwxlyfu2HDhuzX/fff3/d768a61M+41CPTutTVQuoCPJRdfq9W2TU0DaxuO764ONfu3cBdAJn5ReAcYEWFMUmSZqkyETwIrI2ISyLibFqDwXtmlfm/wBsBIuI1tBLB9yqMSZI0S2WJIDNPANuAfcAjtGYHPRwRt0XEVUWxDwC/HRFfA/4MeEfRhJEkDUilq49m5l5g76xzt7Y9PwRsqjKGUeEm95KGxWWoa8BN7iUNk0tM1ICb3EsaJhNBDbjJvaRhMhHUgJvcSxomE0ENuMm9pGFysLgG3ORe0jCZCGrCTe4lDYtdQ5LUcCYCSWo4E4EkNZyJQJIazkQgSQ1nIpCkhjMRSFLDmQgkqeFMBJLUcCYCSWo4E4EkNZyJQJIazkQgSQ1nIpCkhjMRSFLDmQgkqeFMBJLUcCYCSWo4E4EkNZyJYMTsnppm0879HJx+lk0797N7anrYIUkacW5eP0J2T01z8z0HOf7CSVgN00ePc/M9BwHc+F5S32wRjJDb9x1uJYE2x184ye37Dg8pIknjwEQwQp48eryn85JUholghFy0fGlP5yWpDBPBCNm+ZR1Lz1pyyrmlZy1h+5Z1Q4pI0jhwsHiEzAwIt8YEnmPV8qVs37LOgWJJC2IiGDHXrF/FNetXMTk5yU3XTww7HEljwK4hSWq4ShNBRGyNiMMRcSQidnQp87aIOBQRD0fEf68yHknS6SrrGoqIJcAdwC8DTwAPRsSezDzUVmYtcDOwKTN/EBEvryoeSVJnVbYIrgCOZObjmfk8sAu4elaZ3wbuyMwfAGTm0xXGI0nqIDKzmg+OuBbYmpnvKY5vAF6bmdvayuwG/gbYBCwB/m1m/mWHz7oRuBFg5cqVG3bt2tVXTMeOHWPZsmV9vbdu5qvL0eMv8NSz/4/nT77I2UvOYOX557B86VkDjLC8cbku41IPsC51tZC6bN68+UBmbuz02rBnDZ0JrAUmgIuBv4qIyzPzaHuhzLwTuBNg48aNOTEx0dcXm5ycpN/31s1cddk9Nc3Nnz/I8RfOYKbRt/Ssk3z4rZfVcqrpuFyXcakHWJe6qqouVXYNTQOr244vLs61ewLYk5kvZOY3aLUO1lYYUyO4JpGkXlSZCB4E1kbEJRFxNnAdsGdWmd20WgNExArgZ4HHK4ypEVyTSFIvKksEmXkC2AbsAx4B7srMhyPitoi4qii2D/h+RBwC7ge2Z+b3q4qpKVyTSFIvKh0jyMy9wN5Z525te57A+4uHFsn2Let+um9BwTWJJHUz7MFiVaB9TaInjx7nItckkjQHE8GYmlmTSJLm41pDktRwJgJJajgTgSQ1nIlAkhpu3sHiiLiww+nnMvOFCuKRJA1YmRbBV4Dv0Vr+4bHi+Tcj4isRsaHK4CRJ1SuTCO4D3pKZKzLzpcCbgb8A3gt8rMrgJEnVK5MIXpeZ+2YOMvNe4PWZ+QDwksoikyQNRJkbyr4TEf+G1sYyAL8OPFXsQPZiZZFpIHZPTXsHstRwZVoEv0lrCendxeNVxbklwNuqC01V2z01zc33HGT66HESmD56nJvvOcjuqdmrhUsaZ/O2CDLzGeCmLi8fWdxwNEhz7Vtgq0BqjjLTR38W+CCwpr18Zr6hurA0CO5bIAnKjRF8Evhj4OPAyXnKaoRctHwp0x1+6btvgdQsZcYITmTmH2XmlzPzwMyj8shUue1b1rH0rCWnnHPfAql5yrQIPh0R7wU+Bfx45mRm/l1lUWkg3LdAEpRLBG8v/t3edi6BSxc/HA2a+xZIKjNr6JJBBCJJGo4ys4Z+q9P5zPyvix+OJGnQynQN/ULb83OAN9JaiM5EIEljoEzX0Ck3k0XEcn663IQkacT1szHNDwHHDSRpTJQZI/g0rVlC0Fpf6DXAXVUGJUkanDJjBH/Y9vwE8K3MfKKieCRJAzZv11Bm/i/gUeA84ALg+aqDkiQNzryJICLeBnwZ+DVay05/KSKurTowSdJglOkaugX4hcx8GiAiXgZ8Dri7ysAkSYNRZtbQGTNJoPD9ku+TJI2AMi2Cz0bEPuDPiuNfB/ZWF5IkaZDKJIIngC8Cv1Qc35mZn6ouJEnSIJVJBC8H3kdrWYk/AfZVGpFqyU3upfFVZvro7wFrgf8CvAN4LCL+ICL+YcWxqSbc5F4ab6UGfTMzge8WjxO07ie4OyI+WmFsqom5NrmXNPrKLDHxO8BvAc/Q2rd4e2a+EBFnAI8Bv1ttiBo2N7mXxluZMYILgbdm5rfaT2bmixHxK9WEpTpxk3tpvJUZI/j92Umg7bVH5npvRGyNiMMRcSQidsxR7lcjIiNi4/wha9Dc5F4ab2VaBH2JiCXAHcAv05qC+mBE7MnMQ7PKnQf8DvClqmLRwvS6yb0zjKTRUlkiAK4AjmTm4wARsQu4Gjg0q9yHgI8A2yuMRQtUdpP7mRlGM4PLMzOMZj5DUv1Ea0JQBR/cWphua2a+pzi+AXhtZm5rK/PzwC2Z+asRMQl8MDMf6vBZNwI3AqxcuXLDrl39bZB27Ngxli1b1td766audTn83ed4/uSLp50/e8kZrHvFeR3fU9e69Gpc6gHWpa4WUpfNmzcfyMyO3e9VtgjmVMw6+g+07k2YU2beCdwJsHHjxpyYmOjra05OTtLve+umrnV5547PkB2GngL4xs6Jju+pa116NS71AOtSV1XVpcrF46aB1W3HFxfnZpwH/BwwGRHfBF4H7HHAeLR1m0nkDCOpvqpMBA8CayPikog4G7gO2DPzYmY+m5krMnNNZq4BHgCu6tQ1pNHhDCNp9FTWNZSZJyJiG621iZYAf5KZD0fEbcBDmbln7k/QKOp1hpGk4at0jCAz9zJryerMvLVL2YkqY9HglJ1hJKke3GBGkhrORCBJDWci0NDsnppm0879HJx+lk0797ustTQkQ7uPQM12yh3Iq70DWRomWwQaCvc4kOrDFoGGopc9DlzETqqWLQINRdk7kN0mU6qeiUBDUfYOZLuQpOrZNaShaL8DGZ5jVZcuH7fJlKpnItDQzNyBPDk5yU3XT3Qs4zaZUvXsGlKtuYidVD1bBKo1F7GTqmciUO25iJ1ULbuGJKnhbBFobHjjmdQfE4HGwilrF+HaRVIv7BrSWPDGM6l/JgKNBW88k/pnItBYKLt2kaTTmQg0FrzxTOqfg8UaC73ceObsIulUJgKNjTI3njm7SDqdXUNqFGcXSaczEahRnF0knc5EoEZxdpF0OhOBGsXZRdLpHCxWo7istXQ6E4Eap+yy1k4zVVOYCKQOnGaqJnGMQOrAaaZqEhOB1IHTTNUkJgKpA6eZqklMBFIHTjNVkzhYLHXgNFM1iYlA6qLsNFNp1FXaNRQRWyPicEQciYgdHV5/f0QcioivR8TnI+LVVcYjSTpdZYkgIpYAdwBvBi4DfiMiLptVbArYmJn/BLgb+GhV8UiSOquyRXAFcCQzH8/M54FdwNXtBTLz/sz8UXH4AHBxhfFIldg9Nc2mnfs5OP0sm3buZ/fU9LBDknpSZSJYBXy77fiJ4lw37wY+W2E80qKbuQN5uri/YOYOZJOBRklkZjUfHHEtsDUz31Mc3wC8NjO3dSj7r4BtwD/PzB93eP1G4EaAlStXbti1a1dfMR07doxly5b19d66sS71cPi7z/H8yRcBWLkUniruNzt7yRmse8V5Q4xsYUb5msxmXVo2b958IDM3dnqtyllD08DqtuOLi3OniIgrgVvokgQAMvNO4E6AjRs35sTERF8BTU5O0u9768a61MM7d3yGLBrWH7j8BP/+YOtHKoBv7JwYXmALNMrXZDbrMr8qu4YeBNZGxCURcTZwHbCnvUBErAf+M3BVZj5dYSxSJbwDWeOgskSQmSdodffsAx4B7srMhyPitoi4qih2O7AM+GREfDUi9nT5OKmWvANZ46DSG8oycy+wd9a5W9ueX1nl15eq1n4HMjzHKu9A1gjyzmJpgWbuQJ6cnOSm6yeGHY7UMxedk6SGMxFIUsPZNSQNkPsgq45MBNKAuA+y6squIWlA3AdZdWUikAbEfZBVVyYCaUC8C1l1ZSKQBqSXu5Bnlra+ZMdnXNpalXOwWBqQsvsgO6isQTMRSANUZh/kuQaVTQSqgolAqpleBpW9L0GLwTECqWbKDiq3746WuDua+mcikGqm7KByL/clOPisudg1JNVM2UHlsl1IDj5rPiYCqYbKDCpftHwp0x2SwewupF4Gn2fGHK5b/Ry37NzvmEND2DUkjaiyXUi9thxmkstcYw52NY0XE4E0oq5Zv4oPv/VyVi1fSgCrli/lw2+9/LS/4MsOPpcdc3CQevzYNSSNsDJdSNu3rDtljAAW1nLop6vJ6a31ZiKQxlzZweeyYw4OUo8fE4HUAIvZcqhikBpsPQyTiUAScGrLAZ5jVZdfxovd1QS9tR5MGIvPwWJJP3HN+lV8YccbuHzV+Xxhxxs6/oJd7EFqqGagemZm08HpZ53ZNA9bBJJ6tphdTbD4A9WntDBW28KYj4lAUiXKDlLD4g9U95UwaG7CMBFIqkyZlgMs/kD1qCSMuiQXxwgkDV3ZcYeyd1OXHZ9YjITRrtcxjLqMd9gikFQLZVoPZbub6t7C6KVsL+Md/TIRSBopvSaMxZgKu9gJo5eyg9ixzq4hSWNpMafCLnaXVC9le0ku/bJFIKnRhtEl1UvZsq2RhTARSFIJi5kweinbS3Lpl4lAkhZR2SmzZcuWHe9YCBOBJNXcTMKYnJzkpusnFv3zHSyWpIYzEUhSw5kIJKnhTASS1HAmAklquMjMYcfQk4j4HvCtPt++AnhmEcMZJutSP+NSD7AudbWQurw6M1/W6YWRSwQLEREPZebGYcexGKxL/YxLPcC61FVVdbFrSJIazkQgSQ3XtERw57ADWETWpX7GpR5gXeqqkro0aoxAknS6prUIJEmzmAgkqeHGOhFExIci4usR8dWIuDciLupS7u0R8VjxePug4ywjIm6PiEeL+nwqIpZ3KffNiDhY1PmhQcdZRg912RoRhyPiSETsGHSc84mIX4uIhyPixYjoOqVvRK5J2brU+poARMSFEXFf8fN8X0Rc0KXcyeKafDUi9gw6zm7m+x5HxEsi4s+L178UEWsW/EUzc2wfwM+0PX8f8McdylwIPF78e0Hx/IJhx94hzjcBZxbPPwJ8pEu5bwIrhh3vQusCLAH+FrgUOBv4GnDZsGOfFeNrgHXAJLBxjnKjcE3mrcsoXJMizo8CO4rnO+b4WTk27Fj7+R4D7535XQZcB/z5Qr/uWLcIMvPv2w7PBTqNjG8B7svMv8vMHwD3AVsHEV8vMvPezDxRHD4AXDzMeBaiZF2uAI5k5uOZ+TywC7h6UDGWkZmPZObhYcexGErWpfbXpHA18KfF8z8FrhliLL0q8z1ur9/dwBsjIhbyRcc6EQBExL+LiG8D1wO3diiyCvh22/ETxbk6exfw2S6vJXBvRByIiBsHGFO/utVlFK9LN6N2TboZlWuyMjO/Uzz/LrCyS7lzIuKhiHggIuqSLMp8j39SpviD6lngpQv5oiO/Q1lEfA54RYeXbsnM/5mZtwC3RMTNwDbg9wcaYA/mq0tR5hbgBPCJLh/zi5k5HREvB+6LiEcz86+qibi7RarL0JWpRwkjc01GxVx1aT/IzIyIbnPkX11cl0uB/RFxMDP/drFjHQUjnwgy88qSRT8B7OX0RDANTLQdX0yrn3Tg5qtLRLwD+BXgjVl0EHb4jOni36cj4lO0mpoD/6WzCHWZBla3HV9cnBuoHv5/zfUZI3FNSqjFNYG56xIRT0XEKzPzOxHxSuDpLp8xc10ej4hJYD2t/vlhKvM9ninzREScCZwPfH8hX3Ssu4YiYm3b4dXAox2K7QPeFBEXFLML3lScq5WI2Ar8LnBVZv6oS5lzI+K8mee06vLXg4uynDJ1AR4E1kbEJRFxNq1BsdrM7ChrVK5JSaNyTfYAM7P/3g6c1topft5fUjxfAWwCDg0swu7KfI/b63ctsL/bH4alDXuUvMoH8D9o/dB9Hfg0sKo4vxH4eFu5dwFHisc7hx13l7ocodUv+NXiMTNr4CJgb/H8UlqzDL4GPEyryT/02PupS3H8FuBvaP2VVru6AP+SVh/uj4GngH0jfE3mrcsoXJMixpcCnwceAz4HXFic/8nPPfDPgIPFdTkIvHvYcc/1PQZuo/WHE8A5wCeLn6MvA5cu9Gu6xIQkNdxYdw1JkuZnIpCkhjMRSFLDmQgkqeFMBJLUcCYCqQfFSqIrFlpGqhMTgSQ1nIlA6iIidhcLxT08e7G4iFhT7KnwiYh4JCLujoh/0Fbkpoj4SrEPwT8q3nNFRHwxIqYi4v9ExLqBVkjqwkQgdfeuzNxA647U90XE7BUe1wEfy8zXAH9Pa534Gc9k5s8DfwR8sDj3KPBLmbme1kq4f1Bp9FJJJgKpu/dFxNdo7ZmwGlg76/VvZ+YXiuf/DfjFttfuKf49AKwpnp8PfDIi/hr4j8A/riJoqVcmAqmDiJgArgRen5n/FJiitcZLu9nrs7Qf/7j49yQ/XeX3Q8D9mflzwL/o8HnSUJgIpM7OB36QmT8q+vhf16HMqyLi9cXz3wT+d4nPnFlS+B2LEqW0CEwEUmd/CZwZEY8AO2l1D812GPjXRZkLaI0HzOWjwIcjYoox2AtE48PVR6U+RMQa4C+Kbh5ppNkikKSGs0UgSQ1ni0CSGs5EIEkNZyKQpIYzEUhSw5kIJKnh/j8j/Z0umMF0dQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "eMpgyPJIDVjk",
        "outputId": "7a155970-2b8f-4710-893a-5503539e8859"
      },
      "source": [
        "plt.xlabel('alpha')\n",
        "plt.ylabel('glass')\n",
        "plt.scatter(alpha_list[:31],temp[:31,15])\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEGCAYAAABCa2PoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdrklEQVR4nO3dfZBc1Xnn8e8v4k0hicRLMosGrSUKWYlY1VqxCseRd2sWbEv2ri2ZgrW8LCFGVUoqYMcVL8koVGEvXi0CkpDdMnZWNqyJl1gQjGWtkS1j5I7LrHkRCFtIspYJ4EITXtZYEsiWZSQ/+0efMT1Nd8/tnnunb/f8PlVTc/v0uXfOo2bm4Z5zzzmKCMzMzCbrl7rdADMz6w9OKGZmlgsnFDMzy4UTipmZ5cIJxczMcnFCtxvQTWeeeWbMmzevo3N//OMfc+qpp+bboC5xLOXTL3GAYymrycTy6KOP/jAifr2+fFonlHnz5rFjx46Ozq1UKgwNDeXboC5xLOXTL3GAYymrycQi6QeNyt3lZWZmuXBCMTOzXDihmJlZLpxQzMwsF04oZmaWCycUM7NpZPPOUZZt2M6u0UMs27CdzTtHc7v2tH5s2MysH2zeOcpN2/bxTwePMGf2TK5evpBVSwYb1lt3zy6OvHoc5sLowSOsu2cXQMP67fIdiplZDxtLEqMHjxC8liQa3XnctG1fNZnUOPLqcW7ati+XtjihmJn1sHaSxD8dPNLwGs3K2+WEYmbWw9pJEnNmz2xYt1l5u5xQzMx6WDtJ4urlC5l54oxxZTNPnMHVyxfm0hYnFDOzHtZOkli1ZJDrL1rMYEo2g7Nncv1Fi3MZkAc/5WVmVlpZnt4ae53lKa+x+quWDFKpVPjQpUO5ttcJxcyshMY94kvrR3zHkkS3ucvLzKyEin7EtwhOKGZmJVT0I75FcEIxMyuhoh/xLYITiplZCRX9iG8RPChvZlZC7T69VQZOKGZmJVWWp7eycpeXmZnlwgnFzMxy4YRiZma5cEIxM7NcOKGYmVkunFDMzCwXTihmZpYLJxQzM8uFE4qZmeWi0IQiaYWkfZJGJA03eP9kSXem9x+SNK/mvXWpfJ+k5alsrqRvStojabekP66p/3FJo5IeT1/vLjI2MzMbr7ClVyTNAG4B3gHsBx6RtCUi9tRUWwMciIhzJa0GbgDeL2kRsBo4D5gDfEPSG4FjwEcj4jFJvwo8Kum+mmveHBF/UVRMZmbWXJF3KOcDIxHxVET8DNgErKyrsxK4PR3fDVwoSal8U0QcjYingRHg/Ih4LiIeA4iIV4C9QO8sdGNm1seKTCiDwLM1r/fz+j/+v6gTEceAQ8AZWc5N3WNLgIdqiq+S9D1Jt0k6bfIhmJnlb/POUZZt2M784XtZtmE7m3eOdrtJuejJ1YYl/QrwReAjEfFyKv408Akg0ve/BK5ocO5aYC3AwMAAlUqlozYcPny443PLxrGUT7/EAY6l3sEjrzJ64Air5wbMBXiF0b2Psvn5PcyeeWIezcykiM+lyIQySvrnSs5OZY3q7Jd0AjALeKnVuZJOpJpM7oiIe8YqRMQLY8eSPgN8pVGjImIjsBFg6dKlMTQ01EFoUKlU6PTcsnEs5dMvcYBjqbdsw3ZGD854Xfng7Bk8MDy5a7ejiM+lyC6vR4AFkuZLOonqIPuWujpbgMvT8cXA9oiIVL46PQU2H1gAPJzGV24F9kbEX9VeSNJZNS/fBzyRe0RmZpPUi3vFZ1XYHUpEHJN0FbANmAHcFhG7JV0H7IiILVSTw+cljQA/opp0SPXuAvZQfbLryog4LultwGXALkmPpx/15xGxFbhR0puodnk9A/xBUbGZmXVqzuyZjDZIHmXeKz6rQsdQ0h/6rXVl19Yc/xS4pMm564H1dWXfBtSk/mWTba+ZWdGuXr6Qdffs4sirx39RVva94rPqyUF5M7Ne1Yt7xWflhGJmNsV6ba/4rLyWl5mZ5cIJxczMcuGEYmZmuXBCMTOzXDihmJlZLpxQzMwsF04oZmaWCycUMzPLhSc2mpnlZPPO0b6cAZ+VE4qZWQ427xwdt0bX6MEjrLtnF8C0SSru8jIzy8FN2/aNW/AR4Mirx7lp274utWjqOaGYmeWgn/c5ycoJxcwsB832M+mHfU6yckIxM8vB1csXMvPE8Vv79ss+J1l5UN7MLAf9vM9JVk4oZmY56dd9TrJyl5eZmeXCCcXMzHLhhGJmNoHNO0dZtmE7u0YPsWzDdjbvHO12k0rJYyhmZi2MmwE/d3rOgM/KdyhmZi14Bnx2TihmZi14Bnx2TihmZi14Bnx2TihmZi14Bnx2HpQ3M2uhdgY8vMLgNJwBn1WhdyiSVkjaJ2lE0nCD90+WdGd6/yFJ82reW5fK90lansrmSvqmpD2Sdkv645r6p0u6T9KT6ftpRcZmZtPHqiWDPDB8AYsHZ/HA8AVOJk0UllAkzQBuAd4FLAI+IGlRXbU1wIGIOBe4GbghnbsIWA2cB6wAPpWudwz4aEQsAn4HuLLmmsPA/RGxALg/vTYzsylS5B3K+cBIRDwVET8DNgEr6+qsBG5Px3cDF0pSKt8UEUcj4mlgBDg/Ip6LiMcAIuIVYC8w2OBatwOrCorLzMwaKHIMZRB4tub1fuAtzepExDFJh4AzUvmDdeeOu8dM3WNLgIdS0UBEPJeOnwcGGjVK0lpgLcDAwACVSqWNkF5z+PDhjs8tG8dSPv0SBziWsioilp4clJf0K8AXgY9ExMv170dESIpG50bERmAjwNKlS2NoaKijNlQqFTo9t2wcS/n0SxzgWMqqiFiK7PIaBebWvD47lTWsI+kEYBbwUqtzJZ1INZncERH31NR5QdJZqc5ZwIu5RWJmZhMqMqE8AiyQNF/SSVQH2bfU1dkCXJ6OLwa2R0Sk8tXpKbD5wALg4TS+ciuwNyL+qsW1Lge+nHtEZmbWVGFdXmlM5CpgGzADuC0idku6DtgREVuoJofPSxoBfkQ16ZDq3QXsofpk15URcVzS24DLgF2SHk8/6s8jYiuwAbhL0hrgB8C/Lyo2M+sPm3eOTusdFvNW6BhK+kO/ta7s2prjnwKXNDl3PbC+ruzbgJrUfwm4cJJNNrNpYtwqwngV4Tx46RUzm5a8inD+nFDMbFryKsL5c0Ixs2nJqwjnzwnFzKYlryKcv56c2GhmNlm1qwj7Ka98OKGY2bS1asmgE0iO3OVlZma5cEIxM7NcOKGYmVkunFDMzCwXTihmZpYLJxQzM8uFE4qZmeXCCcXMzHLhhGJmZrlwQjEzs1w4oZiZWS6cUMzMLBdeHNLM+o73iu8OJxQz6yveK7573OVlZn3Fe8V3jxOKmfUV7xXfPU4oZtZXvFd892RKKJJOlfRL6fiNkt4r6cRim2Zm1j7vFd89We9QvgWcImkQ+DpwGfC5ohplZtapVUsGuf6ixQzOnomAwdkzuf6ixR6QnwJZn/JSRPxE0hrgUxFxo6THi2yYmVmnvFd8d2S9Q5GktwKXAvemshkt6puZ2TSTNaF8BFgHfCkidks6B/jmRCdJWiFpn6QRScMN3j9Z0p3p/Yckzat5b10q3ydpeU35bZJelPRE3bU+LmlU0uPp690ZYzMzsxxk6vKKiH8A/gEgDc7/MCI+3OocSTOAW4B3APuBRyRtiYg9NdXWAAci4lxJq4EbgPdLWgSsBs4D5gDfkPTGiDhOdezmk8DfNvixN0fEX2SJycx6i2e/l1/Wp7z+TtKvSToVeALYI+nqCU47HxiJiKci4mfAJmBlXZ2VwO3p+G7gQklK5Zsi4mhEPA2MpOsREd8CfpSl3WbWH8Zmv48ePELw2uz3zTtHu900q5F1UH5RRLws6VLgq8Aw8ChwU4tzBoFna17vB97SrE5EHJN0CDgjlT9Yd26W/xW5StLvATuAj0bEgfoKktYCawEGBgaoVCoZLvt6hw8f7vjcsnEs5dMvcUA+sbzw/Cv80W/+vK70GC/se4zKoScnde12+HNpLWtCOTHNO1kFfDIiXpUUubZk8j4NfAKI9P0vgSvqK0XERmAjwNKlS2NoaKijH1apVOj03LJxLOXTL3FAPrF8cPheokGHioCnN0zu2u3w59Ja1kH5/wE8A5wKfEvSG4CXJzhnFJhb8/rsVNawjqQTgFnASxnPHSciXoiI4xHxc+AzpC4yM+t9nv3eGzIllIj47xExGBHvjqofAP9mgtMeARZImi/pJKqD7Fvq6mwBLk/HFwPbIyJS+er0FNh8YAHwcKsfJumsmpfvozrWY2Ylt3nnKMs2bGf+8L0s27C94biIZ7/3hszL10v6t1Sfujqlpvi6ZvXTmMhVwDaqc1ZuS48cXwfsiIgtwK3A5yWNUB1oX53O3S3pLmAPcAy4Mj3hhaQvAEPAmZL2Ax+LiFuBGyW9iWqX1zPAH2SNzcy6I+tS82PHfsqr3DIlFEl/A/wy1buSz1K9m2h5xwAQEVuBrXVl19Yc/xS4pMm564H1Dco/0KT+ZRO1x8zKpdVS8/XJwrPfyy/rGMrvRsTvUZ0z8p+BtwJvLK5ZZjYdeKn5/pI1oYx9uj+RNAd4FTirRX0zswl5sL2/ZE0oX5E0m+q8k8eojlF8oahGmVnvGxts3zV6yIPt00TWpVc+kQ6/KOkrwCkRcai4ZplZLxs32D7Xg+3TRcuEIumiFu8REffk3yQz63UebJ+eJrpDeU/d67HZ8UrHTihm9joebJ+eWiaUiPgggKSPUk0gGnsLOCTpTRHhjbbMbJw5s2cy2iB5eLC9v2UdlH8z8IdUn+yaQ3XS4ArgM5L+tKC2mVmP8mD79JR1pvzZwG9HxGEASR+junPjv6a66vCNxTTPzHpR7WA7vMKgB9unhawJ5TeAozWvXwUGIuKIpKNNzjGzaWxssL1SqfChS4e63RybAlkTyh3AQ5K+nF6/B/i7tOHWnuanmVm/8c6J1kzmeSiSvgosS0V/GBE70vGlhbTMzEon62KONj1lXm04JZAdE1Y0s77VzvwSm36yPuVlZub5JdaSE4qZZebFHK0VJxQzA7xzok1e5jEUM+tf3jnR8uCEYmZezNFy4S4vM/Ngu+XCdyhmfS7LREQv5mh58B2KWR8bGxsZPXiE4LWxkfoBdw+2Wx6cUMz6WKuxkVqrlgxy/UWLGZw9EwGDs2dy/UWLPVZibXGXl1kPyrqeVjtjIx5st8nyHYpZj8najQWeiGhTywnFrMdk7cYCj43Y1HKXl1mPabcbCzwR0aaGE4pZj2n3EV+PjdhUKbTLS9IKSfskjUgabvD+yZLuTO8/JGlezXvrUvk+Sctrym+T9KKkJ+qudbqk+yQ9mb6fVmRsZt3ibiwrq8ISiqQZwC3Au4BFwAckLaqrtgY4EBHnAjcDN6RzFwGrgfOAFcCn0vUAPpfK6g0D90fEAuD+9Nqs7/gRXyurIru8zgdGIuIpAEmbgJWM3zJ4JfDxdHw38ElJSuWbIuIo8LSkkXS970TEt2rvZOquNZSObwcqwJ/lF45Zebgby8qoyIQyCDxb83o/8JZmdSLimKRDwBmp/MG6cyf67RmIiOfS8fPAQKNKktYCawEGBgaoVCoTBtLI4cOHOz63bBxL+fRLHOBYyqqIWPpyUD4iQlI0eW8jsBFg6dKlMTQ01NHPqFQqdHpu2TiW4mWdiDimrHF0wrGUUxGxFDkoPwrMrXl9diprWEfSCcAs4KWM59Z7QdJZ6VpnAS923HKzHLUzEdGslxWZUB4BFkiaL+kkqoPsW+rqbAEuT8cXA9sjIlL56vQU2HxgAfDwBD+v9lqXA1/OIQazSWtnIuLYrom7Rg813TXRrKwKSygRcQy4CtgG7AXuiojdkq6T9N5U7VbgjDTo/iekJ7MiYjdwF9UB/K8BV0bEcQBJXwC+AyyUtF/SmnStDcA7JD0JvD29Nuu6rBMRa+9kwHcy1nsKHUOJiK3A1rqya2uOfwpc0uTc9cD6BuUfaFL/JeDCybTXrAhZJyK2s2uiWRl5LS+zSRjropo/fG/TLqqsExG9a6L1ur58ystsKox1UY3dVYx1UQHj7iiyrqflXROt1zmhmHWonS6qLBMRr16+cFyCAi+pYr3FCcWsQ3l3UdXeycArDHplYOsxTihmHSqii2rsTqZSqfChS4cm0TqzqedBebMOedVfs/F8h2LWIW9eZTaeE4rZJHjVX7PXuMvLzMxy4YRiZma5cJeXWQPtLjdvZk4oZq+TdQa8mY3nLi+zOu0sN29mr3FCMavjRRrNOuMuL5tWsoyNeJFGs874DsWmjaxb8XoGvFlnnFBs2sg6NrJqySDXX7SYwdkzETA4eybXX7TYA/JmE3CXl00b7YyNeAa8Wft8h2LTRrMxEI+NmOXDCcWmDY+NmBXLCcX6wtje7rtGDzXd291jI2bF8hiK9bxxM9vntp7Z7rERs+L4DsV6nme2m5WDE4r1PM9sNysHJxTreX56y6wcnFCs5/npLbNy8KC89bzavd3hFQa9f4lZVxR6hyJphaR9kkYkDTd4/2RJd6b3H5I0r+a9dal8n6TlE11T0uckPS3p8fT1piJjs3JZtWSQB4YvYPHgLB4YvsDJxKwLCrtDkTQDuAV4B7AfeETSlojYU1NtDXAgIs6VtBq4AXi/pEXAauA8YA7wDUlvTOe0uubVEXF3UTGZmVlzRXZ5nQ+MRMRTAJI2ASuB2oSyEvh4Or4b+KQkpfJNEXEUeFrSSLoeGa5pfcLb8Jr1liITyiDwbM3r/cBbmtWJiGOSDgFnpPIH684d+0vS6prrJV0L3A8Mp4Q0jqS1wFqAgYEBKpVKe1Elhw8f7vjcsiljLAePvMrogSOsnhswF+AVRvc+yubn9zB75olNzytjLJ3olzjAsZRVEbH006D8OuB54CRgI/BnwHX1lSJiY3qfpUuXxtDQUEc/rFKp0Om5ZVPGWJZt2M7owRmvKx+cPYMHhoeanlfGWDrRL3GAYymrImIpclB+lPT/lsnZqaxhHUknALOAl1qc2/SaEfFcVB0F/ievdZFZD/JkRbPeU2RCeQRYIGm+pJOoDrJvqauzBbg8HV8MbI+ISOWr01Ng84EFwMOtrinprPRdwCrgiQJjs0kYW8hx/vC9TRdy9GRFs95TWEKJiGPAVcA2YC9wV0TslnSdpPemarcCZ6RB9z8BhtO5u4G7qA62fw24MiKON7tmutYdknYBu4Azgf9SVGzWOW/Da9a/Ch1DiYitwNa6smtrjn8KXNLk3PXA+izXTOUXTLa9VrxWCznWPsFVO1nRT3mZ9YZ+GpS3HuBteM36lxOKTSjP+SBzZs9ktEHy8NiIWe/z4pDWUtYxj7G6Ew22e2zErH85oVhLWTevypp4vA2vWf9yl5e1lHXMI+tgO3hsxKxf+Q7FWso6H8QTEc3MCcVayjrm4YmIZuaEYi1lHfPwYLuZeQxlGht7HHj13Fe4ZsP2po8DZxnz8EREM3NCmabGnso68upxmPvaU1lAx0nAg+1m05u7vKaprI8Dm5ll5TuUPpRlZrufyjKzvPkOpc9knWDop7LMLG9OKH0ma1eWn8oys7y5y6vPZO3Kqn0qC15h0E9lmdkkOaH0mXZW8x17KqtSqfChS4emoHVm1s/c5dVn3JVlZt3iO5QekuXpLU8wNLNucULpEeMmItJ6IqInGJpZNzihdFnW3RDbWR7ezKwbnFAKkiVRtHPX4YmIZlZ2HpRv09g2t7tGDzXd5jbr5MJ2lj/xREQzKzsnlDbUJgqYfKJo567DT2+ZWdk5obQh70TRzl2H92I3s7LzGEob2kkUWSYXXr184bgxFGh91+Gnt8yszHyH0oasdxRZu6d812Fm/cR3KG3IekfRzuRC33WYWb8oNKFIWgH8N2AG8NmI2FD3/snA3wJvBl4C3h8Rz6T31gFrgOPAhyNiW6trSpoPbALOAB4FLouIn+UZTzsLKjpRmNl0U1iXl6QZwC3Au4BFwAckLaqrtgY4EBHnAjcDN6RzFwGrgfOAFcCnJM2Y4Jo3ADenax1I187dqiWDPDB8AYsHZ/HA8AVOGmZmSZFjKOcDIxHxVLpT2ASsrKuzErg9Hd8NXChJqXxTRByNiKeBkXS9htdM51yQrkG65qoCYzMzszpFdnkNAs/WvN4PvKVZnYg4JukQ1S6rQeDBunPHbgUaXfMM4GBEHGtQfxxJa4G1AAMDA1QqlbaCGnP48OGOzy0bx1I+/RIHOJayKiKWaTcoHxEbgY0AS5cujaGhoY6uU6lU6PTcsnEs5dMvcYBjKasiYimyy2sUmFvz+uxU1rCOpBOAWVQH55ud26z8JWB2ukazn2VmZgUqMqE8AiyQNF/SSVQH2bfU1dkCXJ6OLwa2R0Sk8tWSTk5Pby0AHm52zXTON9M1SNf8coGxmZlZHVX/Fhd0cendwF9TfcT3tohYL+k6YEdEbJF0CvB5YAnwI2B1RDyVzr0GuAI4BnwkIr7a7Jqp/Byqg/SnAzuB/xgRRydo3/8DftBheGcCP+zw3LJxLOXTL3GAYymrycTyhoj49frCQhNKP5O0IyKWdrsdeXAs5dMvcYBjKasiYvHSK2ZmlgsnFDMzy4UTSuc2drsBOXIs5dMvcYBjKavcY/EYipmZ5cJ3KGZmlgsnFDMzy4UTSkaSPiHpe5Iel/R1SXOa1Ltc0pPp6/JGdbpN0k2Svp/i+ZKk2U3qPSNpV4p5x1S3M4s2YlkhaZ+kEUnDU93OiUi6RNJuST+X1PRRzh75TLLGUurPBEDS6ZLuS7/P90k6rUm94+kzeVxS/QTurpno3zhNHr8zvf+QpHmT+oER4a8MX8Cv1Rx/GPibBnVOB55K309Lx6d1u+0N2vlO4IR0fANwQ5N6zwBndru9k42F6iTYfwTOAU4Cvgss6nbb69r4W8BCoAIsbVGvFz6TCWPphc8ktfNGYDgdD7f4XTnc7bZ28m8M/NHY3zKqK4/cOZmf6TuUjCLi5ZqXpwKNnmZYDtwXET+KiAPAfVT3cymViPh6vLYy84NU1z7rSRljybKVQldFxN6I2NftduQhYyyl/0yS2i02em1bjMlsIdIRJ5Q2SFov6VngUuDaBlUaLdlf9h24rgC+2uS9AL4u6dG07H/ZNYulFz+XZnrtM2mmVz6TgYh4Lh0/Dww0qXeKpB2SHpRUlqST5d943BYiwNgWIh2ZdsvXtyLpG8A/a/DWNRHx5Yi4BrgmbU98FfCxKW1gGyaKJdW5hupaaXc0uczbImJU0m8A90n6fkR8q5gWN5dTLF2XJY4MeuYz6RWtYql9EREhqdk8izekz+UcYLukXRHxj3m3teycUGpExNszVr0D2MrrE8ooMFTz+myq/chTbqJYJP0+8O+ACyN1oDa4xmj6/qKkL1G9hZ7yP145xJJlK4XCtfHfV6tr9MRnkkEpPhNoHYukFySdFRHPSToLeLHJNcY+l6ckVagueNvthNLOFiL767YQ6Yi7vDKStKDm5Urg+w2qbQPeKem09DTIO1NZqUhaAfwp8N6I+EmTOqdK+tWxY6qxPDF1rcwmSyxk20qh9HrlM8moVz6T2i02Gm6LkX7fT07HZwLLgD1T1sLmJrOFSGe6/SRCr3wBX6T6y/s94H8Dg6l8KfDZmnpXACPp64PdbneTWEao9ps+nr7GnvKYA2xNx+dQfSrku8Buql0ZXW97J7Gk1+8G/i/V/2ssXSzA+6j2cR8FXgC29fBnMmEsvfCZpDaeAdwPPAl8Azg9lf/i9x74XWBX+lx2AWu63e5W/8bAdVT/BwzgFODv0+/Rw8A5k/l5XnrFzMxy4S4vMzPLhROKmZnlwgnFzMxy4YRiZma5cEIxM7NcOKGYdUlaOfjMydYxKwsnFDMzy4UTitkUkLQ5Lei4u35RR0nz0p4ud0jaK+luSb9cU+VDkh5L+6D8ZjrnfEnfkbRT0v+RtHBKAzJrwAnFbGpcERFvpjrD+sOS6ld0XQh8KiJ+C3iZ6j4VY34YEb8NfBr4T6ns+8C/ioglVFe+/q+Ftt4sAycUs6nxYUnfpbpny1xgQd37z0bEA+n4fwFvq3nvnvT9UWBeOp4F/L2kJ4CbgfOKaLRZO5xQzAomaQh4O/DWiPiXwE6qayjVql8Dqfb10fT9OK+tEP4J4JsR8S+A9zS4ntmUc0IxK94s4EBE/CSNgfxOgzr/XNJb0/F/AL6d4ZpjS5H/fi6tNJskJxSz4n0NOEHSXmAD1W6vevuAK1Od06iOl7RyI3C9pJ14XyMrCa82bNZlkuYBX0ndV2Y9y3coZmaWC9+hmJlZLnyHYmZmuXBCMTOzXDihmJlZLpxQzMwsF04oZmaWi/8Pf05xFp6Arq0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "aGEL1lprDVjk",
        "outputId": "47943531-bbc0-4e66-c307-c759ea0ab43c"
      },
      "source": [
        "plt.xlabel('alpha')\n",
        "plt.ylabel('male')\n",
        "plt.scatter(alpha_list[:31],temp[:31,20])\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "IWMyBSJbDVjk",
        "outputId": "fbcf4c6b-9474-40c0-ee7b-4cc68cc20c95"
      },
      "source": [
        "plt.xlabel('alpha')\n",
        "plt.ylabel('smile')\n",
        "plt.scatter(alpha_list[:31],temp[:31,31])\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}